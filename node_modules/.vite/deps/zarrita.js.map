{
  "version": 3,
  "sources": ["../../@zarrita/storage/src/util.ts", "../../@zarrita/storage/src/fetch.ts", "../../zarrita/src/typedarray.ts", "../../zarrita/src/util.ts", "../../zarrita/src/codecs/bitround.ts", "../../zarrita/src/codecs/bytes.ts", "../../zarrita/src/codecs/crc32c.ts", "../../zarrita/src/codecs/gzip.ts", "../../zarrita/src/codecs/json2.ts", "../../zarrita/src/codecs/transpose.ts", "../../zarrita/src/codecs/vlen-utf8.ts", "../../zarrita/src/codecs/zlib.ts", "../../zarrita/src/codecs.ts", "../../zarrita/src/errors.ts", "../../zarrita/src/consolidated.ts", "../../zarrita/src/codecs/sharding.ts", "../../zarrita/src/hierarchy.ts", "../../zarrita/src/create.ts", "../../zarrita/src/indexing/util.ts", "../../zarrita/src/indexing/indexer.ts", "../../zarrita/src/indexing/get.ts", "../../zarrita/src/indexing/set.ts", "../../zarrita/src/indexing/ops.ts", "../../zarrita/src/open.ts"],
  "sourcesContent": ["import type { AbsolutePath } from \"./types.js\";\n\nexport function strip_prefix<Path extends AbsolutePath>(\n\tpath: Path,\n): Path extends AbsolutePath<infer Rest> ? Rest : never {\n\t// @ts-expect-error - TS can't infer this type correctly\n\treturn path.slice(1);\n}\n\nexport function uri2href(url: string | URL) {\n\tlet [protocol, rest] = (typeof url === \"string\" ? url : url.href).split(\n\t\t\"://\",\n\t);\n\tif (protocol === \"https\" || protocol === \"http\") {\n\t\treturn url;\n\t}\n\tif (protocol === \"gc\") {\n\t\treturn `https://storage.googleapis.com/${rest}`;\n\t}\n\tif (protocol === \"s3\") {\n\t\treturn `https://s3.amazonaws.com/${rest}`;\n\t}\n\tthrow Error(`Protocol not supported, got: ${JSON.stringify(protocol)}`);\n}\n\nexport function fetch_range(\n\turl: string | URL,\n\toffset?: number,\n\tlength?: number,\n\topts: RequestInit = {},\n) {\n\tif (offset !== undefined && length !== undefined) {\n\t\t// merge request opts\n\t\topts = {\n\t\t\t...opts,\n\t\t\theaders: {\n\t\t\t\t...opts.headers,\n\t\t\t\tRange: `bytes=${offset}-${offset + length - 1}`,\n\t\t\t},\n\t\t};\n\t}\n\treturn fetch(url, opts);\n}\n\nexport function merge_init(\n\tstoreOverrides: RequestInit,\n\trequestOverrides: RequestInit,\n) {\n\t// Request overrides take precedence over storeOverrides.\n\treturn {\n\t\t...storeOverrides,\n\t\t...requestOverrides,\n\t\theaders: {\n\t\t\t...storeOverrides.headers,\n\t\t\t...requestOverrides.headers,\n\t\t},\n\t};\n}\n\n/**\n * Make an assertion.\n *\n * Usage\n * @example\n * ```ts\n * const value: boolean = Math.random() <= 0.5;\n * assert(value, \"value is greater than than 0.5!\");\n * value // true\n * ```\n *\n * @param expression - The expression to test.\n * @param msg - The optional message to display if the assertion fails.\n * @throws an {@link Error} if `expression` is not truthy.\n */\nexport function assert(\n\texpression: unknown,\n\tmsg: string | undefined = \"\",\n): asserts expression {\n\tif (!expression) throw new Error(msg);\n}\n", "import type { AbsolutePath, AsyncReadable, RangeQuery } from \"./types.js\";\nimport { fetch_range, merge_init } from \"./util.js\";\n\nfunction resolve(root: string | URL, path: AbsolutePath): URL {\n\tconst base = typeof root === \"string\" ? new URL(root) : root;\n\tif (!base.pathname.endsWith(\"/\")) {\n\t\t// ensure trailing slash so that base is resolved as _directory_\n\t\tbase.pathname += \"/\";\n\t}\n\tconst resolved = new URL(path.slice(1), base);\n\t// copy search params to new URL\n\tresolved.search = base.search;\n\treturn resolved;\n}\n\nasync function handle_response(\n\tresponse: Response,\n): Promise<Uint8Array | undefined> {\n\tif (response.status === 404) {\n\t\treturn undefined;\n\t}\n\tif (response.status === 200 || response.status === 206) {\n\t\treturn new Uint8Array(await response.arrayBuffer());\n\t}\n\tthrow new Error(\n\t\t`Unexpected response status ${response.status} ${response.statusText}`,\n\t);\n}\n\nasync function fetch_suffix(\n\turl: URL,\n\tsuffix_length: number,\n\tinit: RequestInit,\n\tuse_suffix_request: boolean,\n): Promise<Response> {\n\tif (use_suffix_request) {\n\t\treturn fetch(url, {\n\t\t\t...init,\n\t\t\theaders: { ...init.headers, Range: `bytes=-${suffix_length}` },\n\t\t});\n\t}\n\tlet response = await fetch(url, { ...init, method: \"HEAD\" });\n\tif (!response.ok) {\n\t\t// will be picked up by handle_response\n\t\treturn response;\n\t}\n\tlet content_length = response.headers.get(\"Content-Length\");\n\tlet length = Number(content_length);\n\treturn fetch_range(url, length - suffix_length, length, init);\n}\n\n/**\n * Readonly store based in the [Fetch API](https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API).\n * Must polyfill `fetch` for use in Node.js.\n *\n * ```typescript\n * import * as zarr from \"zarrita\";\n * const store = new FetchStore(\"http://localhost:8080/data.zarr\");\n * const arr = await zarr.get(store, { kind: \"array\" });\n * ```\n */\nclass FetchStore implements AsyncReadable<RequestInit> {\n\t#overrides: RequestInit;\n\t#use_suffix_request: boolean;\n\n\tconstructor(\n\t\tpublic url: string | URL,\n\t\toptions: { overrides?: RequestInit; useSuffixRequest?: boolean } = {},\n\t) {\n\t\tthis.#overrides = options.overrides ?? {};\n\t\tthis.#use_suffix_request = options.useSuffixRequest ?? false;\n\t}\n\n\t#merge_init(overrides: RequestInit) {\n\t\treturn merge_init(this.#overrides, overrides);\n\t}\n\n\tasync get(\n\t\tkey: AbsolutePath,\n\t\toptions: RequestInit = {},\n\t): Promise<Uint8Array | undefined> {\n\t\tlet href = resolve(this.url, key).href;\n\t\tlet response = await fetch(href, this.#merge_init(options));\n\t\treturn handle_response(response);\n\t}\n\n\tasync getRange(\n\t\tkey: AbsolutePath,\n\t\trange: RangeQuery,\n\t\toptions: RequestInit = {},\n\t): Promise<Uint8Array | undefined> {\n\t\tlet url = resolve(this.url, key);\n\t\tlet init = this.#merge_init(options);\n\t\tlet response: Response;\n\t\tif (\"suffixLength\" in range) {\n\t\t\tresponse = await fetch_suffix(\n\t\t\t\turl,\n\t\t\t\trange.suffixLength,\n\t\t\t\tinit,\n\t\t\t\tthis.#use_suffix_request,\n\t\t\t);\n\t\t} else {\n\t\t\tresponse = await fetch_range(url, range.offset, range.length, init);\n\t\t}\n\t\treturn handle_response(response);\n\t}\n}\n\nexport default FetchStore;\n", "/**\n * Custom array-like views (i.e., TypedArrays) for Zarr binary data buffers.\n *\n * @module\n */\n\n/**\n * An array-like view of a fixed-length boolean buffer.\n *\n * Encoded as 1 byte per value.\n */\nexport class BoolArray {\n\t#bytes: Uint8Array;\n\n\tconstructor(size: number);\n\tconstructor(arr: Iterable<boolean>);\n\tconstructor(buffer: ArrayBuffer, byteOffset?: number, length?: number);\n\tconstructor(\n\t\tx: number | Iterable<boolean> | ArrayBuffer,\n\t\tbyteOffset?: number,\n\t\tlength?: number,\n\t) {\n\t\tif (typeof x === \"number\") {\n\t\t\tthis.#bytes = new Uint8Array(x);\n\t\t} else if (x instanceof ArrayBuffer) {\n\t\t\tthis.#bytes = new Uint8Array(x, byteOffset, length);\n\t\t} else {\n\t\t\tthis.#bytes = new Uint8Array(Array.from(x, (v) => (v ? 1 : 0)));\n\t\t}\n\t}\n\n\tget BYTES_PER_ELEMENT(): 1 {\n\t\treturn 1;\n\t}\n\n\tget byteOffset(): number {\n\t\treturn this.#bytes.byteOffset;\n\t}\n\n\tget byteLength(): number {\n\t\treturn this.#bytes.byteLength;\n\t}\n\n\tget buffer(): ArrayBuffer {\n\t\treturn this.#bytes.buffer as ArrayBuffer;\n\t}\n\n\tget length(): number {\n\t\treturn this.#bytes.length;\n\t}\n\n\tget(idx: number): boolean {\n\t\tlet value = this.#bytes[idx];\n\t\treturn typeof value === \"number\" ? value !== 0 : value;\n\t}\n\n\tset(idx: number, value: boolean): void {\n\t\tthis.#bytes[idx] = value ? 1 : 0;\n\t}\n\n\tfill(value: boolean): void {\n\t\tthis.#bytes.fill(value ? 1 : 0);\n\t}\n\n\t*[Symbol.iterator](): IterableIterator<boolean> {\n\t\tfor (let i = 0; i < this.length; i++) {\n\t\t\tyield this.get(i);\n\t\t}\n\t}\n}\n\n/**\n * An array-like view of a fixed-length byte buffer.\n *\n * Encodes a raw byte sequences without enforced encoding.\n */\nexport class ByteStringArray {\n\t_data: Uint8Array;\n\tchars: number;\n\t#encoder: TextEncoder;\n\n\tconstructor(chars: number, size: number);\n\tconstructor(\n\t\tchars: number,\n\t\tbuffer: ArrayBuffer,\n\t\tbyteOffset?: number,\n\t\tlength?: number,\n\t);\n\tconstructor(chars: number, arr: Iterable<string>);\n\tconstructor(\n\t\tchars: number,\n\t\tx: number | ArrayBuffer | Iterable<string>,\n\t\tbyteOffset?: number,\n\t\tlength?: number,\n\t) {\n\t\tthis.chars = chars;\n\t\tthis.#encoder = new TextEncoder();\n\t\tif (typeof x === \"number\") {\n\t\t\tthis._data = new Uint8Array(x * chars);\n\t\t} else if (x instanceof ArrayBuffer) {\n\t\t\tif (length) length = length * chars;\n\t\t\tthis._data = new Uint8Array(x, byteOffset, length);\n\t\t} else {\n\t\t\tlet values = Array.from(x);\n\t\t\tthis._data = new Uint8Array(values.length * chars);\n\t\t\tfor (let i = 0; i < values.length; i++) {\n\t\t\t\tthis.set(i, values[i]);\n\t\t\t}\n\t\t}\n\t}\n\n\tget BYTES_PER_ELEMENT(): number {\n\t\treturn this.chars;\n\t}\n\n\tget byteOffset(): number {\n\t\treturn this._data.byteOffset;\n\t}\n\n\tget byteLength(): number {\n\t\treturn this._data.byteLength;\n\t}\n\n\tget buffer(): ArrayBuffer {\n\t\treturn this._data.buffer as ArrayBuffer;\n\t}\n\n\tget length(): number {\n\t\treturn this.byteLength / this.BYTES_PER_ELEMENT;\n\t}\n\n\tget(idx: number): string {\n\t\tconst view = new Uint8Array(\n\t\t\tthis.buffer,\n\t\t\tthis.byteOffset + this.chars * idx,\n\t\t\tthis.chars,\n\t\t);\n\t\t// biome-ignore lint/suspicious/noControlCharactersInRegex: necessary for null byte removal\n\t\treturn new TextDecoder().decode(view).replace(/\\x00/g, \"\");\n\t}\n\n\tset(idx: number, value: string): void {\n\t\tconst view = new Uint8Array(\n\t\t\tthis.buffer,\n\t\t\tthis.byteOffset + this.chars * idx,\n\t\t\tthis.chars,\n\t\t);\n\t\tview.fill(0); // clear current\n\t\tview.set(this.#encoder.encode(value));\n\t}\n\n\tfill(value: string): void {\n\t\tconst encoded = this.#encoder.encode(value);\n\t\tfor (let i = 0; i < this.length; i++) {\n\t\t\tthis._data.set(encoded, i * this.chars);\n\t\t}\n\t}\n\n\t*[Symbol.iterator](): IterableIterator<string> {\n\t\tfor (let i = 0; i < this.length; i++) {\n\t\t\tyield this.get(i);\n\t\t}\n\t}\n}\n\n/**\n * An array-like view of a fixed-length Unicode string buffer.\n *\n * Encoded as UTF-32 code points.\n */\nexport class UnicodeStringArray {\n\t#data: Int32Array;\n\tchars: number;\n\n\tconstructor(chars: number, size: number);\n\tconstructor(\n\t\tchars: number,\n\t\tbuffer: ArrayBuffer,\n\t\tbyteOffset?: number,\n\t\tlength?: number,\n\t);\n\tconstructor(chars: number, arr: Iterable<string>);\n\tconstructor(\n\t\tchars: number,\n\t\tx: number | ArrayBuffer | Iterable<string>,\n\t\tbyteOffset?: number,\n\t\tlength?: number,\n\t) {\n\t\tthis.chars = chars;\n\t\tif (typeof x === \"number\") {\n\t\t\tthis.#data = new Int32Array(x * chars);\n\t\t} else if (x instanceof ArrayBuffer) {\n\t\t\tif (length) length *= chars;\n\t\t\tthis.#data = new Int32Array(x, byteOffset, length);\n\t\t} else {\n\t\t\tconst values = x;\n\t\t\tconst d = new UnicodeStringArray(chars, 1);\n\t\t\tthis.#data = new Int32Array(\n\t\t\t\t(function* () {\n\t\t\t\t\tfor (let str of values) {\n\t\t\t\t\t\td.set(0, str);\n\t\t\t\t\t\tyield* d.#data;\n\t\t\t\t\t}\n\t\t\t\t})(),\n\t\t\t);\n\t\t}\n\t}\n\n\tget BYTES_PER_ELEMENT(): number {\n\t\treturn this.#data.BYTES_PER_ELEMENT * this.chars;\n\t}\n\n\tget byteLength(): number {\n\t\treturn this.#data.byteLength;\n\t}\n\n\tget byteOffset(): number {\n\t\treturn this.#data.byteOffset;\n\t}\n\n\tget buffer(): ArrayBuffer {\n\t\treturn this.#data.buffer as ArrayBuffer;\n\t}\n\n\tget length(): number {\n\t\treturn this.#data.length / this.chars;\n\t}\n\n\tget(idx: number): string {\n\t\tconst offset = this.chars * idx;\n\t\tlet result = \"\";\n\t\tfor (let i = 0; i < this.chars; i++) {\n\t\t\tresult += String.fromCodePoint(this.#data[offset + i]);\n\t\t}\n\t\t// biome-ignore lint/suspicious/noControlCharactersInRegex: necessary for null byte removal\n\t\treturn result.replace(/\\u0000/g, \"\");\n\t}\n\n\tset(idx: number, value: string): void {\n\t\tconst offset = this.chars * idx;\n\t\tconst view = this.#data.subarray(offset, offset + this.chars);\n\t\tview.fill(0); // clear current\n\t\tfor (let i = 0; i < this.chars; i++) {\n\t\t\tview[i] = value.codePointAt(i) ?? 0;\n\t\t}\n\t}\n\n\tfill(value: string): void {\n\t\t// encode once\n\t\tthis.set(0, value);\n\t\t// copy the encoded values to all other elements\n\t\tlet encoded = this.#data.subarray(0, this.chars);\n\t\tfor (let i = 1; i < this.length; i++) {\n\t\t\tthis.#data.set(encoded, i * this.chars);\n\t\t}\n\t}\n\n\t*[Symbol.iterator](): IterableIterator<string> {\n\t\tfor (let i = 0; i < this.length; i++) {\n\t\t\tyield this.get(i);\n\t\t}\n\t}\n}\n", "import type {\n\tArrayMetadata,\n\tArrayMetadataV2,\n\tBigintDataType,\n\tCodecMetadata,\n\tDataType,\n\tGroupMetadata,\n\tNumberDataType,\n\tObjectType,\n\tScalar,\n\tStringDataType,\n\tTypedArrayConstructor,\n} from \"./metadata.js\";\nimport {\n\tBoolArray,\n\tByteStringArray,\n\tUnicodeStringArray,\n} from \"./typedarray.js\";\n\nexport function json_encode_object(o: Record<string, unknown>): Uint8Array {\n\tconst str = JSON.stringify(o, null, 2);\n\treturn new TextEncoder().encode(str);\n}\n\nexport function json_decode_object(bytes: Uint8Array) {\n\tconst str = new TextDecoder().decode(bytes);\n\treturn JSON.parse(str);\n}\n\nexport function byteswap_inplace(view: Uint8Array, bytes_per_element: number) {\n\tconst numFlips = bytes_per_element / 2;\n\tconst endByteIndex = bytes_per_element - 1;\n\tlet t = 0;\n\tfor (let i = 0; i < view.length; i += bytes_per_element) {\n\t\tfor (let j = 0; j < numFlips; j += 1) {\n\t\t\tt = view[i + j];\n\t\t\tview[i + j] = view[i + endByteIndex - j];\n\t\t\tview[i + endByteIndex - j] = t;\n\t\t}\n\t}\n}\n\nexport function get_ctr<D extends DataType>(\n\tdata_type: D,\n): TypedArrayConstructor<D> {\n\tif (data_type === \"v2:object\") {\n\t\treturn globalThis.Array as unknown as TypedArrayConstructor<D>;\n\t}\n\tlet match = data_type.match(/v2:([US])(\\d+)/);\n\tif (match) {\n\t\tlet [, kind, chars] = match;\n\t\t// @ts-expect-error\n\t\treturn (kind === \"U\" ? UnicodeStringArray : ByteStringArray).bind(\n\t\t\tnull,\n\t\t\tNumber(chars),\n\t\t);\n\t}\n\t// @ts-expect-error - We've checked that the key exists\n\tlet ctr: TypedArrayConstructor<D> | undefined = (\n\t\t{\n\t\t\tint8: Int8Array,\n\t\t\tint16: Int16Array,\n\t\t\tint32: Int32Array,\n\t\t\tint64: globalThis.BigInt64Array,\n\t\t\tuint8: Uint8Array,\n\t\t\tuint16: Uint16Array,\n\t\t\tuint32: Uint32Array,\n\t\t\tuint64: globalThis.BigUint64Array,\n\t\t\tfloat16: globalThis.Float16Array,\n\t\t\tfloat32: Float32Array,\n\t\t\tfloat64: Float64Array,\n\t\t\tbool: BoolArray,\n\t\t} as const\n\t)[data_type];\n\tassert(ctr, `Unknown or unsupported data_type: ${data_type}`);\n\treturn ctr;\n}\n\n/** Compute strides for 'C' or 'F' ordered array from shape */\nexport function get_strides(\n\tshape: readonly number[],\n\torder: \"C\" | \"F\" | Array<number>,\n): Array<number> {\n\tconst rank = shape.length;\n\tif (typeof order === \"string\") {\n\t\torder =\n\t\t\torder === \"C\"\n\t\t\t\t? Array.from({ length: rank }, (_, i) => i) // Row-major (identity order)\n\t\t\t\t: Array.from({ length: rank }, (_, i) => rank - 1 - i); // Column-major (reverse order)\n\t}\n\tassert(\n\t\trank === order.length,\n\t\t\"Order length must match the number of dimensions.\",\n\t);\n\n\tlet step = 1;\n\tlet stride = new Array(rank);\n\tfor (let i = order.length - 1; i >= 0; i--) {\n\t\tstride[order[i]] = step;\n\t\tstep *= shape[order[i]];\n\t}\n\n\treturn stride;\n}\n\n// https://zarr-specs.readthedocs.io/en/latest/v3/core/v3.0.html#chunk-key-encoding\nexport function create_chunk_key_encoder({\n\tname,\n\tconfiguration,\n}: ArrayMetadata[\"chunk_key_encoding\"]): (chunk_coords: number[]) => string {\n\tif (name === \"default\") {\n\t\tconst separator = configuration?.separator ?? \"/\";\n\t\treturn (chunk_coords) => [\"c\", ...chunk_coords].join(separator);\n\t}\n\tif (name === \"v2\") {\n\t\tconst separator = configuration?.separator ?? \".\";\n\t\treturn (chunk_coords) => chunk_coords.join(separator) || \"0\";\n\t}\n\tthrow new Error(`Unknown chunk key encoding: ${name}`);\n}\n\nfunction coerce_dtype(\n\tdtype: string,\n): { data_type: DataType } | { data_type: DataType; endian: \"little\" | \"big\" } {\n\tif (dtype === \"|O\") {\n\t\treturn { data_type: \"v2:object\" };\n\t}\n\n\tlet match = dtype.match(/^([<|>])(.*)$/);\n\tassert(match, `Invalid dtype: ${dtype}`);\n\n\tlet [, endian, rest] = match;\n\tlet data_type =\n\t\t{\n\t\t\tb1: \"bool\",\n\t\t\ti1: \"int8\",\n\t\t\tu1: \"uint8\",\n\t\t\ti2: \"int16\",\n\t\t\tu2: \"uint16\",\n\t\t\ti4: \"int32\",\n\t\t\tu4: \"uint32\",\n\t\t\ti8: \"int64\",\n\t\t\tu8: \"uint64\",\n\t\t\tf2: \"float16\",\n\t\t\tf4: \"float32\",\n\t\t\tf8: \"float64\",\n\t\t}[rest] ??\n\t\t(rest.startsWith(\"S\") || rest.startsWith(\"U\") ? `v2:${rest}` : undefined);\n\tassert(data_type, `Unsupported or unknown dtype: ${dtype}`);\n\tif (endian === \"|\") {\n\t\treturn { data_type } as { data_type: DataType };\n\t}\n\treturn { data_type, endian: endian === \"<\" ? \"little\" : \"big\" } as {\n\t\tdata_type: DataType;\n\t\tendian: \"little\" | \"big\";\n\t};\n}\n\nexport function v2_to_v3_array_metadata(\n\tmeta: ArrayMetadataV2,\n\tattributes: Record<string, unknown> = {},\n): ArrayMetadata<DataType> {\n\tlet codecs: CodecMetadata[] = [];\n\tlet dtype = coerce_dtype(meta.dtype);\n\tif (meta.order === \"F\") {\n\t\tcodecs.push({ name: \"transpose\", configuration: { order: \"F\" } });\n\t}\n\tif (\"endian\" in dtype && dtype.endian === \"big\") {\n\t\tcodecs.push({ name: \"bytes\", configuration: { endian: \"big\" } });\n\t}\n\tfor (let { id, ...configuration } of meta.filters ?? []) {\n\t\tcodecs.push({ name: id, configuration });\n\t}\n\tif (meta.compressor) {\n\t\tlet { id, ...configuration } = meta.compressor;\n\t\tcodecs.push({ name: id, configuration });\n\t}\n\treturn {\n\t\tzarr_format: 3,\n\t\tnode_type: \"array\",\n\t\tshape: meta.shape,\n\t\tdata_type: dtype.data_type,\n\t\tchunk_grid: {\n\t\t\tname: \"regular\",\n\t\t\tconfiguration: {\n\t\t\t\tchunk_shape: meta.chunks,\n\t\t\t},\n\t\t},\n\t\tchunk_key_encoding: {\n\t\t\tname: \"v2\",\n\t\t\tconfiguration: {\n\t\t\t\tseparator: meta.dimension_separator ?? \".\",\n\t\t\t},\n\t\t},\n\t\tcodecs,\n\t\tfill_value: meta.fill_value,\n\t\tattributes,\n\t};\n}\n\nexport function v2_to_v3_group_metadata(\n\t_meta: unknown,\n\tattributes: Record<string, unknown> = {},\n): GroupMetadata {\n\treturn {\n\t\tzarr_format: 3,\n\t\tnode_type: \"group\",\n\t\tattributes,\n\t};\n}\n\nexport type DataTypeQuery =\n\t| DataType\n\t| \"boolean\"\n\t| \"number\"\n\t| \"bigint\"\n\t| \"object\"\n\t| \"string\";\n\nexport type NarrowDataType<\n\tDtype extends DataType,\n\tQuery extends DataTypeQuery,\n> = Query extends \"number\"\n\t? NumberDataType\n\t: Query extends \"bigint\"\n\t\t? BigintDataType\n\t\t: Query extends \"string\"\n\t\t\t? StringDataType\n\t\t\t: Query extends \"object\"\n\t\t\t\t? ObjectType\n\t\t\t\t: Extract<Query, Dtype>;\n\nexport function is_dtype<Query extends DataTypeQuery>(\n\tdtype: DataType,\n\tquery: Query,\n): dtype is NarrowDataType<DataType, Query> {\n\tif (\n\t\tquery !== \"number\" &&\n\t\tquery !== \"bigint\" &&\n\t\tquery !== \"boolean\" &&\n\t\tquery !== \"object\" &&\n\t\tquery !== \"string\"\n\t) {\n\t\treturn dtype === query;\n\t}\n\tlet is_boolean = dtype === \"bool\";\n\tif (query === \"boolean\") return is_boolean;\n\tlet is_string = dtype.startsWith(\"v2:U\") || dtype.startsWith(\"v2:S\");\n\tif (query === \"string\") return is_string;\n\tlet is_bigint = dtype === \"int64\" || dtype === \"uint64\";\n\tif (query === \"bigint\") return is_bigint;\n\tlet is_object = dtype === \"v2:object\";\n\tif (query === \"object\") return is_object;\n\treturn !is_string && !is_bigint && !is_boolean && !is_object;\n}\n\nexport type ShardingCodecMetadata = {\n\tname: \"sharding_indexed\";\n\tconfiguration: {\n\t\tchunk_shape: number[];\n\t\tcodecs: CodecMetadata[];\n\t\tindex_codecs: CodecMetadata[];\n\t};\n};\n\nexport function is_sharding_codec(\n\tcodec: CodecMetadata,\n): codec is ShardingCodecMetadata {\n\treturn codec?.name === \"sharding_indexed\";\n}\n\nexport function ensure_correct_scalar<D extends DataType>(\n\tmetadata: ArrayMetadata<D>,\n): Scalar<D> | null {\n\tif (\n\t\t(metadata.data_type === \"uint64\" || metadata.data_type === \"int64\") &&\n\t\tmetadata.fill_value != null\n\t) {\n\t\t// @ts-expect-error - We've narrowed the type of fill_value correctly\n\t\treturn BigInt(metadata.fill_value) as Scalar<D>;\n\t}\n\treturn metadata.fill_value;\n}\n\n// biome-ignore lint/suspicious/noExplicitAny: Necessary for type inference\ntype InstanceType<T> = T extends new (...args: any[]) => infer R ? R : never;\n\n// biome-ignore lint/suspicious/noExplicitAny: Abstract base type\ntype ErrorConstructor = new (...args: any[]) => Error;\n\n/**\n * Ensures an error matches expected type(s), otherwise rethrows.\n *\n * Unmatched errors bubble up, like Python's `except`. Narrows error types for\n * type-safe property access.\n *\n * @see {@link https://gist.github.com/manzt/3702f19abb714e21c22ce48851c75abf}\n *\n * @example\n * ```ts\n * class DatabaseError extends Error { }\n * class NetworkError extends Error { }\n *\n * try {\n *   await db.query();\n * } catch (err) {\n *   rethrow_unless(err, DatabaseError, NetworkError);\n *   err // DatabaseError | NetworkError\n * }\n * ```\n *\n * @param error - The error to check\n * @param errors - Expected error type(s)\n * @throws The original error if it doesn't match expected type(s)\n */\nexport function rethrow_unless<E extends ReadonlyArray<ErrorConstructor>>(\n\terror: unknown,\n\t...errors: E\n): asserts error is InstanceType<E[number]> {\n\tif (!errors.some((ErrorClass) => error instanceof ErrorClass)) {\n\t\tthrow error;\n\t}\n}\n\n/**\n * Make an assertion.\n *\n * Usage\n * @example\n * ```ts\n * const value: boolean = Math.random() <= 0.5;\n * assert(value, \"value is greater than than 0.5!\");\n * value // true\n * ```\n *\n * @param expression - The expression to test.\n * @param msg - The optional message to display if the assertion fails.\n * @throws an {@link Error} if `expression` is not truthy.\n */\nexport function assert(\n\texpression: unknown,\n\tmsg: string | undefined = \"\",\n): asserts expression {\n\tif (!expression) {\n\t\tthrow new Error(msg);\n\t}\n}\n\n/**\n * @param {ArrayBuffer |ArrayBufferView | Response} data\n * @param {Object} options\n * @param {CompressionFormat} options.format\n * @param {AbortSignal} [options.signal]\n *\n * @returns {Promise<ArrayBuffer>}\n */\nexport async function decompress(\n\tdata: ArrayBuffer | ArrayBufferView | Response,\n\t{ format, signal }: { format: CompressionFormat; signal?: AbortSignal },\n): Promise<ArrayBuffer> {\n\tconst response = data instanceof Response ? data : new Response(data);\n\tassert(response.body, \"Response does not contain body.\");\n\ttry {\n\t\tconst decompressedResponse = new Response(\n\t\t\tresponse.body.pipeThrough(new DecompressionStream(format), { signal }),\n\t\t);\n\t\tconst buffer = await decompressedResponse.arrayBuffer();\n\t\treturn buffer;\n\t} catch {\n\t\tsignal?.throwIfAborted();\n\t\tthrow new Error(`Failed to decode ${format}`);\n\t}\n}\n", "import type { Chunk, Float32, Float64 } from \"../metadata.js\";\nimport { assert } from \"../util.js\";\n\n/**\n * A codec for bit-rounding.\n *\n * Reduces floating-point precision by truncating mantissa bits during encoding.\n * Decoding is a no-op as the process is lossy and precision cannot be restored.\n *\n * Note: {@link BitroundCodec.encode} is not yet implemented since Zarrita is\n * primarily used in read-only contexts (web browser). If you need encoding support,\n * please open an issue at {@link https://github.com/manzt/zarrita.js/issues}.\n *\n * @see {@link https://github.com/zarr-developers/numcodecs/blob/main/numcodecs/bitround.py}\n * for the original Python implementation.\n *\n * @remarks\n * Data types are not validated, and `float16` arrays are not supported (reflecting browser support).\n */\nexport class BitroundCodec<D extends Float64 | Float32> {\n\tkind = \"array_to_array\";\n\n\tconstructor(configuration: { keepbits: number }, _meta: { data_type: D }) {\n\t\tassert(configuration.keepbits >= 0, \"keepbits must be zero or positive\");\n\t}\n\n\tstatic fromConfig<D extends Float32 | Float64>(\n\t\tconfiguration: { keepbits: number },\n\t\tmeta: { data_type: D },\n\t): BitroundCodec<D> {\n\t\treturn new BitroundCodec(configuration, meta);\n\t}\n\n\t/**\n\t * Encode a chunk of data with bit-rounding.\n\t * @param _arr - The chunk to encode\n\t */\n\tencode(_arr: Chunk<D>): Chunk<D> {\n\t\tthrow new Error(\n\t\t\t\"`BitroundCodec.encode` is not implemented. Please open an issue at https://github.com/manzt/zarrita.js/issues.\",\n\t\t);\n\t}\n\n\t/**\n\t * Decode a chunk of data (no-op).\n\t * @param arr - The chunk to decode\n\t * @returns The decoded chunk\n\t */\n\tdecode(arr: Chunk<D>): Chunk<D> {\n\t\treturn arr; // No-op as bit-rounding is lossy\n\t}\n}\n", "import type {\n\tChunk,\n\tCodecMetadata,\n\tDataType,\n\tTypedArrayConstructor,\n} from \"../metadata.js\";\nimport { byteswap_inplace, get_ctr, get_strides } from \"../util.js\";\n\nconst LITTLE_ENDIAN_OS = system_is_little_endian();\n\nfunction system_is_little_endian(): boolean {\n\tconst a = new Uint32Array([0x12345678]);\n\tconst b = new Uint8Array(a.buffer, a.byteOffset, a.byteLength);\n\treturn !(b[0] === 0x12);\n}\n\nfunction bytes_per_element<D extends DataType>(\n\tTypedArray: TypedArrayConstructor<D>,\n): number {\n\tif (\"BYTES_PER_ELEMENT\" in TypedArray) {\n\t\treturn TypedArray.BYTES_PER_ELEMENT as number;\n\t}\n\t// Unicode string array is backed by a Int32Array.\n\treturn 4;\n}\n\nexport class BytesCodec<D extends Exclude<DataType, \"v2:object\">> {\n\tkind = \"array_to_bytes\";\n\t#stride: Array<number>;\n\t#TypedArray: TypedArrayConstructor<D>;\n\t#BYTES_PER_ELEMENT: number;\n\t#shape: Array<number>;\n\t#endian?: \"little\" | \"big\";\n\n\tconstructor(\n\t\tconfiguration: { endian?: \"little\" | \"big\" } | undefined,\n\t\tmeta: { data_type: D; shape: number[]; codecs: CodecMetadata[] },\n\t) {\n\t\tthis.#endian = configuration?.endian;\n\t\tthis.#TypedArray = get_ctr(meta.data_type);\n\t\tthis.#shape = meta.shape;\n\t\tthis.#stride = get_strides(meta.shape, \"C\");\n\t\t// TODO: fix me.\n\t\t// hack to get bytes per element since it's dynamic for string types.\n\t\tconst sample = new this.#TypedArray(0);\n\t\tthis.#BYTES_PER_ELEMENT = sample.BYTES_PER_ELEMENT;\n\t}\n\n\tstatic fromConfig<D extends Exclude<DataType, \"v2:object\">>(\n\t\tconfiguration: { endian: \"little\" | \"big\" },\n\t\tmeta: { data_type: D; shape: number[]; codecs: CodecMetadata[] },\n\t): BytesCodec<D> {\n\t\treturn new BytesCodec(configuration, meta);\n\t}\n\n\tencode(arr: Chunk<D>): Uint8Array {\n\t\tlet bytes = new Uint8Array(arr.data.buffer);\n\t\tif (LITTLE_ENDIAN_OS && this.#endian === \"big\") {\n\t\t\tbyteswap_inplace(bytes, bytes_per_element(this.#TypedArray));\n\t\t}\n\t\treturn bytes;\n\t}\n\n\tdecode(bytes: Uint8Array): Chunk<D> {\n\t\tif (LITTLE_ENDIAN_OS && this.#endian === \"big\") {\n\t\t\tbyteswap_inplace(bytes, bytes_per_element(this.#TypedArray));\n\t\t}\n\t\treturn {\n\t\t\tdata: new this.#TypedArray(\n\t\t\t\tbytes.buffer,\n\t\t\t\tbytes.byteOffset,\n\t\t\t\tbytes.byteLength / this.#BYTES_PER_ELEMENT,\n\t\t\t),\n\t\t\tshape: this.#shape,\n\t\t\tstride: this.#stride,\n\t\t};\n\t}\n}\n", "export class Crc32cCodec {\n\treadonly kind = \"bytes_to_bytes\";\n\tstatic fromConfig() {\n\t\treturn new Crc32cCodec();\n\t}\n\tencode(_: Uint8Array): Uint8Array {\n\t\tthrow new Error(\"Not implemented\");\n\t}\n\tdecode(arr: Uint8Array): Uint8Array {\n\t\treturn new Uint8Array(arr.buffer, arr.byteOffset, arr.byteLength - 4);\n\t}\n}\n", "import { decompress } from \"../util.js\";\n\ninterface GzipCodecConfig {\n\tlevel: number;\n}\n\nexport class GzipCodec {\n\tkind = \"bytes_to_bytes\";\n\n\tstatic fromConfig(_: GzipCodecConfig) {\n\t\treturn new GzipCodec();\n\t}\n\n\tencode(_bytes: Uint8Array): never {\n\t\tthrow new Error(\n\t\t\t\"Gzip encoding is not enabled by default. Please register a custom codec with `numcodecs/gzip`.\",\n\t\t);\n\t}\n\n\tasync decode(bytes: Uint8Array): Promise<Uint8Array> {\n\t\tconst buffer = await decompress(bytes, { format: \"gzip\" });\n\t\treturn new Uint8Array(buffer);\n\t}\n}\n", "// Adapted from https://github.com/hms-dbmi/vizarr/blob/5b0e3ea6fbb42d19d0e38e60e49bb73d1aca0693/src/utils.ts#L26\nimport type { Chunk, ObjectType } from \"../metadata.js\";\nimport { assert, get_strides, json_decode_object } from \"../util.js\";\n\ntype EncoderConfig = {\n\tencoding?: \"utf-8\";\n\tskipkeys?: boolean;\n\tensure_ascii?: boolean;\n\tcheck_circular?: boolean;\n\tallow_nan?: boolean;\n\tsort_keys?: boolean;\n\tindent?: number;\n\tseparators?: [string, string];\n};\ntype DecoderConfig = {\n\tstrict?: boolean;\n};\n\ntype JsonCodecConfig = EncoderConfig & DecoderConfig;\n\n// TODO: Correctly type the replacer function\n// biome-ignore lint/suspicious/noExplicitAny: Really complex type\ntype ReplacerFunction = (key: string | number, value: any) => any;\n\n// Reference: https://stackoverflow.com/a/21897413\nfunction throw_on_nan_replacer(_key: string | number, value: number): number {\n\tassert(\n\t\t!Number.isNaN(value),\n\t\t\"JsonCodec allow_nan is false but NaN was encountered during encoding.\",\n\t);\n\tassert(\n\t\tvalue !== Number.POSITIVE_INFINITY,\n\t\t\"JsonCodec allow_nan is false but Infinity was encountered during encoding.\",\n\t);\n\tassert(\n\t\tvalue !== Number.NEGATIVE_INFINITY,\n\t\t\"JsonCodec allow_nan is false but -Infinity was encountered during encoding.\",\n\t);\n\treturn value;\n}\n\n// Reference: https://gist.github.com/davidfurlong/463a83a33b70a3b6618e97ec9679e490\nfunction sort_keys_replacer(\n\t_key: string | number,\n\tvalue: Record<string, unknown>,\n) {\n\treturn value instanceof Object && !Array.isArray(value)\n\t\t? Object.keys(value)\n\t\t\t\t.sort()\n\t\t\t\t.reduce(\n\t\t\t\t\t(sorted, key: string | number) => {\n\t\t\t\t\t\tsorted[key] = value[key];\n\t\t\t\t\t\treturn sorted;\n\t\t\t\t\t},\n\t\t\t\t\t{} as Record<string, unknown>,\n\t\t\t\t)\n\t\t: value;\n}\n\nexport class JsonCodec {\n\tkind = \"array_to_bytes\";\n\n\t#encoder_config: EncoderConfig;\n\t#decoder_config: DecoderConfig;\n\n\tconstructor(public configuration: JsonCodecConfig = {}) {\n\t\t// Reference: https://github.com/zarr-developers/numcodecs/blob/0878717a3613d91a453fe3d3716aa9c67c023a8b/numcodecs/json.py#L36\n\t\tconst {\n\t\t\tencoding = \"utf-8\",\n\t\t\tskipkeys = false,\n\t\t\tensure_ascii = true,\n\t\t\tcheck_circular = true,\n\t\t\tallow_nan = true,\n\t\t\tsort_keys = true,\n\t\t\tindent,\n\t\t\tstrict = true,\n\t\t} = configuration;\n\n\t\tlet separators = configuration.separators;\n\t\tif (!separators) {\n\t\t\t// ensure separators are explicitly specified, and consistent behaviour across\n\t\t\t// Python versions, and most compact representation if indent is None\n\t\t\tif (!indent) {\n\t\t\t\tseparators = [\",\", \":\"];\n\t\t\t} else {\n\t\t\t\tseparators = [\", \", \": \"];\n\t\t\t}\n\t\t}\n\n\t\tthis.#encoder_config = {\n\t\t\tencoding,\n\t\t\tskipkeys,\n\t\t\tensure_ascii,\n\t\t\tcheck_circular,\n\t\t\tallow_nan,\n\t\t\tindent,\n\t\t\tseparators,\n\t\t\tsort_keys,\n\t\t};\n\t\tthis.#decoder_config = { strict };\n\t}\n\tstatic fromConfig(configuration: JsonCodecConfig) {\n\t\treturn new JsonCodec(configuration);\n\t}\n\n\tencode(buf: Chunk<ObjectType>): Uint8Array {\n\t\tconst {\n\t\t\tindent,\n\t\t\tencoding,\n\t\t\tensure_ascii,\n\t\t\tcheck_circular,\n\t\t\tallow_nan,\n\t\t\tsort_keys,\n\t\t} = this.#encoder_config;\n\t\tassert(\n\t\t\tencoding === \"utf-8\",\n\t\t\t\"JsonCodec does not yet support non-utf-8 encoding.\",\n\t\t);\n\t\tconst replacer_functions: ReplacerFunction[] = [];\n\n\t\t// By default, for JSON.stringify,\n\t\t// a TypeError will be thrown if one attempts to encode an object with circular references\n\t\tassert(\n\t\t\tcheck_circular,\n\t\t\t\"JsonCodec does not yet support skipping the check for circular references during encoding.\",\n\t\t);\n\n\t\tif (!allow_nan) {\n\t\t\t// Throw if NaN/Infinity/-Infinity are encountered during encoding.\n\t\t\treplacer_functions.push(throw_on_nan_replacer);\n\t\t}\n\t\tif (sort_keys) {\n\t\t\t// We can ensure keys are sorted but not really the opposite since\n\t\t\t// there is no guarantee of key ordering in JS.\n\t\t\treplacer_functions.push(sort_keys_replacer);\n\t\t}\n\n\t\tconst items = Array.from(buf.data);\n\t\titems.push(\"|O\");\n\t\titems.push(buf.shape);\n\n\t\tlet replacer: ReplacerFunction | undefined;\n\t\tif (replacer_functions.length) {\n\t\t\treplacer = (key, value) => {\n\t\t\t\tlet new_value = value;\n\t\t\t\tfor (let sub_replacer of replacer_functions) {\n\t\t\t\t\tnew_value = sub_replacer(key, new_value);\n\t\t\t\t}\n\t\t\t\treturn new_value;\n\t\t\t};\n\t\t}\n\t\tlet json_str = JSON.stringify(items, replacer, indent);\n\n\t\tif (ensure_ascii) {\n\t\t\t// If ensure_ascii is true (the default), the output is guaranteed\n\t\t\t// to have all incoming non-ASCII characters escaped.\n\t\t\t// If ensure_ascii is false, these characters will be output as-is.\n\t\t\t// Reference: https://stackoverflow.com/a/31652607\n\t\t\tjson_str = json_str.replace(/[\\u007F-\\uFFFF]/g, (chr) => {\n\t\t\t\tconst full_str = `0000${chr.charCodeAt(0).toString(16)}`;\n\t\t\t\tconst sub_str = full_str.substring(full_str.length - 4);\n\t\t\t\treturn `\\\\u${sub_str}`;\n\t\t\t});\n\t\t}\n\t\treturn new TextEncoder().encode(json_str);\n\t}\n\n\tdecode(bytes: Uint8Array): Chunk<ObjectType> {\n\t\tconst { strict } = this.#decoder_config;\n\t\t// (i.e., allowing control characters inside strings)\n\t\tassert(strict, \"JsonCodec does not yet support non-strict decoding.\");\n\n\t\tconst items = json_decode_object(bytes);\n\t\tconst shape = items.pop();\n\t\titems.pop(); // Pop off dtype (unused)\n\n\t\t// O-d case\n\t\tassert(shape, \"0D not implemented for JsonCodec.\");\n\t\tconst stride = get_strides(shape, \"C\");\n\t\tconst data = items;\n\t\treturn { data, shape, stride };\n\t}\n}\n", "import type {\n\tChunk,\n\tDataType,\n\tScalar,\n\tTypedArray,\n\tTypedArrayConstructor,\n} from \"../metadata.js\";\nimport {\n\tBoolArray,\n\tByteStringArray,\n\tUnicodeStringArray,\n} from \"../typedarray.js\";\nimport { assert, get_strides } from \"../util.js\";\n\ntype TypedArrayProxy<D extends DataType> = {\n\t[x: number]: Scalar<D>;\n};\n\nfunction proxy<D extends DataType>(arr: TypedArray<D>): TypedArrayProxy<D> {\n\tif (\n\t\tarr instanceof BoolArray ||\n\t\tarr instanceof ByteStringArray ||\n\t\tarr instanceof UnicodeStringArray\n\t) {\n\t\t// @ts-expect-error - TS cannot infer arr is a TypedArrayProxy<D>\n\t\tconst arrp: TypedArrayProxy<D> = new Proxy(arr, {\n\t\t\tget(target, prop) {\n\t\t\t\treturn target.get(Number(prop));\n\t\t\t},\n\t\t\tset(target, prop, value) {\n\t\t\t\t// @ts-expect-error - value is OK\n\t\t\t\ttarget.set(Number(prop), value);\n\t\t\t\treturn true;\n\t\t\t},\n\t\t});\n\t\treturn arrp;\n\t}\n\t// @ts-expect-error - TS cannot infer arr is a TypedArrayProxy<D>\n\treturn arr;\n}\n\nfunction empty_like<D extends DataType>(\n\tchunk: Chunk<D>,\n\torder: Order,\n): Chunk<D> {\n\tlet data: TypedArray<D>;\n\tif (\n\t\tchunk.data instanceof ByteStringArray ||\n\t\tchunk.data instanceof UnicodeStringArray\n\t) {\n\t\tdata = new (chunk.constructor as TypedArrayConstructor<D>)(\n\t\t\t// @ts-expect-error\n\t\t\tchunk.data.length,\n\t\t\tchunk.data.chars,\n\t\t);\n\t} else {\n\t\tdata = new (chunk.constructor as TypedArrayConstructor<D>)(\n\t\t\tchunk.data.length,\n\t\t);\n\t}\n\treturn {\n\t\tdata,\n\t\tshape: chunk.shape,\n\t\tstride: get_strides(chunk.shape, order),\n\t};\n}\n\nfunction convert_array_order<D extends DataType>(\n\tsrc: Chunk<D>,\n\ttarget: Order,\n): Chunk<D> {\n\tlet out = empty_like(src, target);\n\tlet n_dims = src.shape.length;\n\tlet size = src.data.length;\n\tlet index = Array(n_dims).fill(0);\n\n\tlet src_data = proxy(src.data);\n\tlet out_data = proxy(out.data);\n\n\tfor (let src_idx = 0; src_idx < size; src_idx++) {\n\t\tlet out_idx = 0;\n\t\tfor (let dim = 0; dim < n_dims; dim++) {\n\t\t\tout_idx += index[dim] * out.stride[dim];\n\t\t}\n\t\tout_data[out_idx] = src_data[src_idx];\n\n\t\tindex[0] += 1;\n\t\tfor (let dim = 0; dim < n_dims; dim++) {\n\t\t\tif (index[dim] === src.shape[dim]) {\n\t\t\t\tif (dim + 1 === n_dims) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tindex[dim] = 0;\n\t\t\t\tindex[dim + 1] += 1;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn out;\n}\n\n/** Determine the memory order (axis permutation) for a chunk */\nfunction get_order(chunk: Chunk<DataType>): number[] {\n\tlet rank = chunk.shape.length;\n\tassert(\n\t\trank === chunk.stride.length,\n\t\t\"Shape and stride must have the same length.\",\n\t);\n\treturn chunk.stride\n\t\t.map((s, i) => ({ stride: s, index: i }))\n\t\t.sort((a, b) => b.stride - a.stride)\n\t\t.map((entry) => entry.index);\n}\n\nfunction matches_order(chunk: Chunk<DataType>, target: Order) {\n\tlet source = get_order(chunk);\n\tassert(source.length === target.length, \"Orders must match\");\n\treturn source.every((dim, i) => dim === target[i]);\n}\n\ntype Order = \"C\" | \"F\" | Array<number>;\n\nexport class TransposeCodec {\n\tkind = \"array_to_array\";\n\t#order: Array<number>;\n\t#inverseOrder: Array<number>;\n\n\tconstructor(configuration: { order?: Order }, meta: { shape: number[] }) {\n\t\tlet value = configuration.order ?? \"C\";\n\t\tlet rank = meta.shape.length;\n\t\tlet order = new Array<number>(rank);\n\t\tlet inverseOrder = new Array<number>(rank);\n\n\t\tif (value === \"C\") {\n\t\t\tfor (let i = 0; i < rank; ++i) {\n\t\t\t\torder[i] = i;\n\t\t\t\tinverseOrder[i] = i;\n\t\t\t}\n\t\t} else if (value === \"F\") {\n\t\t\tfor (let i = 0; i < rank; ++i) {\n\t\t\t\torder[i] = rank - i - 1;\n\t\t\t\tinverseOrder[i] = rank - i - 1;\n\t\t\t}\n\t\t} else {\n\t\t\torder = value;\n\t\t\torder.forEach((x, i) => {\n\t\t\t\tassert(\n\t\t\t\t\tinverseOrder[x] === undefined,\n\t\t\t\t\t`Invalid permutation: ${JSON.stringify(value)}`,\n\t\t\t\t);\n\t\t\t\tinverseOrder[x] = i;\n\t\t\t});\n\t\t}\n\n\t\tthis.#order = order;\n\t\tthis.#inverseOrder = inverseOrder;\n\t}\n\n\tstatic fromConfig(\n\t\tconfiguration: { order: Order },\n\t\tmeta: { shape: number[] },\n\t) {\n\t\treturn new TransposeCodec(configuration, meta);\n\t}\n\n\tencode<D extends DataType>(arr: Chunk<D>): Chunk<D> {\n\t\tif (matches_order(arr, this.#inverseOrder)) {\n\t\t\t// can skip making a copy\n\t\t\treturn arr;\n\t\t}\n\t\treturn convert_array_order(arr, this.#inverseOrder);\n\t}\n\n\tdecode<D extends DataType>(arr: Chunk<D>): Chunk<D> {\n\t\treturn {\n\t\t\tdata: arr.data,\n\t\t\tshape: arr.shape,\n\t\t\tstride: get_strides(arr.shape, this.#order),\n\t\t};\n\t}\n}\n", "import type { Chunk, ObjectType } from \"../metadata.js\";\nimport { get_strides } from \"../util.js\";\n\nexport class VLenUTF8 {\n\treadonly kind = \"array_to_bytes\";\n\t#shape: number[];\n\t#strides: number[];\n\n\tconstructor(shape: number[]) {\n\t\tthis.#shape = shape;\n\t\tthis.#strides = get_strides(shape, \"C\");\n\t}\n\tstatic fromConfig(_: unknown, meta: { shape: number[] }) {\n\t\treturn new VLenUTF8(meta.shape);\n\t}\n\n\tencode(_chunk: Chunk<ObjectType>): Uint8Array {\n\t\tthrow new Error(\"Method not implemented.\");\n\t}\n\n\tdecode(bytes: Uint8Array): Chunk<ObjectType> {\n\t\tlet decoder = new TextDecoder();\n\t\tlet view = new DataView(bytes.buffer);\n\t\tlet data = Array(view.getUint32(0, true));\n\t\tlet pos = 4;\n\t\tfor (let i = 0; i < data.length; i++) {\n\t\t\tlet item_length = view.getUint32(pos, true);\n\t\t\tpos += 4;\n\t\t\tdata[i] = decoder.decode(\n\t\t\t\t(bytes.buffer as ArrayBuffer).slice(pos, pos + item_length),\n\t\t\t);\n\t\t\tpos += item_length;\n\t\t}\n\t\treturn { data, shape: this.#shape, stride: this.#strides };\n\t}\n}\n", "import { decompress } from \"../util.js\";\n\ninterface ZlibCodecConfig {\n\tlevel: number;\n}\n\nexport class ZlibCodec {\n\tkind = \"bytes_to_bytes\";\n\n\tstatic fromConfig(_: ZlibCodecConfig) {\n\t\treturn new ZlibCodec();\n\t}\n\n\tencode(_bytes: Uint8Array): never {\n\t\tthrow new Error(\n\t\t\t\"Zlib encoding is not enabled by default. Please register a codec with `numcodecs/zlib`.\",\n\t\t);\n\t}\n\n\tasync decode(bytes: Uint8Array): Promise<Uint8Array> {\n\t\tconst buffer = await decompress(bytes, { format: \"deflate\" });\n\t\treturn new Uint8Array(buffer);\n\t}\n}\n", "import type { Codec as _Codec } from \"numcodecs\";\nimport { BitroundCodec } from \"./codecs/bitround.js\";\nimport { BytesCodec } from \"./codecs/bytes.js\";\nimport { Crc32cCodec } from \"./codecs/crc32c.js\";\nimport { GzipCodec } from \"./codecs/gzip.js\";\nimport { JsonCodec } from \"./codecs/json2.js\";\nimport { TransposeCodec } from \"./codecs/transpose.js\";\nimport { VLenUTF8 } from \"./codecs/vlen-utf8.js\";\nimport { ZlibCodec } from \"./codecs/zlib.js\";\nimport type { Chunk, CodecMetadata, DataType } from \"./metadata.js\";\nimport { assert } from \"./util.js\";\n\ntype ChunkMetadata<D extends DataType> = {\n\tdata_type: D;\n\tshape: number[];\n\tcodecs: CodecMetadata[];\n};\n\ntype CodecEntry = {\n\tfromConfig: (config: unknown, meta: ChunkMetadata<DataType>) => Codec;\n\tkind?: \"array_to_array\" | \"array_to_bytes\" | \"bytes_to_bytes\";\n};\n\ntype Codec = _Codec & { kind: CodecEntry[\"kind\"] };\n\nfunction create_default_registry(): Map<string, () => Promise<CodecEntry>> {\n\treturn new Map()\n\t\t.set(\"blosc\", () => import(\"numcodecs/blosc\").then((m) => m.default))\n\t\t.set(\"lz4\", () => import(\"numcodecs/lz4\").then((m) => m.default))\n\t\t.set(\"zstd\", () => import(\"numcodecs/zstd\").then((m) => m.default))\n\t\t.set(\"gzip\", () => GzipCodec)\n\t\t.set(\"zlib\", () => ZlibCodec)\n\t\t.set(\"transpose\", () => TransposeCodec)\n\t\t.set(\"bytes\", () => BytesCodec)\n\t\t.set(\"crc32c\", () => Crc32cCodec)\n\t\t.set(\"vlen-utf8\", () => VLenUTF8)\n\t\t.set(\"json2\", () => JsonCodec)\n\t\t.set(\"bitround\", () => BitroundCodec);\n}\n\nexport const registry: Map<string, () => Promise<CodecEntry>> =\n\tcreate_default_registry();\n\nexport function create_codec_pipeline<Dtype extends DataType>(\n\tchunk_metadata: ChunkMetadata<Dtype>,\n): {\n\tencode(chunk: Chunk<Dtype>): Promise<Uint8Array>;\n\tdecode(bytes: Uint8Array): Promise<Chunk<Dtype>>;\n} {\n\tlet codecs: Awaited<ReturnType<typeof load_codecs>>;\n\treturn {\n\t\tasync encode(chunk: Chunk<Dtype>): Promise<Uint8Array> {\n\t\t\tif (!codecs) codecs = await load_codecs(chunk_metadata);\n\t\t\tfor (const codec of codecs.array_to_array) {\n\t\t\t\tchunk = await codec.encode(chunk);\n\t\t\t}\n\t\t\tlet bytes = await codecs.array_to_bytes.encode(chunk);\n\t\t\tfor (const codec of codecs.bytes_to_bytes) {\n\t\t\t\tbytes = await codec.encode(bytes);\n\t\t\t}\n\t\t\treturn bytes;\n\t\t},\n\t\tasync decode(bytes: Uint8Array): Promise<Chunk<Dtype>> {\n\t\t\tif (!codecs) codecs = await load_codecs(chunk_metadata);\n\t\t\tfor (let i = codecs.bytes_to_bytes.length - 1; i >= 0; i--) {\n\t\t\t\tbytes = await codecs.bytes_to_bytes[i].decode(bytes);\n\t\t\t}\n\t\t\tlet chunk = await codecs.array_to_bytes.decode(bytes);\n\t\t\tfor (let i = codecs.array_to_array.length - 1; i >= 0; i--) {\n\t\t\t\tchunk = await codecs.array_to_array[i].decode(chunk);\n\t\t\t}\n\t\t\treturn chunk;\n\t\t},\n\t};\n}\n\ntype ArrayToArrayCodec<D extends DataType> = {\n\tencode: (data: Chunk<D>) => Promise<Chunk<D>> | Chunk<D>;\n\tdecode: (data: Chunk<D>) => Promise<Chunk<D>> | Chunk<D>;\n};\n\ntype ArrayToBytesCodec<D extends DataType> = {\n\tencode: (data: Chunk<D>) => Promise<Uint8Array> | Uint8Array;\n\tdecode: (data: Uint8Array) => Promise<Chunk<D>> | Chunk<D>;\n};\n\ntype BytesToBytesCodec = {\n\tencode: (data: Uint8Array) => Promise<Uint8Array>;\n\tdecode: (data: Uint8Array) => Promise<Uint8Array>;\n};\n\nasync function load_codecs<D extends DataType>(chunk_meta: ChunkMetadata<D>) {\n\tlet promises = chunk_meta.codecs.map(async (meta) => {\n\t\tlet Codec = await registry.get(meta.name)?.();\n\t\tassert(Codec, `Unknown codec: ${meta.name}`);\n\t\treturn { Codec, meta };\n\t});\n\tlet array_to_array: ArrayToArrayCodec<D>[] = [];\n\tlet array_to_bytes: ArrayToBytesCodec<D> | undefined;\n\tlet bytes_to_bytes: BytesToBytesCodec[] = [];\n\tfor await (let { Codec, meta } of promises) {\n\t\tlet codec = Codec.fromConfig(meta.configuration, chunk_meta);\n\t\tswitch (codec.kind) {\n\t\t\tcase \"array_to_array\":\n\t\t\t\tarray_to_array.push(codec as unknown as ArrayToArrayCodec<D>);\n\t\t\t\tbreak;\n\t\t\tcase \"array_to_bytes\":\n\t\t\t\tarray_to_bytes = codec as unknown as ArrayToBytesCodec<D>;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbytes_to_bytes.push(codec as unknown as BytesToBytesCodec);\n\t\t}\n\t}\n\tif (!array_to_bytes) {\n\t\tassert(\n\t\t\tis_typed_array_like_meta(chunk_meta),\n\t\t\t`Cannot encode ${chunk_meta.data_type} to bytes without a codec`,\n\t\t);\n\t\tarray_to_bytes = BytesCodec.fromConfig({ endian: \"little\" }, chunk_meta);\n\t}\n\treturn { array_to_array, array_to_bytes, bytes_to_bytes };\n}\n\nfunction is_typed_array_like_meta<D extends DataType>(\n\tmeta: ChunkMetadata<D>,\n): meta is ChunkMetadata<Exclude<D, \"v2:object\">> {\n\treturn meta.data_type !== \"v2:object\";\n}\n", "export class NodeNotFoundError extends Error {\n\tconstructor(context: string, options: { cause?: Error } = {}) {\n\t\tsuper(`Node not found: ${context}`, options);\n\t\tthis.name = \"NodeNotFoundError\";\n\t}\n}\n\nexport class KeyError extends Error {\n\tconstructor(path: string) {\n\t\tsuper(`Missing key: ${path}`);\n\t\tthis.name = \"KeyError\";\n\t}\n}\n", "import type { AbsolutePath, Readable } from \"@zarrita/storage\";\nimport { KeyError, NodeNotFoundError } from \"./errors.js\";\nimport type {\n\tArrayMetadata,\n\tArrayMetadataV2,\n\tAttributes,\n\tGroupMetadata,\n\tGroupMetadataV2,\n} from \"./metadata.js\";\nimport {\n\tassert,\n\tjson_decode_object,\n\tjson_encode_object,\n\trethrow_unless,\n} from \"./util.js\";\n\ntype ConsolidatedMetadata = {\n\tmetadata: Record<string, ArrayMetadataV2 | GroupMetadataV2>;\n\tzarr_consolidated_format: 1;\n};\n\n/**\n * Represents a read-only store that can list its contents.\n */\nexport interface Listable<Store extends Readable> {\n\t/** Get the bytes at a given path. */\n\tget: (...args: Parameters<Store[\"get\"]>) => Promise<Uint8Array | undefined>;\n\t/** Get a byte range at a given path. */\n\tgetRange: Store[\"getRange\"];\n\t/** List the contents of the store. */\n\tcontents(): { path: AbsolutePath; kind: \"array\" | \"group\" }[];\n}\n\nasync function get_consolidated_metadata(\n\tstore: Readable,\n\tmetadataKeyOption: string | undefined,\n): Promise<ConsolidatedMetadata> {\n\tconst metadataKey = metadataKeyOption ?? \".zmetadata\";\n\tlet bytes = await store.get(`/${metadataKey}`);\n\tif (!bytes) {\n\t\tthrow new NodeNotFoundError(\"v2 consolidated metadata\", {\n\t\t\tcause: new KeyError(`/${metadataKey}`),\n\t\t});\n\t}\n\tlet meta: ConsolidatedMetadata = json_decode_object(bytes);\n\tassert(\n\t\tmeta.zarr_consolidated_format === 1,\n\t\t\"Unsupported consolidated format.\",\n\t);\n\treturn meta;\n}\n\ntype Metadata =\n\t| ArrayMetadataV2\n\t| GroupMetadataV2\n\t| ArrayMetadata\n\t| GroupMetadata\n\t| Attributes;\n\nfunction is_meta_key(key: string): boolean {\n\treturn (\n\t\tkey.endsWith(\".zarray\") ||\n\t\tkey.endsWith(\".zgroup\") ||\n\t\tkey.endsWith(\".zattrs\") ||\n\t\tkey.endsWith(\"zarr.json\")\n\t);\n}\n\nfunction is_v3(meta: Metadata): meta is ArrayMetadata | GroupMetadata {\n\treturn \"zarr_format\" in meta && meta.zarr_format === 3;\n}\n\n/** Options for {@linkcode withConsolidated} and {@linkcode tryWithConsolidated}. */\nexport interface WithConsolidatedOptions {\n\t/**\n\t * Key to read consolidated metadata from.\n\t *\n\t * @default {\".zmetadata\"}\n\t */\n\treadonly metadataKey?: string;\n}\n\n/**\n * Open a consolidated store.\n *\n * This will open a store with Zarr v2 consolidated metadata (`.zmetadata`).\n * @see {@link https://zarr.readthedocs.io/en/stable/spec/v2.html#consolidated-metadata}\n *\n * @param store The store to open.\n * @param opts Options object.\n * @returns A listable store.\n *\n * @example\n * ```js\n * let store = await withConsolidated(\n *   new zarr.FetchStore(\"https://my-bucket.s3.amazonaws.com\");\n * );\n * store.contents(); // [{ path: \"/\", kind: \"group\" }, { path: \"/foo\", kind: \"array\" }, ...]\n * let grp = zarr.open(store); // Open the root group.\n * let foo = zarr.open(grp.resolve(contents[1].path)); // Open the foo array\n * ```\n */\nexport async function withConsolidated<Store extends Readable>(\n\tstore: Store,\n\topts: WithConsolidatedOptions = {},\n): Promise<Listable<Store>> {\n\tlet v2_meta = await get_consolidated_metadata(store, opts.metadataKey);\n\tlet known_meta: Record<AbsolutePath, Metadata> = {};\n\tfor (let [key, value] of Object.entries(v2_meta.metadata)) {\n\t\tknown_meta[`/${key}`] = value;\n\t}\n\n\treturn {\n\t\tasync get(\n\t\t\t...args: Parameters<Store[\"get\"]>\n\t\t): Promise<Uint8Array | undefined> {\n\t\t\tlet [key, opts] = args;\n\t\t\tif (known_meta[key]) {\n\t\t\t\treturn json_encode_object(known_meta[key]);\n\t\t\t}\n\t\t\tlet maybe_bytes = await store.get(key, opts);\n\t\t\tif (is_meta_key(key) && maybe_bytes) {\n\t\t\t\tlet meta = json_decode_object(maybe_bytes);\n\t\t\t\tknown_meta[key] = meta;\n\t\t\t}\n\t\t\treturn maybe_bytes;\n\t\t},\n\t\t// Delegate range requests to the underlying store.\n\t\t// Note: Supporting range requests for consolidated metadata is possible\n\t\t// but unlikely to be useful enough to justify the effort.\n\t\tgetRange: store.getRange?.bind(store),\n\t\tcontents(): { path: AbsolutePath; kind: \"array\" | \"group\" }[] {\n\t\t\tlet contents: { path: AbsolutePath; kind: \"array\" | \"group\" }[] = [];\n\t\t\tfor (let [key, value] of Object.entries(known_meta)) {\n\t\t\t\tlet parts = key.split(\"/\");\n\t\t\t\tlet filename = parts.pop();\n\t\t\t\tlet path = (parts.join(\"/\") || \"/\") as AbsolutePath;\n\t\t\t\tif (filename === \".zarray\") contents.push({ path, kind: \"array\" });\n\t\t\t\tif (filename === \".zgroup\") contents.push({ path, kind: \"group\" });\n\t\t\t\tif (is_v3(value)) {\n\t\t\t\t\tcontents.push({ path, kind: value.node_type });\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn contents;\n\t\t},\n\t};\n}\n\n/**\n * Try to open a consolidated store, but fall back to the original store if the\n * consolidated metadata is missing.\n *\n * Provides a convenient way to open a store that may or may not have consolidated,\n * returning a consistent interface for both cases. Ideal for usage senarios with\n * known access paths, since store with consolidated metadata do not incur\n * additional network requests when accessing underlying groups and arrays.\n *\n * @param store The store to open.\n * @param opts Options to pass to withConsolidated.\n * @returns A listable store.\n */\nexport async function tryWithConsolidated<Store extends Readable>(\n\tstore: Store,\n\topts: WithConsolidatedOptions = {},\n): Promise<Listable<Store> | Store> {\n\treturn withConsolidated(store, opts).catch((error: unknown) => {\n\t\trethrow_unless(error, NodeNotFoundError);\n\t\treturn store;\n\t});\n}\n", "import type { Readable } from \"@zarrita/storage\";\nimport { create_codec_pipeline } from \"../codecs.js\";\nimport type { Location } from \"../hierarchy.js\";\nimport type { Chunk } from \"../metadata.js\";\nimport { assert, type ShardingCodecMetadata } from \"../util.js\";\n\nconst MAX_BIG_UINT = 18446744073709551615n;\n\nexport function create_sharded_chunk_getter<Store extends Readable>(\n\tlocation: Location<Store>,\n\tshard_shape: number[],\n\tencode_shard_key: (coord: number[]) => string,\n\tsharding_config: ShardingCodecMetadata[\"configuration\"],\n) {\n\tassert(location.store.getRange, \"Store does not support range requests\");\n\tlet get_range = location.store.getRange.bind(location.store);\n\tlet index_shape = shard_shape.map(\n\t\t(d, i) => d / sharding_config.chunk_shape[i],\n\t);\n\tlet index_codec = create_codec_pipeline({\n\t\tdata_type: \"uint64\",\n\t\tshape: [...index_shape, 2],\n\t\tcodecs: sharding_config.index_codecs,\n\t});\n\n\tlet cache: Record<string, Chunk<\"uint64\"> | null> = {};\n\treturn async (chunk_coord: number[]) => {\n\t\tlet shard_coord = chunk_coord.map((d, i) => Math.floor(d / index_shape[i]));\n\t\tlet shard_path = location.resolve(encode_shard_key(shard_coord)).path;\n\n\t\tlet index: Chunk<\"uint64\"> | null;\n\t\tif (shard_path in cache) {\n\t\t\tindex = cache[shard_path];\n\t\t} else {\n\t\t\tlet checksum_size = 4;\n\t\t\tlet index_size = 16 * index_shape.reduce((a, b) => a * b, 1);\n\t\t\tlet bytes = await get_range(shard_path, {\n\t\t\t\tsuffixLength: index_size + checksum_size,\n\t\t\t});\n\t\t\tindex = cache[shard_path] = bytes\n\t\t\t\t? await index_codec.decode(bytes)\n\t\t\t\t: null;\n\t\t}\n\n\t\tif (index === null) {\n\t\t\treturn undefined;\n\t\t}\n\n\t\tlet { data, shape, stride } = index;\n\t\tlet linear_offset = chunk_coord\n\t\t\t.map((d, i) => d % shape[i])\n\t\t\t.reduce((acc, sel, idx) => acc + sel * stride[idx], 0);\n\n\t\tlet offset = data[linear_offset];\n\t\tlet length = data[linear_offset + 1];\n\t\t// write null chunk when 2^64-1 indicates fill value\n\t\tif (offset === MAX_BIG_UINT && length === MAX_BIG_UINT) {\n\t\t\treturn undefined;\n\t\t}\n\t\treturn get_range(shard_path, {\n\t\t\toffset: Number(offset),\n\t\t\tlength: Number(length),\n\t\t});\n\t};\n}\n", "import type { AbsolutePath, Readable } from \"@zarrita/storage\";\nimport { create_sharded_chunk_getter } from \"./codecs/sharding.js\";\nimport { create_codec_pipeline } from \"./codecs.js\";\nimport type {\n\tArrayMetadata,\n\tAttributes,\n\tChunk,\n\tCodecMetadata,\n\tDataType,\n\tGroupMetadata,\n\tScalar,\n\tTypedArrayConstructor,\n} from \"./metadata.js\";\nimport {\n\tcreate_chunk_key_encoder,\n\ttype DataTypeQuery,\n\tensure_correct_scalar,\n\tget_ctr,\n\tget_strides,\n\tis_dtype,\n\tis_sharding_codec,\n\ttype NarrowDataType,\n} from \"./util.js\";\n\nexport class Location<Store> {\n\tconstructor(\n\t\tpublic readonly store: Store,\n\t\tpublic readonly path: AbsolutePath = \"/\",\n\t) {}\n\n\tresolve(path: string): Location<Store> {\n\t\t// reuse URL resolution logic built into the browser\n\t\t// handles relative paths, absolute paths, etc.\n\t\tlet root = new URL(\n\t\t\t`file://${this.path.endsWith(\"/\") ? this.path : `${this.path}/`}`,\n\t\t);\n\t\treturn new Location(\n\t\t\tthis.store,\n\t\t\tdecodeURIComponent(new URL(path, root).pathname) as AbsolutePath,\n\t\t);\n\t}\n}\n\nexport function root<Store>(store: Store): Location<Store>;\nexport function root(): Location<Map<string, Uint8Array>>;\nexport function root<Store>(\n\tstore?: Store,\n): Location<Store | Map<string, Uint8Array>> {\n\treturn new Location(store ?? new Map());\n}\n\nexport class Group<Store extends Readable> extends Location<Store> {\n\treadonly kind = \"group\";\n\t#metadata: GroupMetadata;\n\tconstructor(store: Store, path: AbsolutePath, metadata: GroupMetadata) {\n\t\tsuper(store, path);\n\t\tthis.#metadata = metadata;\n\t}\n\tget attrs(): Attributes {\n\t\treturn this.#metadata.attributes;\n\t}\n}\n\nfunction get_array_order(\n\tcodecs: CodecMetadata[],\n): \"C\" | \"F\" | globalThis.Array<number> {\n\tconst maybe_transpose_codec = codecs.find((c) => c.name === \"transpose\");\n\t// @ts-expect-error - TODO: Should validate?\n\treturn maybe_transpose_codec?.configuration?.order ?? \"C\";\n}\n\nconst CONTEXT_MARKER = Symbol(\"zarrita.context\");\n\nexport function get_context<T>(obj: { [CONTEXT_MARKER]: T }): T {\n\treturn obj[CONTEXT_MARKER];\n}\n\nfunction create_context<Store extends Readable, D extends DataType>(\n\tlocation: Location<Readable>,\n\tmetadata: ArrayMetadata<D>,\n): ArrayContext<Store, D> {\n\tlet { configuration } = metadata.codecs.find(is_sharding_codec) ?? {};\n\tlet shared_context = {\n\t\tencode_chunk_key: create_chunk_key_encoder(metadata.chunk_key_encoding),\n\t\tTypedArray: get_ctr(metadata.data_type),\n\t\tfill_value: metadata.fill_value,\n\t};\n\n\tif (configuration) {\n\t\tlet native_order = get_array_order(configuration.codecs);\n\t\treturn {\n\t\t\t...shared_context,\n\t\t\tkind: \"sharded\",\n\t\t\tchunk_shape: configuration.chunk_shape,\n\t\t\tcodec: create_codec_pipeline({\n\t\t\t\tdata_type: metadata.data_type,\n\t\t\t\tshape: configuration.chunk_shape,\n\t\t\t\tcodecs: configuration.codecs,\n\t\t\t}),\n\t\t\tget_strides(shape: number[]) {\n\t\t\t\treturn get_strides(shape, native_order);\n\t\t\t},\n\t\t\tget_chunk_bytes: create_sharded_chunk_getter(\n\t\t\t\tlocation,\n\t\t\t\tmetadata.chunk_grid.configuration.chunk_shape,\n\t\t\t\tshared_context.encode_chunk_key,\n\t\t\t\tconfiguration,\n\t\t\t),\n\t\t};\n\t}\n\n\tlet native_order = get_array_order(metadata.codecs);\n\treturn {\n\t\t...shared_context,\n\t\tkind: \"regular\",\n\t\tchunk_shape: metadata.chunk_grid.configuration.chunk_shape,\n\t\tcodec: create_codec_pipeline({\n\t\t\tdata_type: metadata.data_type,\n\t\t\tshape: metadata.chunk_grid.configuration.chunk_shape,\n\t\t\tcodecs: metadata.codecs,\n\t\t}),\n\t\tget_strides(shape: number[]) {\n\t\t\treturn get_strides(shape, native_order);\n\t\t},\n\t\tasync get_chunk_bytes(chunk_coords, options) {\n\t\t\tlet chunk_key = shared_context.encode_chunk_key(chunk_coords);\n\t\t\tlet chunk_path = location.resolve(chunk_key).path;\n\t\t\treturn location.store.get(chunk_path, options);\n\t\t},\n\t};\n}\n\n/** For internal use only, and is subject to change. */\ninterface ArrayContext<Store extends Readable, D extends DataType> {\n\tkind: \"sharded\" | \"regular\";\n\t/** The codec pipeline for this array. */\n\tcodec: ReturnType<typeof create_codec_pipeline<D>>;\n\t/** Encode a chunk key from chunk coordinates. */\n\tencode_chunk_key(chunk_coords: number[]): string;\n\t/** The TypedArray constructor for this array chunks. */\n\tTypedArray: TypedArrayConstructor<D>;\n\t/** A function to get the strides for a given shape, using the array order */\n\tget_strides(shape: number[]): number[];\n\t/** The fill value for this array. */\n\tfill_value: Scalar<D> | null;\n\t/** A function to get the bytes for a given chunk. */\n\tget_chunk_bytes(\n\t\tchunk_coords: number[],\n\t\toptions?: Parameters<Store[\"get\"]>[1],\n\t): Promise<Uint8Array | undefined>;\n\t/** The chunk shape for this array. */\n\tchunk_shape: number[];\n}\n\nexport class Array<\n\tDtype extends DataType,\n\tStore extends Readable = Readable,\n> extends Location<Store> {\n\treadonly kind = \"array\";\n\t#metadata: ArrayMetadata<Dtype>;\n\t[CONTEXT_MARKER]: ArrayContext<Store, Dtype>;\n\n\tconstructor(\n\t\tstore: Store,\n\t\tpath: AbsolutePath,\n\t\tmetadata: ArrayMetadata<Dtype>,\n\t) {\n\t\tsuper(store, path);\n\t\tthis.#metadata = {\n\t\t\t...metadata,\n\t\t\tfill_value: ensure_correct_scalar(metadata),\n\t\t};\n\t\tthis[CONTEXT_MARKER] = create_context(this, metadata);\n\t}\n\n\tget attrs(): Attributes {\n\t\treturn this.#metadata.attributes;\n\t}\n\n\tget shape(): number[] {\n\t\treturn this.#metadata.shape;\n\t}\n\n\tget chunks(): number[] {\n\t\treturn this[CONTEXT_MARKER].chunk_shape;\n\t}\n\n\tget dtype(): Dtype {\n\t\treturn this.#metadata.data_type;\n\t}\n\n\tasync getChunk(\n\t\tchunk_coords: number[],\n\t\toptions?: Parameters<Store[\"get\"]>[1],\n\t): Promise<Chunk<Dtype>> {\n\t\tlet context = this[CONTEXT_MARKER];\n\t\tlet maybe_bytes = await context.get_chunk_bytes(chunk_coords, options);\n\t\tif (!maybe_bytes) {\n\t\t\tlet size = context.chunk_shape.reduce((a, b) => a * b, 1);\n\t\t\tlet data = new context.TypedArray(size);\n\t\t\t// @ts-expect-error: TS can't infer that `fill_value` is union (assumes never) but this is ok\n\t\t\tdata.fill(context.fill_value);\n\t\t\treturn {\n\t\t\t\tdata,\n\t\t\t\tshape: context.chunk_shape,\n\t\t\t\tstride: context.get_strides(context.chunk_shape),\n\t\t\t};\n\t\t}\n\t\treturn context.codec.decode(maybe_bytes);\n\t}\n\n\t/**\n\t * A helper method to narrow `zarr.Array` Dtype.\n\t *\n\t * ```typescript\n\t * let arr: zarr.Array<DataType, FetchStore> = zarr.open(store, { kind: \"array\" });\n\t *\n\t * // Option 1: narrow by scalar type (e.g. \"bool\", \"raw\", \"bigint\", \"number\")\n\t * if (arr.is(\"bigint\")) {\n\t *   // zarr.Array<\"int64\" | \"uint64\", FetchStore>\n\t * }\n\t *\n\t * // Option 3: exact match\n\t * if (arr.is(\"float32\")) {\n\t *   // zarr.Array<\"float32\", FetchStore, \"/\">\n\t * }\n\t * ```\n\t */\n\tis<Query extends DataTypeQuery>(\n\t\tquery: Query,\n\t): this is Array<NarrowDataType<Dtype, Query>, Store> {\n\t\treturn is_dtype(this.dtype, query);\n\t}\n}\n", "import type { Mutable } from \"@zarrita/storage\";\n\nimport { Array, Group, Location } from \"./hierarchy.js\";\nimport type {\n\tArrayMetadata,\n\tAttributes,\n\tCodecMetadata,\n\tDataType,\n\tGroupMetadata,\n\tScalar,\n} from \"./metadata.js\";\nimport { json_encode_object } from \"./util.js\";\n\ninterface CreateGroupOptions {\n\tattributes?: Record<string, unknown>;\n}\n\ninterface CreateArrayOptions<Dtype extends DataType> {\n\tshape: number[];\n\tchunk_shape: number[];\n\tdata_type: Dtype;\n\tcodecs?: CodecMetadata[];\n\tfill_value?: Scalar<Dtype>;\n\tchunk_separator?: \".\" | \"/\";\n\tattributes?: Attributes;\n}\n\nexport async function create<\n\tStore extends Mutable,\n\t_Dtype extends DataType = DataType,\n>(location: Location<Store> | Store): Promise<Group<Store>>;\n\nexport async function create<\n\tStore extends Mutable,\n\t_Dtype extends DataType = DataType,\n>(\n\tlocation: Location<Store> | Store,\n\toptions: CreateGroupOptions,\n): Promise<Group<Store>>;\n\nexport async function create<Store extends Mutable, Dtype extends DataType>(\n\tlocation: Location<Store> | Store,\n\toptions: CreateArrayOptions<Dtype>,\n): Promise<Array<Dtype, Store>>;\n\nexport async function create<Store extends Mutable, Dtype extends DataType>(\n\tlocation: Location<Store> | Store,\n\toptions: CreateArrayOptions<Dtype> | CreateGroupOptions = {},\n): Promise<Array<Dtype, Store> | Group<Store>> {\n\tlet loc = \"store\" in location ? location : new Location(location);\n\tif (\"shape\" in options) {\n\t\tlet arr = await create_array(loc, options);\n\t\treturn arr as Array<Dtype, Store>;\n\t}\n\treturn create_group(loc, options);\n}\n\nasync function create_group<Store extends Mutable>(\n\tlocation: Location<Store>,\n\toptions: CreateGroupOptions = {},\n): Promise<Group<Store>> {\n\tlet metadata = {\n\t\tzarr_format: 3,\n\t\tnode_type: \"group\",\n\t\tattributes: options.attributes ?? {},\n\t} satisfies GroupMetadata;\n\tawait location.store.set(\n\t\tlocation.resolve(\"zarr.json\").path,\n\t\tjson_encode_object(metadata),\n\t);\n\treturn new Group(location.store, location.path, metadata);\n}\n\nasync function create_array<Store extends Mutable, Dtype extends DataType>(\n\tlocation: Location<Store>,\n\toptions: CreateArrayOptions<Dtype>,\n): Promise<Array<DataType, Store>> {\n\tlet metadata = {\n\t\tzarr_format: 3,\n\t\tnode_type: \"array\",\n\t\tshape: options.shape,\n\t\tdata_type: options.data_type,\n\t\tchunk_grid: {\n\t\t\tname: \"regular\",\n\t\t\tconfiguration: {\n\t\t\t\tchunk_shape: options.chunk_shape,\n\t\t\t},\n\t\t},\n\t\tchunk_key_encoding: {\n\t\t\tname: \"default\",\n\t\t\tconfiguration: {\n\t\t\t\tseparator: options.chunk_separator ?? \"/\",\n\t\t\t},\n\t\t},\n\t\tcodecs: options.codecs ?? [],\n\t\tfill_value: options.fill_value ?? null,\n\t\tattributes: options.attributes ?? {},\n\t} satisfies ArrayMetadata<Dtype>;\n\tawait location.store.set(\n\t\tlocation.resolve(\"zarr.json\").path,\n\t\tjson_encode_object(metadata),\n\t);\n\treturn new Array(location.store, location.path, metadata);\n}\n", "import type { ChunkQueue, Indices, Slice } from \"./types.js\";\n\n/** Similar to python's `range` function. Supports positive ranges only. */\nexport function* range(\n\tstart: number,\n\tstop?: number,\n\tstep = 1,\n): Iterable<number> {\n\tif (stop === undefined) {\n\t\tstop = start;\n\t\tstart = 0;\n\t}\n\tfor (let i = start; i < stop; i += step) {\n\t\tyield i;\n\t}\n}\n\n/**\n * python-like itertools.product generator\n * https://gist.github.com/cybercase/db7dde901d7070c98c48\n */\nexport function* product<T extends Array<Iterable<unknown>>>(\n\t...iterables: T\n): IterableIterator<{\n\t[K in keyof T]: T[K] extends Iterable<infer U> ? U : never;\n}> {\n\tif (iterables.length === 0) {\n\t\treturn;\n\t}\n\t// make a list of iterators from the iterables\n\tconst iterators = iterables.map((it) => it[Symbol.iterator]());\n\tconst results = iterators.map((it) => it.next());\n\tif (results.some((r) => r.done)) {\n\t\tthrow new Error(\"Input contains an empty iterator.\");\n\t}\n\tfor (let i = 0; ; ) {\n\t\tif (results[i].done) {\n\t\t\t// reset the current iterator\n\t\t\titerators[i] = iterables[i][Symbol.iterator]();\n\t\t\tresults[i] = iterators[i].next();\n\t\t\t// advance, and exit if we've reached the end\n\t\t\tif (++i >= iterators.length) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t} else {\n\t\t\t// @ts-expect-error - TS can't infer this\n\t\t\tyield results.map(({ value }) => value);\n\t\t\ti = 0;\n\t\t}\n\t\tresults[i] = iterators[i].next();\n\t}\n}\n\n// https://github.com/python/cpython/blob/263c0dd16017613c5ea2fbfc270be4de2b41b5ad/Objects/sliceobject.c#L376-L519\nexport function slice_indices(\n\t{ start, stop, step }: Slice,\n\tlength: number,\n): Indices {\n\tif (step === 0) {\n\t\tthrow new Error(\"slice step cannot be zero\");\n\t}\n\tstep = step ?? 1;\n\tconst step_is_negative = step < 0;\n\n\t/* Find lower and upper bounds for start and stop. */\n\tconst [lower, upper] = step_is_negative ? [-1, length - 1] : [0, length];\n\n\t/* Compute start. */\n\tif (start === null) {\n\t\tstart = step_is_negative ? upper : lower;\n\t} else {\n\t\tif (start < 0) {\n\t\t\tstart += length;\n\t\t\tif (start < lower) {\n\t\t\t\tstart = lower;\n\t\t\t}\n\t\t} else if (start > upper) {\n\t\t\tstart = upper;\n\t\t}\n\t}\n\n\t/* Compute stop. */\n\tif (stop === null) {\n\t\tstop = step_is_negative ? lower : upper;\n\t} else {\n\t\tif (stop < 0) {\n\t\t\tstop += length;\n\t\t\tif (stop < lower) {\n\t\t\t\tstop = lower;\n\t\t\t}\n\t\t} else if (stop > upper) {\n\t\t\tstop = upper;\n\t\t}\n\t}\n\n\treturn [start, stop, step];\n}\n\n/** @category Utilty */\nexport function slice(stop: number | null): Slice;\nexport function slice(\n\tstart: number | null,\n\tstop?: number | null,\n\tstep?: number | null,\n): Slice;\nexport function slice(\n\tstart: number | null,\n\tstop?: number | null,\n\tstep: number | null = null,\n): Slice {\n\tif (stop === undefined) {\n\t\tstop = start;\n\t\tstart = null;\n\t}\n\treturn {\n\t\tstart,\n\t\tstop,\n\t\tstep,\n\t};\n}\n\n/** Built-in \"queue\" for awaiting promises. */\nexport function create_queue(): ChunkQueue {\n\tconst promises: Promise<void>[] = [];\n\treturn {\n\t\tadd: (fn) => promises.push(fn()),\n\t\tonIdle: () => Promise.all(promises),\n\t};\n}\n", "import type { Indices, Slice } from \"./types.js\";\nimport { product, range, slice, slice_indices } from \"./util.js\";\n\nexport class IndexError extends Error {\n\tconstructor(msg: string) {\n\t\tsuper(msg);\n\t\tthis.name = \"IndexError\";\n\t}\n}\n\nfunction err_too_many_indices(\n\tselection: (number | Slice)[],\n\tshape: readonly number[],\n) {\n\tthrow new IndexError(\n\t\t`too many indicies for array; expected ${shape.length}, got ${selection.length}`,\n\t);\n}\n\nfunction err_boundscheck(dim_len: number) {\n\tthrow new IndexError(\n\t\t`index out of bounds for dimension with length ${dim_len}`,\n\t);\n}\n\nfunction err_negative_step() {\n\tthrow new IndexError(\"only slices with step >= 1 are supported\");\n}\n\nfunction check_selection_length(\n\tselection: (number | Slice)[],\n\tshape: readonly number[],\n) {\n\tif (selection.length > shape.length) {\n\t\terr_too_many_indices(selection, shape);\n\t}\n}\n\nexport function normalize_integer_selection(dim_sel: number, dim_len: number) {\n\t// normalize type to int\n\tdim_sel = Math.trunc(dim_sel);\n\t// handle wraparound\n\tif (dim_sel < 0) {\n\t\tdim_sel = dim_len + dim_sel;\n\t}\n\t// handle out of bounds\n\tif (dim_sel >= dim_len || dim_sel < 0) {\n\t\terr_boundscheck(dim_len);\n\t}\n\treturn dim_sel;\n}\n\ninterface IntChunkDimProjection {\n\tdim_chunk_ix: number;\n\tdim_chunk_sel: number;\n}\n\ninterface IntDimIndexerProps {\n\tdim_sel: number;\n\tdim_len: number;\n\tdim_chunk_len: number;\n}\n\nclass IntDimIndexer {\n\tdim_sel: number;\n\tdim_len: number;\n\tdim_chunk_len: number;\n\tnitems: 1;\n\n\tconstructor({ dim_sel, dim_len, dim_chunk_len }: IntDimIndexerProps) {\n\t\t// normalize\n\t\tdim_sel = normalize_integer_selection(dim_sel, dim_len);\n\t\t// store properties\n\t\tthis.dim_sel = dim_sel;\n\t\tthis.dim_len = dim_len;\n\t\tthis.dim_chunk_len = dim_chunk_len;\n\t\tthis.nitems = 1;\n\t}\n\n\t*[Symbol.iterator](): IterableIterator<IntChunkDimProjection> {\n\t\tconst dim_chunk_ix = Math.floor(this.dim_sel / this.dim_chunk_len);\n\t\tconst dim_offset = dim_chunk_ix * this.dim_chunk_len;\n\t\tconst dim_chunk_sel = this.dim_sel - dim_offset;\n\t\tyield { dim_chunk_ix, dim_chunk_sel };\n\t}\n}\n\ninterface SliceChunkDimProjection {\n\tdim_chunk_ix: number;\n\tdim_chunk_sel: Indices;\n\tdim_out_sel: Indices;\n}\n\ninterface SliceDimIndexerProps {\n\tdim_sel: Slice;\n\tdim_len: number;\n\tdim_chunk_len: number;\n}\n\nclass SliceDimIndexer {\n\tstart: number;\n\tstop: number;\n\tstep: number;\n\n\tdim_len: number;\n\tdim_chunk_len: number;\n\tnitems: number;\n\tnchunks: number;\n\n\tconstructor({ dim_sel, dim_len, dim_chunk_len }: SliceDimIndexerProps) {\n\t\t// normalize\n\t\tconst [start, stop, step] = slice_indices(dim_sel, dim_len);\n\t\tthis.start = start;\n\t\tthis.stop = stop;\n\t\tthis.step = step;\n\t\tif (this.step < 1) err_negative_step();\n\t\t// store properties\n\t\tthis.dim_len = dim_len;\n\t\tthis.dim_chunk_len = dim_chunk_len;\n\t\tthis.nitems = Math.max(0, Math.ceil((this.stop - this.start) / this.step));\n\t\tthis.nchunks = Math.ceil(this.dim_len / this.dim_chunk_len);\n\t}\n\n\t*[Symbol.iterator](): IterableIterator<SliceChunkDimProjection> {\n\t\t// figure out the range of chunks we need to visit\n\t\tconst dim_chunk_ix_from = Math.floor(this.start / this.dim_chunk_len);\n\t\tconst dim_chunk_ix_to = Math.ceil(this.stop / this.dim_chunk_len);\n\t\tfor (const dim_chunk_ix of range(dim_chunk_ix_from, dim_chunk_ix_to)) {\n\t\t\t// compute offsets for chunk within overall array\n\t\t\tconst dim_offset = dim_chunk_ix * this.dim_chunk_len;\n\t\t\tconst dim_limit = Math.min(\n\t\t\t\tthis.dim_len,\n\t\t\t\t(dim_chunk_ix + 1) * this.dim_chunk_len,\n\t\t\t);\n\t\t\t// determine chunk length, accounting for trailing chunk\n\t\t\tconst dim_chunk_len = dim_limit - dim_offset;\n\n\t\t\tlet dim_out_offset = 0;\n\t\t\tlet dim_chunk_sel_start = 0;\n\t\t\tif (this.start < dim_offset) {\n\t\t\t\t// selection start before current chunk\n\t\t\t\tconst remainder = (dim_offset - this.start) % this.step;\n\t\t\t\tif (remainder) dim_chunk_sel_start += this.step - remainder;\n\t\t\t\t// compute number of previous items, provides offset into output array\n\t\t\t\tdim_out_offset = Math.ceil((dim_offset - this.start) / this.step);\n\t\t\t} else {\n\t\t\t\t// selection starts within current chunk\n\t\t\t\tdim_chunk_sel_start = this.start - dim_offset;\n\t\t\t}\n\t\t\t// selection starts within current chunk if true,\n\t\t\t// otherwise selection ends after current chunk.\n\t\t\tconst dim_chunk_sel_stop =\n\t\t\t\tthis.stop > dim_limit ? dim_chunk_len : this.stop - dim_offset;\n\n\t\t\tconst dim_chunk_sel: Indices = [\n\t\t\t\tdim_chunk_sel_start,\n\t\t\t\tdim_chunk_sel_stop,\n\t\t\t\tthis.step,\n\t\t\t];\n\t\t\tconst dim_chunk_nitems = Math.ceil(\n\t\t\t\t(dim_chunk_sel_stop - dim_chunk_sel_start) / this.step,\n\t\t\t);\n\n\t\t\tconst dim_out_sel: Indices = [\n\t\t\t\tdim_out_offset,\n\t\t\t\tdim_out_offset + dim_chunk_nitems,\n\t\t\t\t1,\n\t\t\t];\n\t\t\tyield { dim_chunk_ix, dim_chunk_sel, dim_out_sel };\n\t\t}\n\t}\n}\n\nexport function normalize_selection(\n\tselection: null | (Slice | null | number)[],\n\tshape: readonly number[],\n): (number | Slice)[] {\n\tlet normalized: (number | Slice)[] = [];\n\tif (selection === null) {\n\t\tnormalized = shape.map((_) => slice(null));\n\t} else if (Array.isArray(selection)) {\n\t\tnormalized = selection.map((s) => s ?? slice(null));\n\t}\n\tcheck_selection_length(normalized, shape);\n\treturn normalized;\n}\n\ninterface BasicIndexerProps {\n\tselection: null | (null | number | Slice)[];\n\tshape: readonly number[];\n\tchunk_shape: readonly number[];\n}\n\nexport type IndexerProjection =\n\t| { from: number; to: null }\n\t| {\n\t\t\tfrom: Indices;\n\t\t\tto: Indices;\n\t  };\n\ninterface ChunkProjection {\n\tchunk_coords: number[];\n\tmapping: IndexerProjection[];\n}\n\nexport class BasicIndexer {\n\tdim_indexers: (SliceDimIndexer | IntDimIndexer)[];\n\tshape: number[];\n\n\tconstructor({ selection, shape, chunk_shape }: BasicIndexerProps) {\n\t\t// setup per-dimension indexers\n\t\tthis.dim_indexers = normalize_selection(selection, shape).map(\n\t\t\t(dim_sel, i) => {\n\t\t\t\treturn new (\n\t\t\t\t\ttypeof dim_sel === \"number\" ? IntDimIndexer : SliceDimIndexer\n\t\t\t\t)({\n\t\t\t\t\t// @ts-expect-error ts inference not strong enough to know correct chunk\n\t\t\t\t\tdim_sel: dim_sel,\n\t\t\t\t\tdim_len: shape[i],\n\t\t\t\t\tdim_chunk_len: chunk_shape[i],\n\t\t\t\t});\n\t\t\t},\n\t\t);\n\t\tthis.shape = this.dim_indexers\n\t\t\t.filter((ixr) => ixr instanceof SliceDimIndexer)\n\t\t\t.map((sixr) => sixr.nitems);\n\t}\n\n\t*[Symbol.iterator](): IterableIterator<ChunkProjection> {\n\t\tfor (const dim_projections of product(...this.dim_indexers)) {\n\t\t\tconst chunk_coords = dim_projections.map((p) => p.dim_chunk_ix);\n\t\t\tconst mapping: IndexerProjection[] = dim_projections.map((p) => {\n\t\t\t\tif (\"dim_out_sel\" in p) {\n\t\t\t\t\treturn { from: p.dim_chunk_sel, to: p.dim_out_sel };\n\t\t\t\t}\n\t\t\t\treturn { from: p.dim_chunk_sel, to: null };\n\t\t\t});\n\t\t\tyield { chunk_coords, mapping };\n\t\t}\n\t}\n}\n", "import type { Readable } from \"@zarrita/storage\";\n\nimport { type Array, get_context } from \"../hierarchy.js\";\nimport type { Chunk, DataType, Scalar, TypedArray } from \"../metadata.js\";\nimport { BasicIndexer } from \"./indexer.js\";\nimport type {\n\tGetOptions,\n\tPrepare,\n\tSetFromChunk,\n\tSetScalar,\n\tSlice,\n} from \"./types.js\";\nimport { create_queue } from \"./util.js\";\n\nfunction unwrap<D extends DataType>(\n\tarr: TypedArray<D>,\n\tidx: number,\n): Scalar<D> {\n\treturn (\"get\" in arr ? arr.get(idx) : arr[idx]) as Scalar<D>;\n}\n\nexport async function get<\n\tD extends DataType,\n\tStore extends Readable,\n\tArr extends Chunk<D>,\n\tSel extends (null | Slice | number)[],\n>(\n\tarr: Array<D, Store>,\n\tselection: null | Sel,\n\topts: GetOptions<Parameters<Store[\"get\"]>[1]>,\n\tsetter: {\n\t\tprepare: Prepare<D, Arr>;\n\t\tset_scalar: SetScalar<D, Arr>;\n\t\tset_from_chunk: SetFromChunk<D, Arr>;\n\t},\n): Promise<\n\tnull extends Sel[number] ? Arr : Slice extends Sel[number] ? Arr : Scalar<D>\n> {\n\tlet context = get_context(arr);\n\tlet indexer = new BasicIndexer({\n\t\tselection,\n\t\tshape: arr.shape,\n\t\tchunk_shape: arr.chunks,\n\t});\n\n\tlet out = setter.prepare(\n\t\tnew context.TypedArray(indexer.shape.reduce((a, b) => a * b, 1)),\n\t\tindexer.shape,\n\t\tcontext.get_strides(indexer.shape),\n\t);\n\n\tlet queue = opts.create_queue?.() ?? create_queue();\n\tfor (const { chunk_coords, mapping } of indexer) {\n\t\tqueue.add(async () => {\n\t\t\tlet { data, shape, stride } = await arr.getChunk(chunk_coords, opts.opts);\n\t\t\tlet chunk = setter.prepare(data, shape, stride);\n\t\t\tsetter.set_from_chunk(out, chunk, mapping);\n\t\t});\n\t}\n\n\tawait queue.onIdle();\n\n\t// If the final out shape is empty, we just return a scalar.\n\t// @ts-expect-error - TS can't narrow this conditional type\n\treturn indexer.shape.length === 0 ? unwrap(out.data, 0) : out;\n}\n", "import type { Mutable } from \"@zarrita/storage\";\n\nimport { type Array, get_context } from \"../hierarchy.js\";\nimport type { Chunk, DataType, Scalar, TypedArray } from \"../metadata.js\";\nimport { BasicIndexer, type IndexerProjection } from \"./indexer.js\";\nimport type {\n\tIndices,\n\tPrepare,\n\tSetFromChunk,\n\tSetOptions,\n\tSetScalar,\n\tSlice,\n} from \"./types.js\";\nimport { create_queue } from \"./util.js\";\n\nfunction flip_indexer_projection(m: IndexerProjection) {\n\tif (m.to == null) return { from: m.to, to: m.from };\n\treturn { from: m.to, to: m.from };\n}\n\nexport async function set<Dtype extends DataType, Arr extends Chunk<Dtype>>(\n\tarr: Array<Dtype, Mutable>,\n\tselection: (number | Slice | null)[] | null,\n\tvalue: Scalar<Dtype> | Arr,\n\topts: SetOptions,\n\tsetter: {\n\t\tprepare: Prepare<Dtype, Arr>;\n\t\tset_scalar: SetScalar<Dtype, Arr>;\n\t\tset_from_chunk: SetFromChunk<Dtype, Arr>;\n\t},\n) {\n\tconst context = get_context(arr);\n\tif (context.kind === \"sharded\") {\n\t\tthrow new Error(\"Set not supported for sharded arrays.\");\n\t}\n\tconst indexer = new BasicIndexer({\n\t\tselection,\n\t\tshape: arr.shape,\n\t\tchunk_shape: arr.chunks,\n\t});\n\n\t// We iterate over all chunks which overlap the selection and thus contain data\n\t// that needs to be replaced. Each chunk is processed in turn, extracting the\n\t// necessary data from the value array and storing into the chunk array.\n\n\tconst chunk_size = arr.chunks.reduce((a, b) => a * b, 1);\n\tconst queue = opts.create_queue ? opts.create_queue() : create_queue();\n\n\t// N.B., it is an important optimisation that we only visit chunks which overlap\n\t// the selection. This minimises the number of iterations in the main for loop.\n\tfor (const { chunk_coords, mapping } of indexer) {\n\t\tconst chunk_selection = mapping.map((i) => i.from);\n\t\tconst flipped = mapping.map(flip_indexer_projection);\n\t\tqueue.add(async () => {\n\t\t\t// obtain key for chunk storage\n\t\t\tconst chunk_path = arr.resolve(\n\t\t\t\tcontext.encode_chunk_key(chunk_coords),\n\t\t\t).path;\n\n\t\t\tlet chunk_data: TypedArray<Dtype>;\n\t\t\tconst chunk_shape = arr.chunks.slice();\n\t\t\tconst chunk_stride = context.get_strides(chunk_shape);\n\n\t\t\tif (is_total_slice(chunk_selection, chunk_shape)) {\n\t\t\t\t// totally replace\n\t\t\t\tchunk_data = new context.TypedArray(chunk_size);\n\t\t\t\t// optimization: we are completely replacing the chunk, so no need\n\t\t\t\t// to access the exisiting chunk data\n\t\t\t\tif (typeof value === \"object\") {\n\t\t\t\t\t// Otherwise data just contiguous TypedArray\n\t\t\t\t\tconst chunk = setter.prepare(\n\t\t\t\t\t\tchunk_data,\n\t\t\t\t\t\tchunk_shape.slice(),\n\t\t\t\t\t\tchunk_stride.slice(),\n\t\t\t\t\t);\n\t\t\t\t\t// @ts-expect-error - Value is not a scalar\n\t\t\t\t\tsetter.set_from_chunk(chunk, value, flipped);\n\t\t\t\t} else {\n\t\t\t\t\t// @ts-expect-error - Value is a scalar\n\t\t\t\t\tchunk_data.fill(value);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// partially replace the contents of this chunk\n\t\t\t\tchunk_data = await arr.getChunk(chunk_coords).then(({ data }) => data);\n\n\t\t\t\tconst chunk = setter.prepare(\n\t\t\t\t\tchunk_data,\n\t\t\t\t\tchunk_shape.slice(),\n\t\t\t\t\tchunk_stride.slice(),\n\t\t\t\t);\n\n\t\t\t\t// Modify chunk data\n\t\t\t\tif (typeof value === \"object\") {\n\t\t\t\t\t// @ts-expect-error - Value is not a scalar\n\t\t\t\t\tsetter.set_from_chunk(chunk, value, flipped);\n\t\t\t\t} else {\n\t\t\t\t\tsetter.set_scalar(chunk, chunk_selection, value);\n\t\t\t\t}\n\t\t\t}\n\t\t\tawait arr.store.set(\n\t\t\t\tchunk_path,\n\t\t\t\tawait context.codec.encode({\n\t\t\t\t\tdata: chunk_data,\n\t\t\t\t\tshape: chunk_shape,\n\t\t\t\t\tstride: chunk_stride,\n\t\t\t\t}),\n\t\t\t);\n\t\t});\n\t}\n\tawait queue.onIdle();\n}\n\nfunction is_total_slice(\n\tselection: (number | Indices)[],\n\tshape: readonly number[],\n): selection is Indices[] {\n\t// all items are Indices and every slice is complete\n\treturn selection.every((s, i) => {\n\t\t// can't be a full selection\n\t\tif (typeof s === \"number\") return false;\n\t\t// explicit complete slice\n\t\tconst [start, stop, step] = s;\n\t\treturn stop - start === shape[i] && step === 1;\n\t});\n}\n", "import type { Mutable, Readable } from \"@zarrita/storage\";\n\nimport type { Array } from \"../hierarchy.js\";\nimport type {\n\tChunk,\n\tDataType,\n\tScalar,\n\tTypedArray,\n\tTypedArrayConstructor,\n} from \"../metadata.js\";\nimport { get as get_with_setter } from \"./get.js\";\nimport { set as set_with_setter } from \"./set.js\";\nimport type {\n\tGetOptions,\n\tIndices,\n\tProjection,\n\tSetOptions,\n\tSlice,\n} from \"./types.js\";\n\n/** A 1D \"view\" of an array that can be used to set values in the array. */\nfunction object_array_view<T>(arr: T[], offset = 0, size?: number) {\n\tlet length = size ?? arr.length - offset;\n\treturn {\n\t\tlength,\n\t\tsubarray(from: number, to: number = length) {\n\t\t\treturn object_array_view(arr, offset + from, to - from);\n\t\t},\n\t\tset(data: { get(idx: number): T; length: number }, start = 0) {\n\t\t\tfor (let i = 0; i < data.length; i++) {\n\t\t\t\tarr[offset + start + i] = data.get(i);\n\t\t\t}\n\t\t},\n\t\tget(index: number) {\n\t\t\treturn arr[offset + index];\n\t\t},\n\t};\n}\n\n/**\n * Convert a chunk to a Uint8Array that can be used with the binary\n * set functions. This is necessary because the binary set functions\n * require a contiguous block of memory, and allows us to support more than\n * just the browser's TypedArray objects.\n *\n * WARNING: This function is not meant to be used directly and is NOT type-safe.\n * In the case of `Array` instances, it will return a `object_array_view` of\n * the underlying, which is supported by our binary set functions.\n */\nfunction compat_chunk<D extends DataType>(\n\tarr: Chunk<D>,\n): {\n\tdata: Uint8Array;\n\tstride: number[];\n\tbytes_per_element: number;\n} {\n\tif (globalThis.Array.isArray(arr.data)) {\n\t\treturn {\n\t\t\t// @ts-expect-error\n\t\t\tdata: object_array_view(arr.data),\n\t\t\tstride: arr.stride,\n\t\t\tbytes_per_element: 1,\n\t\t};\n\t}\n\treturn {\n\t\tdata: new Uint8Array(\n\t\t\tarr.data.buffer,\n\t\t\tarr.data.byteOffset,\n\t\t\tarr.data.byteLength,\n\t\t),\n\t\tstride: arr.stride,\n\t\tbytes_per_element: arr.data.BYTES_PER_ELEMENT,\n\t};\n}\n\n/** Hack to get the constructor of a typed array constructor from an existing TypedArray. */\nfunction get_typed_array_constructor<D extends Exclude<DataType, \"v2:object\">>(\n\tarr: TypedArray<D>,\n): TypedArrayConstructor<D> {\n\tif (\"chars\" in arr) {\n\t\t// our custom TypedArray needs to bind the number of characters per\n\t\t// element to the constructor.\n\t\treturn arr.constructor.bind(null, arr.chars);\n\t}\n\treturn arr.constructor as TypedArrayConstructor<D>;\n}\n\n/**\n * Convert a scalar to a Uint8Array that can be used with the binary\n * set functions. This is necessary because the binary set functions\n * require a contiguous block of memory, and allows us to support more\n * than just the browser's TypedArray objects.\n *\n * WARNING: This function is not meant to be used directly and is NOT type-safe.\n * In the case of `Array` instances, it will return a `object_array_view` of\n * the scalar, which is supported by our binary set functions.\n */\nfunction compat_scalar<D extends DataType>(\n\tarr: Chunk<D>,\n\tvalue: Scalar<D>,\n): Uint8Array {\n\tif (globalThis.Array.isArray(arr.data)) {\n\t\t// @ts-expect-error\n\t\treturn object_array_view([value]);\n\t}\n\tlet TypedArray = get_typed_array_constructor(arr.data);\n\t// @ts-expect-error - value is a scalar and matches\n\tlet data = new TypedArray([value]);\n\treturn new Uint8Array(data.buffer, data.byteOffset, data.byteLength);\n}\n\nexport const setter = {\n\tprepare<D extends DataType>(\n\t\tdata: TypedArray<D>,\n\t\tshape: number[],\n\t\tstride: number[],\n\t) {\n\t\treturn { data, shape, stride };\n\t},\n\tset_scalar<D extends DataType>(\n\t\tdest: Chunk<D>,\n\t\tsel: (number | Indices)[],\n\t\tvalue: Scalar<D>,\n\t) {\n\t\tlet view = compat_chunk(dest);\n\t\tset_scalar_binary(\n\t\t\tview,\n\t\t\tsel,\n\t\t\tcompat_scalar(dest, value),\n\t\t\tview.bytes_per_element,\n\t\t);\n\t},\n\tset_from_chunk<D extends DataType>(\n\t\tdest: Chunk<D>,\n\t\tsrc: Chunk<D>,\n\t\tprojections: Projection[],\n\t) {\n\t\tlet view = compat_chunk(dest);\n\t\tset_from_chunk_binary(\n\t\t\tview,\n\t\t\tcompat_chunk(src),\n\t\t\tview.bytes_per_element,\n\t\t\tprojections,\n\t\t);\n\t},\n};\n\n/** @category Utility */\nexport async function get<\n\tD extends DataType,\n\tStore extends Readable,\n\tSel extends (null | Slice | number)[],\n>(\n\tarr: Array<D, Store>,\n\tselection: Sel | null = null,\n\topts: GetOptions<Parameters<Store[\"get\"]>[1]> = {},\n): Promise<\n\tnull extends Sel[number]\n\t\t? Chunk<D>\n\t\t: Slice extends Sel[number]\n\t\t\t? Chunk<D>\n\t\t\t: Scalar<D>\n> {\n\treturn get_with_setter<D, Store, Chunk<D>, Sel>(arr, selection, opts, setter);\n}\n\n/** @category Utility */\nexport async function set<D extends DataType>(\n\tarr: Array<D, Mutable>,\n\tselection: (null | Slice | number)[] | null,\n\tvalue: Scalar<D> | Chunk<D>,\n\topts: SetOptions = {},\n): Promise<void> {\n\treturn set_with_setter<D, Chunk<D>>(arr, selection, value, opts, setter);\n}\n\nfunction indices_len(start: number, stop: number, step: number) {\n\tif (step < 0 && stop < start) {\n\t\treturn Math.floor((start - stop - 1) / -step) + 1;\n\t}\n\tif (start < stop) return Math.floor((stop - start - 1) / step) + 1;\n\treturn 0;\n}\n\nfunction set_scalar_binary(\n\tout: { data: Uint8Array; stride: number[] },\n\tout_selection: (Indices | number)[],\n\tvalue: Uint8Array,\n\tbytes_per_element: number,\n) {\n\tif (out_selection.length === 0) {\n\t\tout.data.set(value, 0);\n\t\treturn;\n\t}\n\tconst [slice, ...slices] = out_selection;\n\tconst [curr_stride, ...stride] = out.stride;\n\tif (typeof slice === \"number\") {\n\t\tconst data = out.data.subarray(curr_stride * slice * bytes_per_element);\n\t\tset_scalar_binary({ data, stride }, slices, value, bytes_per_element);\n\t\treturn;\n\t}\n\tconst [from, to, step] = slice;\n\tconst len = indices_len(from, to, step);\n\tif (slices.length === 0) {\n\t\tfor (let i = 0; i < len; i++) {\n\t\t\tout.data.set(value, curr_stride * (from + step * i) * bytes_per_element);\n\t\t}\n\t\treturn;\n\t}\n\tfor (let i = 0; i < len; i++) {\n\t\tconst data = out.data.subarray(\n\t\t\tcurr_stride * (from + step * i) * bytes_per_element,\n\t\t);\n\t\tset_scalar_binary({ data, stride }, slices, value, bytes_per_element);\n\t}\n}\n\nfunction set_from_chunk_binary(\n\tdest: { data: Uint8Array; stride: number[] },\n\tsrc: { data: Uint8Array; stride: number[] },\n\tbytes_per_element: number,\n\tprojections: Projection[],\n) {\n\tconst [proj, ...projs] = projections;\n\tconst [dstride, ...dstrides] = dest.stride;\n\tconst [sstride, ...sstrides] = src.stride;\n\tif (proj.from === null) {\n\t\tif (projs.length === 0) {\n\t\t\tdest.data.set(\n\t\t\t\tsrc.data.subarray(0, bytes_per_element),\n\t\t\t\tproj.to * bytes_per_element,\n\t\t\t);\n\t\t\treturn;\n\t\t}\n\t\tset_from_chunk_binary(\n\t\t\t{\n\t\t\t\tdata: dest.data.subarray(dstride * proj.to * bytes_per_element),\n\t\t\t\tstride: dstrides,\n\t\t\t},\n\t\t\tsrc,\n\t\t\tbytes_per_element,\n\t\t\tprojs,\n\t\t);\n\t\treturn;\n\t}\n\tif (proj.to === null) {\n\t\tif (projs.length === 0) {\n\t\t\tlet offset = proj.from * bytes_per_element;\n\t\t\tdest.data.set(src.data.subarray(offset, offset + bytes_per_element), 0);\n\t\t\treturn;\n\t\t}\n\t\tset_from_chunk_binary(\n\t\t\tdest,\n\t\t\t{\n\t\t\t\tdata: src.data.subarray(sstride * proj.from * bytes_per_element),\n\t\t\t\tstride: sstrides,\n\t\t\t},\n\t\t\tbytes_per_element,\n\t\t\tprojs,\n\t\t);\n\t\treturn;\n\t}\n\tconst [from, to, step] = proj.to;\n\tconst [sfrom, _, sstep] = proj.from;\n\tconst len = indices_len(from, to, step);\n\tif (projs.length === 0) {\n\t\t// NB: we have a contiguous block of memory\n\t\t// so we can just copy over all the data at once.\n\t\tif (step === 1 && sstep === 1 && dstride === 1 && sstride === 1) {\n\t\t\tlet offset = sfrom * bytes_per_element;\n\t\t\tlet size = len * bytes_per_element;\n\t\t\tdest.data.set(\n\t\t\t\tsrc.data.subarray(offset, offset + size),\n\t\t\t\tfrom * bytes_per_element,\n\t\t\t);\n\t\t\treturn;\n\t\t}\n\t\t// Otherwise, we have to copy over each element individually.\n\t\tfor (let i = 0; i < len; i++) {\n\t\t\tlet offset = sstride * (sfrom + sstep * i) * bytes_per_element;\n\t\t\tdest.data.set(\n\t\t\t\tsrc.data.subarray(offset, offset + bytes_per_element),\n\t\t\t\tdstride * (from + step * i) * bytes_per_element,\n\t\t\t);\n\t\t}\n\t\treturn;\n\t}\n\tfor (let i = 0; i < len; i++) {\n\t\tset_from_chunk_binary(\n\t\t\t{\n\t\t\t\tdata: dest.data.subarray(\n\t\t\t\t\tdstride * (from + i * step) * bytes_per_element,\n\t\t\t\t),\n\t\t\t\tstride: dstrides,\n\t\t\t},\n\t\t\t{\n\t\t\t\tdata: src.data.subarray(\n\t\t\t\t\tsstride * (sfrom + i * sstep) * bytes_per_element,\n\t\t\t\t),\n\t\t\t\tstride: sstrides,\n\t\t\t},\n\t\t\tbytes_per_element,\n\t\t\tprojs,\n\t\t);\n\t}\n}\n", "import type { Readable } from \"@zarrita/storage\";\nimport { KeyError, NodeNotFoundError } from \"./errors.js\";\nimport { Array, Group, Location } from \"./hierarchy.js\";\nimport type {\n\tArrayMetadata,\n\tAttributes,\n\tDataType,\n\tGroupMetadata,\n} from \"./metadata.js\";\nimport {\n\tensure_correct_scalar,\n\tjson_decode_object,\n\trethrow_unless,\n\tv2_to_v3_array_metadata,\n\tv2_to_v3_group_metadata,\n} from \"./util.js\";\n\nlet VERSION_COUNTER = create_version_counter();\nfunction create_version_counter() {\n\tlet version_counts = new WeakMap<Readable, { v2: number; v3: number }>();\n\tfunction get_counts(store: Readable) {\n\t\tlet counts = version_counts.get(store) ?? { v2: 0, v3: 0 };\n\t\tversion_counts.set(store, counts);\n\t\treturn counts;\n\t}\n\treturn {\n\t\tincrement(store: Readable, version: \"v2\" | \"v3\") {\n\t\t\tget_counts(store)[version] += 1;\n\t\t},\n\t\tversion_max(store: Readable): \"v2\" | \"v3\" {\n\t\t\tlet counts = get_counts(store);\n\t\t\treturn counts.v3 > counts.v2 ? \"v3\" : \"v2\";\n\t\t},\n\t};\n}\n\nasync function load_attrs(location: Location<Readable>): Promise<Attributes> {\n\tlet meta_bytes = await location.store.get(location.resolve(\".zattrs\").path);\n\tif (!meta_bytes) return {};\n\treturn json_decode_object(meta_bytes);\n}\n\nfunction open_v2<Store extends Readable>(\n\tlocation: Location<Store> | Store,\n\toptions: { kind: \"group\"; attrs?: boolean },\n): Promise<Group<Store>>;\n\nfunction open_v2<Store extends Readable>(\n\tlocation: Location<Store> | Store,\n\toptions: { kind: \"array\"; attrs?: boolean },\n): Promise<Array<DataType, Store>>;\n\nfunction open_v2<Store extends Readable>(\n\tlocation: Location<Store> | Store,\n\toptions?: { kind?: \"array\" | \"group\"; attrs?: boolean },\n): Promise<Array<DataType, Store> | Group<Store>>;\n\nasync function open_v2<Store extends Readable>(\n\tlocation: Location<Store> | Store,\n\toptions: { kind?: \"array\" | \"group\"; attrs?: boolean } = {},\n) {\n\tlet loc = \"store\" in location ? location : new Location(location);\n\tlet attrs = {};\n\tif (options.attrs ?? true) attrs = await load_attrs(loc);\n\tif (options.kind === \"array\") return open_array_v2(loc, attrs);\n\tif (options.kind === \"group\") return open_group_v2(loc, attrs);\n\treturn open_array_v2(loc, attrs).catch((err) => {\n\t\trethrow_unless(err, NodeNotFoundError);\n\t\treturn open_group_v2(loc, attrs);\n\t});\n}\n\nasync function open_array_v2<Store extends Readable>(\n\tlocation: Location<Store>,\n\tattrs: Attributes,\n) {\n\tlet { path } = location.resolve(\".zarray\");\n\tlet meta = await location.store.get(path);\n\tif (!meta) {\n\t\tthrow new NodeNotFoundError(\"v2 array\", {\n\t\t\tcause: new KeyError(path),\n\t\t});\n\t}\n\tVERSION_COUNTER.increment(location.store, \"v2\");\n\treturn new Array(\n\t\tlocation.store,\n\t\tlocation.path,\n\t\tv2_to_v3_array_metadata(json_decode_object(meta), attrs),\n\t);\n}\n\nasync function open_group_v2<Store extends Readable>(\n\tlocation: Location<Store>,\n\tattrs: Attributes,\n) {\n\tlet { path } = location.resolve(\".zgroup\");\n\tlet meta = await location.store.get(path);\n\tif (!meta) {\n\t\tthrow new NodeNotFoundError(\"v2 group\", {\n\t\t\tcause: new KeyError(path),\n\t\t});\n\t}\n\tVERSION_COUNTER.increment(location.store, \"v2\");\n\treturn new Group(\n\t\tlocation.store,\n\t\tlocation.path,\n\t\tv2_to_v3_group_metadata(json_decode_object(meta), attrs),\n\t);\n}\n\nasync function _open_v3<Store extends Readable>(location: Location<Store>) {\n\tlet { store, path } = location.resolve(\"zarr.json\");\n\tlet meta = await location.store.get(path);\n\tif (!meta) {\n\t\tthrow new NodeNotFoundError(\"v3 array or group\", {\n\t\t\tcause: new KeyError(path),\n\t\t});\n\t}\n\tlet meta_doc: ArrayMetadata<DataType> | GroupMetadata =\n\t\tjson_decode_object(meta);\n\tif (meta_doc.node_type === \"array\") {\n\t\tmeta_doc.fill_value = ensure_correct_scalar(meta_doc);\n\t}\n\treturn meta_doc.node_type === \"array\"\n\t\t? new Array(store, location.path, meta_doc)\n\t\t: new Group(store, location.path, meta_doc);\n}\n\nfunction open_v3<Store extends Readable>(\n\tlocation: Location<Store> | Store,\n\toptions: { kind: \"group\" },\n): Promise<Group<Store>>;\n\nfunction open_v3<Store extends Readable>(\n\tlocation: Location<Store> | Store,\n\toptions: { kind: \"array\" },\n): Promise<Array<DataType, Store>>;\n\nfunction open_v3<Store extends Readable>(\n\tlocation: Location<Store> | Store,\n): Promise<Array<DataType, Store> | Group<Store>>;\n\nfunction open_v3<Store extends Readable>(\n\tlocation: Location<Store> | Store,\n): Promise<Array<DataType, Store> | Group<Store>>;\n\nasync function open_v3<Store extends Readable>(\n\tlocation: Location<Store>,\n\toptions: { kind?: \"array\" | \"group\" } = {},\n): Promise<Array<DataType, Store> | Group<Store>> {\n\tlet loc = \"store\" in location ? location : new Location(location);\n\tlet node = await _open_v3(loc);\n\tVERSION_COUNTER.increment(loc.store, \"v3\");\n\tif (options.kind === undefined) return node;\n\tif (options.kind === \"array\" && node instanceof Array) return node;\n\tif (options.kind === \"group\" && node instanceof Group) return node;\n\tlet kind = node instanceof Array ? \"array\" : \"group\";\n\tthrow new Error(`Expected node of kind ${options.kind}, found ${kind}.`);\n}\n\nexport function open<Store extends Readable>(\n\tlocation: Location<Store> | Store,\n\toptions: { kind: \"group\" },\n): Promise<Group<Store>>;\n\nexport function open<Store extends Readable>(\n\tlocation: Location<Store> | Store,\n\toptions: { kind: \"array\" },\n): Promise<Array<DataType, Store>>;\n\nexport async function open<Store extends Readable>(\n\tlocation: Location<Store> | Store,\n\toptions: { kind?: \"array\" | \"group\" },\n): Promise<Array<DataType, Store> | Group<Store>>;\n\nexport function open<Store extends Readable>(\n\tlocation: Location<Store> | Store,\n): Promise<Array<DataType, Store> | Group<Store>>;\n\nexport function open<Store extends Readable>(\n\tlocation: Location<Store> | Store,\n): Promise<Array<DataType, Store> | Group<Store>>;\n\nexport async function open<Store extends Readable>(\n\tlocation: Location<Store> | Store,\n\toptions: { kind?: \"array\" | \"group\" } = {},\n): Promise<Array<DataType, Store> | Group<Store>> {\n\tlet store = \"store\" in location ? location.store : location;\n\tlet version_max = VERSION_COUNTER.version_max(store);\n\t// Use the open function for the version with the most successful opens.\n\t// Note that here we use the dot syntax to access the open functions\n\t// because this enables us to use vi.spyOn during testing.\n\tlet open_primary = version_max === \"v2\" ? open.v2 : open.v3;\n\tlet open_secondary = version_max === \"v2\" ? open.v3 : open.v2;\n\treturn open_primary(location, options).catch((err) => {\n\t\trethrow_unless(err, NodeNotFoundError);\n\t\treturn open_secondary(location, options);\n\t});\n}\n\nopen.v2 = open_v2;\nopen.v3 = open_v3;\n"],
  "mappings": ";;;;;;;;;AAyBM,SAAU,YACf,KACA,QACA,QACA,OAAoB,CAAA,GAAE;AAEtB,MAAI,WAAW,UAAa,WAAW,QAAW;AAEjD,WAAO;MACN,GAAG;MACH,SAAS;QACR,GAAG,KAAK;QACR,OAAO,SAAS,MAAM,IAAI,SAAS,SAAS,CAAC;;;EAGhD;AACA,SAAO,MAAM,KAAK,IAAI;AACvB;AAEM,SAAU,WACf,gBACA,kBAA6B;AAG7B,SAAO;IACN,GAAG;IACH,GAAG;IACH,SAAS;MACR,GAAG,eAAe;MAClB,GAAG,iBAAiB;;;AAGvB;;;ACtDA,SAAS,QAAQA,OAAoB,MAAkB;AACtD,QAAM,OAAO,OAAOA,UAAS,WAAW,IAAI,IAAIA,KAAI,IAAIA;AACxD,MAAI,CAAC,KAAK,SAAS,SAAS,GAAG,GAAG;AAEjC,SAAK,YAAY;EAClB;AACA,QAAM,WAAW,IAAI,IAAI,KAAK,MAAM,CAAC,GAAG,IAAI;AAE5C,WAAS,SAAS,KAAK;AACvB,SAAO;AACR;AAEA,eAAe,gBACd,UAAkB;AAElB,MAAI,SAAS,WAAW,KAAK;AAC5B,WAAO;EACR;AACA,MAAI,SAAS,WAAW,OAAO,SAAS,WAAW,KAAK;AACvD,WAAO,IAAI,WAAW,MAAM,SAAS,YAAW,CAAE;EACnD;AACA,QAAM,IAAI,MACT,8BAA8B,SAAS,MAAM,IAAI,SAAS,UAAU,EAAE;AAExE;AAEA,eAAe,aACd,KACA,eACA,MACA,oBAA2B;AAE3B,MAAI,oBAAoB;AACvB,WAAO,MAAM,KAAK;MACjB,GAAG;MACH,SAAS,EAAE,GAAG,KAAK,SAAS,OAAO,UAAU,aAAa,GAAE;KAC5D;EACF;AACA,MAAI,WAAW,MAAM,MAAM,KAAK,EAAE,GAAG,MAAM,QAAQ,OAAM,CAAE;AAC3D,MAAI,CAAC,SAAS,IAAI;AAEjB,WAAO;EACR;AACA,MAAI,iBAAiB,SAAS,QAAQ,IAAI,gBAAgB;AAC1D,MAAI,SAAS,OAAO,cAAc;AAClC,SAAO,YAAY,KAAK,SAAS,eAAe,QAAQ,IAAI;AAC7D;AAhDA;AA4DA,IAAM,aAAN,MAAgB;EAIf,YACQ,KACP,UAAmE,CAAA,GAAE;AANvE;AAKS;AAJR;AACA;AAGQ,SAAA,MAAA;AAGP,uBAAK,YAAa,QAAQ,aAAa,CAAA;AACvC,uBAAK,qBAAsB,QAAQ,oBAAoB;EACxD;EAMA,MAAM,IACL,KACA,UAAuB,CAAA,GAAE;AAEzB,QAAI,OAAO,QAAQ,KAAK,KAAK,GAAG,EAAE;AAClC,QAAI,WAAW,MAAM,MAAM,MAAM,sBAAK,sCAAL,WAAiB,QAAQ;AAC1D,WAAO,gBAAgB,QAAQ;EAChC;EAEA,MAAM,SACL,KACAC,QACA,UAAuB,CAAA,GAAE;AAEzB,QAAI,MAAM,QAAQ,KAAK,KAAK,GAAG;AAC/B,QAAI,OAAO,sBAAK,sCAAL,WAAiB;AAC5B,QAAI;AACJ,QAAI,kBAAkBA,QAAO;AAC5B,iBAAW,MAAM,aAChB,KACAA,OAAM,cACN,MACA,mBAAK,oBAAmB;IAE1B,OAAO;AACN,iBAAW,MAAM,YAAY,KAAKA,OAAM,QAAQA,OAAM,QAAQ,IAAI;IACnE;AACA,WAAO,gBAAgB,QAAQ;EAChC;;AA3CA;AACA;AAFD;AAYC,gBAAW,SAAC,WAAsB;AACjC,SAAO,WAAW,mBAAK,aAAY,SAAS;AAC7C;AAiCD,IAAA,gBAAe;;;AC5Gf;AAWM,IAAO,YAAP,MAAgB;EAMrB,YACC,GACA,YACA,QAAe;AARhB;AAUC,QAAI,OAAO,MAAM,UAAU;AAC1B,yBAAK,QAAS,IAAI,WAAW,CAAC;IAC/B,WAAW,aAAa,aAAa;AACpC,yBAAK,QAAS,IAAI,WAAW,GAAG,YAAY,MAAM;IACnD,OAAO;AACN,yBAAK,QAAS,IAAI,WAAW,MAAM,KAAK,GAAG,CAAC,MAAO,IAAI,IAAI,CAAE,CAAC;IAC/D;EACD;EAEA,IAAI,oBAAiB;AACpB,WAAO;EACR;EAEA,IAAI,aAAU;AACb,WAAO,mBAAK,QAAO;EACpB;EAEA,IAAI,aAAU;AACb,WAAO,mBAAK,QAAO;EACpB;EAEA,IAAI,SAAM;AACT,WAAO,mBAAK,QAAO;EACpB;EAEA,IAAI,SAAM;AACT,WAAO,mBAAK,QAAO;EACpB;EAEA,IAAI,KAAW;AACd,QAAI,QAAQ,mBAAK,QAAO,GAAG;AAC3B,WAAO,OAAO,UAAU,WAAW,UAAU,IAAI;EAClD;EAEA,IAAI,KAAa,OAAc;AAC9B,uBAAK,QAAO,GAAG,IAAI,QAAQ,IAAI;EAChC;EAEA,KAAK,OAAc;AAClB,uBAAK,QAAO,KAAK,QAAQ,IAAI,CAAC;EAC/B;EAEA,EAAE,OAAO,QAAQ,IAAC;AACjB,aAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AACrC,YAAM,KAAK,IAAI,CAAC;IACjB;EACD;;AAxDA;AAZD;AA4EM,IAAO,kBAAP,MAAsB;EAa3B,YACC,OACA,GACA,YACA,QAAe;AAhBhB;AACA;AACA;AAgBC,SAAK,QAAQ;AACb,uBAAK,UAAW,IAAI,YAAW;AAC/B,QAAI,OAAO,MAAM,UAAU;AAC1B,WAAK,QAAQ,IAAI,WAAW,IAAI,KAAK;IACtC,WAAW,aAAa,aAAa;AACpC,UAAI;AAAQ,iBAAS,SAAS;AAC9B,WAAK,QAAQ,IAAI,WAAW,GAAG,YAAY,MAAM;IAClD,OAAO;AACN,UAAI,SAAS,MAAM,KAAK,CAAC;AACzB,WAAK,QAAQ,IAAI,WAAW,OAAO,SAAS,KAAK;AACjD,eAAS,IAAI,GAAG,IAAI,OAAO,QAAQ,KAAK;AACvC,aAAK,IAAI,GAAG,OAAO,CAAC,CAAC;MACtB;IACD;EACD;EAEA,IAAI,oBAAiB;AACpB,WAAO,KAAK;EACb;EAEA,IAAI,aAAU;AACb,WAAO,KAAK,MAAM;EACnB;EAEA,IAAI,aAAU;AACb,WAAO,KAAK,MAAM;EACnB;EAEA,IAAI,SAAM;AACT,WAAO,KAAK,MAAM;EACnB;EAEA,IAAI,SAAM;AACT,WAAO,KAAK,aAAa,KAAK;EAC/B;EAEA,IAAI,KAAW;AACd,UAAM,OAAO,IAAI,WAChB,KAAK,QACL,KAAK,aAAa,KAAK,QAAQ,KAC/B,KAAK,KAAK;AAGX,WAAO,IAAI,YAAW,EAAG,OAAO,IAAI,EAAE,QAAQ,SAAS,EAAE;EAC1D;EAEA,IAAI,KAAa,OAAa;AAC7B,UAAM,OAAO,IAAI,WAChB,KAAK,QACL,KAAK,aAAa,KAAK,QAAQ,KAC/B,KAAK,KAAK;AAEX,SAAK,KAAK,CAAC;AACX,SAAK,IAAI,mBAAK,UAAS,OAAO,KAAK,CAAC;EACrC;EAEA,KAAK,OAAa;AACjB,UAAM,UAAU,mBAAK,UAAS,OAAO,KAAK;AAC1C,aAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AACrC,WAAK,MAAM,IAAI,SAAS,IAAI,KAAK,KAAK;IACvC;EACD;EAEA,EAAE,OAAO,QAAQ,IAAC;AACjB,aAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AACrC,YAAM,KAAK,IAAI,CAAC;IACjB;EACD;;AAnFA;AA/ED;AA0KM,IAAO,sBAAP,MAAO,oBAAkB;EAY9B,YACC,OACA,GACA,YACA,QAAe;AAfhB;AACA;AAgBC,SAAK,QAAQ;AACb,QAAI,OAAO,MAAM,UAAU;AAC1B,yBAAK,OAAQ,IAAI,WAAW,IAAI,KAAK;IACtC,WAAW,aAAa,aAAa;AACpC,UAAI;AAAQ,kBAAU;AACtB,yBAAK,OAAQ,IAAI,WAAW,GAAG,YAAY,MAAM;IAClD,OAAO;AACN,YAAM,SAAS;AACf,YAAM,IAAI,IAAI,oBAAmB,OAAO,CAAC;AACzC,yBAAK,OAAQ,IAAI,YACf,aAAS;AACT,iBAAS,OAAO,QAAQ;AACvB,YAAE,IAAI,GAAG,GAAG;AACZ,iBAAO,gBAAE;QACV;MACD,GAAE,CAAE;IAEN;EACD;EAEA,IAAI,oBAAiB;AACpB,WAAO,mBAAK,OAAM,oBAAoB,KAAK;EAC5C;EAEA,IAAI,aAAU;AACb,WAAO,mBAAK,OAAM;EACnB;EAEA,IAAI,aAAU;AACb,WAAO,mBAAK,OAAM;EACnB;EAEA,IAAI,SAAM;AACT,WAAO,mBAAK,OAAM;EACnB;EAEA,IAAI,SAAM;AACT,WAAO,mBAAK,OAAM,SAAS,KAAK;EACjC;EAEA,IAAI,KAAW;AACd,UAAM,SAAS,KAAK,QAAQ;AAC5B,QAAI,SAAS;AACb,aAAS,IAAI,GAAG,IAAI,KAAK,OAAO,KAAK;AACpC,gBAAU,OAAO,cAAc,mBAAK,OAAM,SAAS,CAAC,CAAC;IACtD;AAEA,WAAO,OAAO,QAAQ,WAAW,EAAE;EACpC;EAEA,IAAI,KAAa,OAAa;AAC7B,UAAM,SAAS,KAAK,QAAQ;AAC5B,UAAM,OAAO,mBAAK,OAAM,SAAS,QAAQ,SAAS,KAAK,KAAK;AAC5D,SAAK,KAAK,CAAC;AACX,aAAS,IAAI,GAAG,IAAI,KAAK,OAAO,KAAK;AACpC,WAAK,CAAC,IAAI,MAAM,YAAY,CAAC,KAAK;IACnC;EACD;EAEA,KAAK,OAAa;AAEjB,SAAK,IAAI,GAAG,KAAK;AAEjB,QAAI,UAAU,mBAAK,OAAM,SAAS,GAAG,KAAK,KAAK;AAC/C,aAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AACrC,yBAAK,OAAM,IAAI,SAAS,IAAI,KAAK,KAAK;IACvC;EACD;EAEA,EAAE,OAAO,QAAQ,IAAC;AACjB,aAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AACrC,YAAM,KAAK,IAAI,CAAC;IACjB;EACD;;AA1FA;AADK,IAAO,qBAAP;;;ACvJA,SAAU,mBAAmB,GAA0B;AAC5D,QAAM,MAAM,KAAK,UAAU,GAAG,MAAM,CAAC;AACrC,SAAO,IAAI,YAAW,EAAG,OAAO,GAAG;AACpC;AAEM,SAAU,mBAAmB,OAAiB;AACnD,QAAM,MAAM,IAAI,YAAW,EAAG,OAAO,KAAK;AAC1C,SAAO,KAAK,MAAM,GAAG;AACtB;AAEM,SAAU,iBAAiB,MAAkBC,oBAAyB;AAC3E,QAAM,WAAWA,qBAAoB;AACrC,QAAM,eAAeA,qBAAoB;AACzC,MAAI,IAAI;AACR,WAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAKA,oBAAmB;AACxD,aAAS,IAAI,GAAG,IAAI,UAAU,KAAK,GAAG;AACrC,UAAI,KAAK,IAAI,CAAC;AACd,WAAK,IAAI,CAAC,IAAI,KAAK,IAAI,eAAe,CAAC;AACvC,WAAK,IAAI,eAAe,CAAC,IAAI;IAC9B;EACD;AACD;AAEM,SAAU,QACf,WAAY;AAEZ,MAAI,cAAc,aAAa;AAC9B,WAAO,WAAW;EACnB;AACA,MAAI,QAAQ,UAAU,MAAM,gBAAgB;AAC5C,MAAI,OAAO;AACV,QAAI,CAAC,EAAE,MAAM,KAAK,IAAI;AAEtB,YAAQ,SAAS,MAAM,qBAAqB,iBAAiB,KAC5D,MACA,OAAO,KAAK,CAAC;EAEf;AAEA,MAAI,MACH;IACC,MAAM;IACN,OAAO;IACP,OAAO;IACP,OAAO,WAAW;IAClB,OAAO;IACP,QAAQ;IACR,QAAQ;IACR,QAAQ,WAAW;IACnB,SAAS,WAAW;IACpB,SAAS;IACT,SAAS;IACT,MAAM;IAEN,SAAS;AACX,SAAO,KAAK,qCAAqC,SAAS,EAAE;AAC5D,SAAO;AACR;AAGM,SAAU,YACf,OACA,OAAgC;AAEhC,QAAM,OAAO,MAAM;AACnB,MAAI,OAAO,UAAU,UAAU;AAC9B,YACC,UAAU,MACP,MAAM,KAAK,EAAE,QAAQ,KAAI,GAAI,CAAC,GAAG,MAAM,CAAC,IACxC,MAAM,KAAK,EAAE,QAAQ,KAAI,GAAI,CAAC,GAAG,MAAM,OAAO,IAAI,CAAC;EACxD;AACA,SACC,SAAS,MAAM,QACf,mDAAmD;AAGpD,MAAI,OAAO;AACX,MAAI,SAAS,IAAI,MAAM,IAAI;AAC3B,WAAS,IAAI,MAAM,SAAS,GAAG,KAAK,GAAG,KAAK;AAC3C,WAAO,MAAM,CAAC,CAAC,IAAI;AACnB,YAAQ,MAAM,MAAM,CAAC,CAAC;EACvB;AAEA,SAAO;AACR;AAGM,SAAU,yBAAyB,EACxC,MACA,cAAa,GACwB;AACrC,MAAI,SAAS,WAAW;AACvB,UAAM,aAAY,+CAAe,cAAa;AAC9C,WAAO,CAAC,iBAAiB,CAAC,KAAK,GAAG,YAAY,EAAE,KAAK,SAAS;EAC/D;AACA,MAAI,SAAS,MAAM;AAClB,UAAM,aAAY,+CAAe,cAAa;AAC9C,WAAO,CAAC,iBAAiB,aAAa,KAAK,SAAS,KAAK;EAC1D;AACA,QAAM,IAAI,MAAM,+BAA+B,IAAI,EAAE;AACtD;AAEA,SAAS,aACR,OAAa;AAEb,MAAI,UAAU,MAAM;AACnB,WAAO,EAAE,WAAW,YAAW;EAChC;AAEA,MAAI,QAAQ,MAAM,MAAM,eAAe;AACvC,SAAO,OAAO,kBAAkB,KAAK,EAAE;AAEvC,MAAI,CAAC,EAAE,QAAQ,IAAI,IAAI;AACvB,MAAI,YACH;IACC,IAAI;IACJ,IAAI;IACJ,IAAI;IACJ,IAAI;IACJ,IAAI;IACJ,IAAI;IACJ,IAAI;IACJ,IAAI;IACJ,IAAI;IACJ,IAAI;IACJ,IAAI;IACJ,IAAI;IACH,IAAI,MACL,KAAK,WAAW,GAAG,KAAK,KAAK,WAAW,GAAG,IAAI,MAAM,IAAI,KAAK;AAChE,SAAO,WAAW,iCAAiC,KAAK,EAAE;AAC1D,MAAI,WAAW,KAAK;AACnB,WAAO,EAAE,UAAS;EACnB;AACA,SAAO,EAAE,WAAW,QAAQ,WAAW,MAAM,WAAW,MAAK;AAI9D;AAEM,SAAU,wBACf,MACA,aAAsC,CAAA,GAAE;AAExC,MAAI,SAA0B,CAAA;AAC9B,MAAI,QAAQ,aAAa,KAAK,KAAK;AACnC,MAAI,KAAK,UAAU,KAAK;AACvB,WAAO,KAAK,EAAE,MAAM,aAAa,eAAe,EAAE,OAAO,IAAG,EAAE,CAAE;EACjE;AACA,MAAI,YAAY,SAAS,MAAM,WAAW,OAAO;AAChD,WAAO,KAAK,EAAE,MAAM,SAAS,eAAe,EAAE,QAAQ,MAAK,EAAE,CAAE;EAChE;AACA,WAAS,EAAE,IAAI,GAAG,cAAa,KAAM,KAAK,WAAW,CAAA,GAAI;AACxD,WAAO,KAAK,EAAE,MAAM,IAAI,cAAa,CAAE;EACxC;AACA,MAAI,KAAK,YAAY;AACpB,QAAI,EAAE,IAAI,GAAG,cAAa,IAAK,KAAK;AACpC,WAAO,KAAK,EAAE,MAAM,IAAI,cAAa,CAAE;EACxC;AACA,SAAO;IACN,aAAa;IACb,WAAW;IACX,OAAO,KAAK;IACZ,WAAW,MAAM;IACjB,YAAY;MACX,MAAM;MACN,eAAe;QACd,aAAa,KAAK;;;IAGpB,oBAAoB;MACnB,MAAM;MACN,eAAe;QACd,WAAW,KAAK,uBAAuB;;;IAGzC;IACA,YAAY,KAAK;IACjB;;AAEF;AAEM,SAAU,wBACf,OACA,aAAsC,CAAA,GAAE;AAExC,SAAO;IACN,aAAa;IACb,WAAW;IACX;;AAEF;AAuBM,SAAU,SACf,OACA,OAAY;AAEZ,MACC,UAAU,YACV,UAAU,YACV,UAAU,aACV,UAAU,YACV,UAAU,UACT;AACD,WAAO,UAAU;EAClB;AACA,MAAI,aAAa,UAAU;AAC3B,MAAI,UAAU;AAAW,WAAO;AAChC,MAAI,YAAY,MAAM,WAAW,MAAM,KAAK,MAAM,WAAW,MAAM;AACnE,MAAI,UAAU;AAAU,WAAO;AAC/B,MAAI,YAAY,UAAU,WAAW,UAAU;AAC/C,MAAI,UAAU;AAAU,WAAO;AAC/B,MAAI,YAAY,UAAU;AAC1B,MAAI,UAAU;AAAU,WAAO;AAC/B,SAAO,CAAC,aAAa,CAAC,aAAa,CAAC,cAAc,CAAC;AACpD;AAWM,SAAU,kBACf,OAAoB;AAEpB,UAAO,+BAAO,UAAS;AACxB;AAEM,SAAU,sBACf,UAA0B;AAE1B,OACE,SAAS,cAAc,YAAY,SAAS,cAAc,YAC3D,SAAS,cAAc,MACtB;AAED,WAAO,OAAO,SAAS,UAAU;EAClC;AACA,SAAO,SAAS;AACjB;AAiCM,SAAU,eACf,UACG,QAAS;AAEZ,MAAI,CAAC,OAAO,KAAK,CAAC,eAAe,iBAAiB,UAAU,GAAG;AAC9D,UAAM;EACP;AACD;AAiBM,SAAU,OACf,YACA,MAA0B,IAAE;AAE5B,MAAI,CAAC,YAAY;AAChB,UAAM,IAAI,MAAM,GAAG;EACpB;AACD;AAUA,eAAsB,WACrB,MACA,EAAE,QAAQ,OAAM,GAAuD;AAEvE,QAAM,WAAW,gBAAgB,WAAW,OAAO,IAAI,SAAS,IAAI;AACpE,SAAO,SAAS,MAAM,iCAAiC;AACvD,MAAI;AACH,UAAM,uBAAuB,IAAI,SAChC,SAAS,KAAK,YAAY,IAAI,oBAAoB,MAAM,GAAG,EAAE,OAAM,CAAE,CAAC;AAEvE,UAAM,SAAS,MAAM,qBAAqB,YAAW;AACrD,WAAO;EACR,QAAQ;AACP,qCAAQ;AACR,UAAM,IAAI,MAAM,oBAAoB,MAAM,EAAE;EAC7C;AACD;;;ACjWM,IAAO,gBAAP,MAAO,eAAa;EAGzB,YAAY,eAAqC,OAAuB;AAFxE,gCAAO;AAGN,WAAO,cAAc,YAAY,GAAG,mCAAmC;EACxE;EAEA,OAAO,WACN,eACA,MAAsB;AAEtB,WAAO,IAAI,eAAc,eAAe,IAAI;EAC7C;;;;;EAMA,OAAO,MAAc;AACpB,UAAM,IAAI,MACT,gHAAgH;EAElH;;;;;;EAOA,OAAO,KAAa;AACnB,WAAO;EACR;;;;AC1CD,IAAM,mBAAmB,wBAAuB;AAEhD,SAAS,0BAAuB;AAC/B,QAAM,IAAI,IAAI,YAAY,CAAC,SAAU,CAAC;AACtC,QAAM,IAAI,IAAI,WAAW,EAAE,QAAQ,EAAE,YAAY,EAAE,UAAU;AAC7D,SAAO,EAAE,EAAE,CAAC,MAAM;AACnB;AAEA,SAAS,kBACR,YAAoC;AAEpC,MAAI,uBAAuB,YAAY;AACtC,WAAO,WAAW;EACnB;AAEA,SAAO;AACR;AAlBA;AAoBM,IAAO,cAAP,MAAO,YAAU;EAQtB,YACC,eACA,MAAgE;AATjE,gCAAO;AACP;AACA;AACA;AACA;AACA;AAMC,uBAAK,SAAU,+CAAe;AAC9B,uBAAK,aAAc,QAAQ,KAAK,SAAS;AACzC,uBAAK,QAAS,KAAK;AACnB,uBAAK,SAAU,YAAY,KAAK,OAAO,GAAG;AAG1C,UAAM,SAAS,KAAI,mBAAK,cAAY,CAAC;AACrC,uBAAK,oBAAqB,OAAO;EAClC;EAEA,OAAO,WACN,eACA,MAAgE;AAEhE,WAAO,IAAI,YAAW,eAAe,IAAI;EAC1C;EAEA,OAAO,KAAa;AACnB,QAAI,QAAQ,IAAI,WAAW,IAAI,KAAK,MAAM;AAC1C,QAAI,oBAAoB,mBAAK,aAAY,OAAO;AAC/C,uBAAiB,OAAO,kBAAkB,mBAAK,YAAW,CAAC;IAC5D;AACA,WAAO;EACR;EAEA,OAAO,OAAiB;AACvB,QAAI,oBAAoB,mBAAK,aAAY,OAAO;AAC/C,uBAAiB,OAAO,kBAAkB,mBAAK,YAAW,CAAC;IAC5D;AACA,WAAO;MACN,MAAM,KAAI,mBAAK,cACd,MAAM,QACN,MAAM,YACN,MAAM,aAAa,mBAAK,mBAAkB;MAE3C,OAAO,mBAAK;MACZ,QAAQ,mBAAK;;EAEf;;AAhDA;AACA;AACA;AACA;AACA;AANK,IAAO,aAAP;;;AC1BA,IAAO,cAAP,MAAO,aAAW;EAAlB;AACI,gCAAO;;EAChB,OAAO,aAAU;AAChB,WAAO,IAAI,aAAW;EACvB;EACA,OAAO,GAAa;AACnB,UAAM,IAAI,MAAM,iBAAiB;EAClC;EACA,OAAO,KAAe;AACrB,WAAO,IAAI,WAAW,IAAI,QAAQ,IAAI,YAAY,IAAI,aAAa,CAAC;EACrE;;;;ACJK,IAAO,YAAP,MAAO,WAAS;EAAhB;AACL,gCAAO;;EAEP,OAAO,WAAW,GAAkB;AACnC,WAAO,IAAI,WAAS;EACrB;EAEA,OAAOC,SAAkB;AACxB,UAAM,IAAI,MACT,gGAAgG;EAElG;EAEA,MAAM,OAAO,OAAiB;AAC7B,UAAM,SAAS,MAAM,WAAW,OAAO,EAAE,QAAQ,OAAM,CAAE;AACzD,WAAO,IAAI,WAAW,MAAM;EAC7B;;;;ACGD,SAAS,sBAAsB,MAAuB,OAAa;AAClE,SACC,CAAC,OAAO,MAAM,KAAK,GACnB,uEAAuE;AAExE,SACC,UAAU,OAAO,mBACjB,4EAA4E;AAE7E,SACC,UAAU,OAAO,mBACjB,6EAA6E;AAE9E,SAAO;AACR;AAGA,SAAS,mBACR,MACA,OAA8B;AAE9B,SAAO,iBAAiB,UAAU,CAAC,MAAM,QAAQ,KAAK,IACnD,OAAO,KAAK,KAAK,EAChB,KAAI,EACJ,OACA,CAAC,QAAQ,QAAwB;AAChC,WAAO,GAAG,IAAI,MAAM,GAAG;AACvB,WAAO;EACR,GACA,CAAA,CAA6B,IAE9B;AACJ;AAvDA;AAyDM,IAAO,aAAP,MAAO,WAAS;EAMrB,YAAmB,gBAAiC,CAAA,GAAE;AAAnC;AALnB,gCAAO;AAEP;AACA;AAEmB,SAAA,gBAAA;AAElB,UAAM,EACL,WAAW,SACX,WAAW,OACX,eAAe,MACf,iBAAiB,MACjB,YAAY,MACZ,YAAY,MACZ,QACA,SAAS,KAAI,IACV;AAEJ,QAAI,aAAa,cAAc;AAC/B,QAAI,CAAC,YAAY;AAGhB,UAAI,CAAC,QAAQ;AACZ,qBAAa,CAAC,KAAK,GAAG;MACvB,OAAO;AACN,qBAAa,CAAC,MAAM,IAAI;MACzB;IACD;AAEA,uBAAK,iBAAkB;MACtB;MACA;MACA;MACA;MACA;MACA;MACA;MACA;;AAED,uBAAK,iBAAkB,EAAE,OAAM;EAChC;EACA,OAAO,WAAW,eAA8B;AAC/C,WAAO,IAAI,WAAU,aAAa;EACnC;EAEA,OAAO,KAAsB;AAC5B,UAAM,EACL,QACA,UACA,cACA,gBACA,WACA,UAAS,IACN,mBAAK;AACT,WACC,aAAa,SACb,oDAAoD;AAErD,UAAM,qBAAyC,CAAA;AAI/C,WACC,gBACA,4FAA4F;AAG7F,QAAI,CAAC,WAAW;AAEf,yBAAmB,KAAK,qBAAqB;IAC9C;AACA,QAAI,WAAW;AAGd,yBAAmB,KAAK,kBAAkB;IAC3C;AAEA,UAAM,QAAQ,MAAM,KAAK,IAAI,IAAI;AACjC,UAAM,KAAK,IAAI;AACf,UAAM,KAAK,IAAI,KAAK;AAEpB,QAAI;AACJ,QAAI,mBAAmB,QAAQ;AAC9B,iBAAW,CAAC,KAAK,UAAS;AACzB,YAAI,YAAY;AAChB,iBAAS,gBAAgB,oBAAoB;AAC5C,sBAAY,aAAa,KAAK,SAAS;QACxC;AACA,eAAO;MACR;IACD;AACA,QAAI,WAAW,KAAK,UAAU,OAAO,UAAU,MAAM;AAErD,QAAI,cAAc;AAKjB,iBAAW,SAAS,QAAQ,oBAAoB,CAAC,QAAO;AACvD,cAAM,WAAW,OAAO,IAAI,WAAW,CAAC,EAAE,SAAS,EAAE,CAAC;AACtD,cAAM,UAAU,SAAS,UAAU,SAAS,SAAS,CAAC;AACtD,eAAO,MAAM,OAAO;MACrB,CAAC;IACF;AACA,WAAO,IAAI,YAAW,EAAG,OAAO,QAAQ;EACzC;EAEA,OAAO,OAAiB;AACvB,UAAM,EAAE,OAAM,IAAK,mBAAK;AAExB,WAAO,QAAQ,qDAAqD;AAEpE,UAAM,QAAQ,mBAAmB,KAAK;AACtC,UAAM,QAAQ,MAAM,IAAG;AACvB,UAAM,IAAG;AAGT,WAAO,OAAO,mCAAmC;AACjD,UAAM,SAAS,YAAY,OAAO,GAAG;AACrC,UAAM,OAAO;AACb,WAAO,EAAE,MAAM,OAAO,OAAM;EAC7B;;AAvHA;AACA;AAJK,IAAO,YAAP;;;ACzCN,SAAS,MAA0B,KAAkB;AACpD,MACC,eAAe,aACf,eAAe,mBACf,eAAe,oBACd;AAED,UAAM,OAA2B,IAAI,MAAM,KAAK;MAC/C,IAAI,QAAQ,MAAI;AACf,eAAO,OAAO,IAAI,OAAO,IAAI,CAAC;MAC/B;MACA,IAAI,QAAQ,MAAM,OAAK;AAEtB,eAAO,IAAI,OAAO,IAAI,GAAG,KAAK;AAC9B,eAAO;MACR;KACA;AACD,WAAO;EACR;AAEA,SAAO;AACR;AAEA,SAAS,WACR,OACA,OAAY;AAEZ,MAAI;AACJ,MACC,MAAM,gBAAgB,mBACtB,MAAM,gBAAgB,oBACrB;AACD,WAAO,IAAK,MAAM;;MAEjB,MAAM,KAAK;MACX,MAAM,KAAK;IAAK;EAElB,OAAO;AACN,WAAO,IAAK,MAAM,YACjB,MAAM,KAAK,MAAM;EAEnB;AACA,SAAO;IACN;IACA,OAAO,MAAM;IACb,QAAQ,YAAY,MAAM,OAAO,KAAK;;AAExC;AAEA,SAAS,oBACR,KACA,QAAa;AAEb,MAAI,MAAM,WAAW,KAAK,MAAM;AAChC,MAAI,SAAS,IAAI,MAAM;AACvB,MAAI,OAAO,IAAI,KAAK;AACpB,MAAI,QAAQ,MAAM,MAAM,EAAE,KAAK,CAAC;AAEhC,MAAI,WAAW,MAAM,IAAI,IAAI;AAC7B,MAAI,WAAW,MAAM,IAAI,IAAI;AAE7B,WAAS,UAAU,GAAG,UAAU,MAAM,WAAW;AAChD,QAAI,UAAU;AACd,aAAS,MAAM,GAAG,MAAM,QAAQ,OAAO;AACtC,iBAAW,MAAM,GAAG,IAAI,IAAI,OAAO,GAAG;IACvC;AACA,aAAS,OAAO,IAAI,SAAS,OAAO;AAEpC,UAAM,CAAC,KAAK;AACZ,aAAS,MAAM,GAAG,MAAM,QAAQ,OAAO;AACtC,UAAI,MAAM,GAAG,MAAM,IAAI,MAAM,GAAG,GAAG;AAClC,YAAI,MAAM,MAAM,QAAQ;AACvB;QACD;AACA,cAAM,GAAG,IAAI;AACb,cAAM,MAAM,CAAC,KAAK;MACnB;IACD;EACD;AAEA,SAAO;AACR;AAGA,SAAS,UAAU,OAAsB;AACxC,MAAI,OAAO,MAAM,MAAM;AACvB,SACC,SAAS,MAAM,OAAO,QACtB,6CAA6C;AAE9C,SAAO,MAAM,OACX,IAAI,CAAC,GAAG,OAAO,EAAE,QAAQ,GAAG,OAAO,EAAC,EAAG,EACvC,KAAK,CAAC,GAAG,MAAM,EAAE,SAAS,EAAE,MAAM,EAClC,IAAI,CAAC,UAAU,MAAM,KAAK;AAC7B;AAEA,SAAS,cAAc,OAAwB,QAAa;AAC3D,MAAI,SAAS,UAAU,KAAK;AAC5B,SAAO,OAAO,WAAW,OAAO,QAAQ,mBAAmB;AAC3D,SAAO,OAAO,MAAM,CAAC,KAAK,MAAM,QAAQ,OAAO,CAAC,CAAC;AAClD;AA/GA;AAmHM,IAAO,kBAAP,MAAO,gBAAc;EAK1B,YAAY,eAAkC,MAAyB;AAJvE,gCAAO;AACP;AACA;AAGC,QAAI,QAAQ,cAAc,SAAS;AACnC,QAAI,OAAO,KAAK,MAAM;AACtB,QAAI,QAAQ,IAAI,MAAc,IAAI;AAClC,QAAI,eAAe,IAAI,MAAc,IAAI;AAEzC,QAAI,UAAU,KAAK;AAClB,eAAS,IAAI,GAAG,IAAI,MAAM,EAAE,GAAG;AAC9B,cAAM,CAAC,IAAI;AACX,qBAAa,CAAC,IAAI;MACnB;IACD,WAAW,UAAU,KAAK;AACzB,eAAS,IAAI,GAAG,IAAI,MAAM,EAAE,GAAG;AAC9B,cAAM,CAAC,IAAI,OAAO,IAAI;AACtB,qBAAa,CAAC,IAAI,OAAO,IAAI;MAC9B;IACD,OAAO;AACN,cAAQ;AACR,YAAM,QAAQ,CAAC,GAAG,MAAK;AACtB,eACC,aAAa,CAAC,MAAM,QACpB,wBAAwB,KAAK,UAAU,KAAK,CAAC,EAAE;AAEhD,qBAAa,CAAC,IAAI;MACnB,CAAC;IACF;AAEA,uBAAK,QAAS;AACd,uBAAK,eAAgB;EACtB;EAEA,OAAO,WACN,eACA,MAAyB;AAEzB,WAAO,IAAI,gBAAe,eAAe,IAAI;EAC9C;EAEA,OAA2B,KAAa;AACvC,QAAI,cAAc,KAAK,mBAAK,cAAa,GAAG;AAE3C,aAAO;IACR;AACA,WAAO,oBAAoB,KAAK,mBAAK,cAAa;EACnD;EAEA,OAA2B,KAAa;AACvC,WAAO;MACN,MAAM,IAAI;MACV,OAAO,IAAI;MACX,QAAQ,YAAY,IAAI,OAAO,mBAAK,OAAM;;EAE5C;;AAvDA;AACA;AAHK,IAAO,iBAAP;;;ACzHN,IAAAC,SAAA;AAEM,IAAO,YAAP,MAAO,UAAQ;EAKpB,YAAY,OAAe;AAJlB,gCAAO;AAChB,uBAAAA;AACA;AAGC,uBAAKA,SAAS;AACd,uBAAK,UAAW,YAAY,OAAO,GAAG;EACvC;EACA,OAAO,WAAW,GAAY,MAAyB;AACtD,WAAO,IAAI,UAAS,KAAK,KAAK;EAC/B;EAEA,OAAO,QAAyB;AAC/B,UAAM,IAAI,MAAM,yBAAyB;EAC1C;EAEA,OAAO,OAAiB;AACvB,QAAI,UAAU,IAAI,YAAW;AAC7B,QAAI,OAAO,IAAI,SAAS,MAAM,MAAM;AACpC,QAAI,OAAO,MAAM,KAAK,UAAU,GAAG,IAAI,CAAC;AACxC,QAAI,MAAM;AACV,aAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AACrC,UAAI,cAAc,KAAK,UAAU,KAAK,IAAI;AAC1C,aAAO;AACP,WAAK,CAAC,IAAI,QAAQ,OAChB,MAAM,OAAuB,MAAM,KAAK,MAAM,WAAW,CAAC;AAE5D,aAAO;IACR;AACA,WAAO,EAAE,MAAM,OAAO,mBAAKA,UAAQ,QAAQ,mBAAK,UAAQ;EACzD;;AA7BAA,UAAA;AACA;AAHK,IAAO,WAAP;;;ACGA,IAAO,YAAP,MAAO,WAAS;EAAhB;AACL,gCAAO;;EAEP,OAAO,WAAW,GAAkB;AACnC,WAAO,IAAI,WAAS;EACrB;EAEA,OAAOC,SAAkB;AACxB,UAAM,IAAI,MACT,yFAAyF;EAE3F;EAEA,MAAM,OAAO,OAAiB;AAC7B,UAAM,SAAS,MAAM,WAAW,OAAO,EAAE,QAAQ,UAAS,CAAE;AAC5D,WAAO,IAAI,WAAW,MAAM;EAC7B;;;;ACGD,SAAS,0BAAuB;AAC/B,UAAO,oBAAI,IAAG,GACZ,IAAI,SAAS,MAAM,OAAO,qBAAiB,EAAE,KAAK,CAAC,MAAM,EAAE,OAAO,CAAC,EACnE,IAAI,OAAO,MAAM,OAAO,mBAAe,EAAE,KAAK,CAAC,MAAM,EAAE,OAAO,CAAC,EAC/D,IAAI,QAAQ,MAAM,OAAO,oBAAgB,EAAE,KAAK,CAAC,MAAM,EAAE,OAAO,CAAC,EACjE,IAAI,QAAQ,MAAM,SAAS,EAC3B,IAAI,QAAQ,MAAM,SAAS,EAC3B,IAAI,aAAa,MAAM,cAAc,EACrC,IAAI,SAAS,MAAM,UAAU,EAC7B,IAAI,UAAU,MAAM,WAAW,EAC/B,IAAI,aAAa,MAAM,QAAQ,EAC/B,IAAI,SAAS,MAAM,SAAS,EAC5B,IAAI,YAAY,MAAM,aAAa;AACtC;AAEO,IAAM,WACZ,wBAAuB;AAElB,SAAU,sBACf,gBAAoC;AAKpC,MAAI;AACJ,SAAO;IACN,MAAM,OAAO,OAAmB;AAC/B,UAAI,CAAC;AAAQ,iBAAS,MAAM,YAAY,cAAc;AACtD,iBAAW,SAAS,OAAO,gBAAgB;AAC1C,gBAAQ,MAAM,MAAM,OAAO,KAAK;MACjC;AACA,UAAI,QAAQ,MAAM,OAAO,eAAe,OAAO,KAAK;AACpD,iBAAW,SAAS,OAAO,gBAAgB;AAC1C,gBAAQ,MAAM,MAAM,OAAO,KAAK;MACjC;AACA,aAAO;IACR;IACA,MAAM,OAAO,OAAiB;AAC7B,UAAI,CAAC;AAAQ,iBAAS,MAAM,YAAY,cAAc;AACtD,eAAS,IAAI,OAAO,eAAe,SAAS,GAAG,KAAK,GAAG,KAAK;AAC3D,gBAAQ,MAAM,OAAO,eAAe,CAAC,EAAE,OAAO,KAAK;MACpD;AACA,UAAI,QAAQ,MAAM,OAAO,eAAe,OAAO,KAAK;AACpD,eAAS,IAAI,OAAO,eAAe,SAAS,GAAG,KAAK,GAAG,KAAK;AAC3D,gBAAQ,MAAM,OAAO,eAAe,CAAC,EAAE,OAAO,KAAK;MACpD;AACA,aAAO;IACR;;AAEF;AAiBA,eAAe,YAAgC,YAA4B;AAC1E,MAAI,WAAW,WAAW,OAAO,IAAI,OAAO,SAAQ;AA3FrD,QAAAC;AA4FE,QAAI,QAAQ,QAAMA,MAAA,SAAS,IAAI,KAAK,IAAI,MAAtB,gBAAAA;AAClB,WAAO,OAAO,kBAAkB,KAAK,IAAI,EAAE;AAC3C,WAAO,EAAE,OAAO,KAAI;EACrB,CAAC;AACD,MAAI,iBAAyC,CAAA;AAC7C,MAAI;AACJ,MAAI,iBAAsC,CAAA;AAC1C,iBAAe,EAAE,OAAO,KAAI,KAAM,UAAU;AAC3C,QAAI,QAAQ,MAAM,WAAW,KAAK,eAAe,UAAU;AAC3D,YAAQ,MAAM,MAAM;MACnB,KAAK;AACJ,uBAAe,KAAK,KAAwC;AAC5D;MACD,KAAK;AACJ,yBAAiB;AACjB;MACD;AACC,uBAAe,KAAK,KAAqC;IAC3D;EACD;AACA,MAAI,CAAC,gBAAgB;AACpB,WACC,yBAAyB,UAAU,GACnC,iBAAiB,WAAW,SAAS,2BAA2B;AAEjE,qBAAiB,WAAW,WAAW,EAAE,QAAQ,SAAQ,GAAI,UAAU;EACxE;AACA,SAAO,EAAE,gBAAgB,gBAAgB,eAAc;AACxD;AAEA,SAAS,yBACR,MAAsB;AAEtB,SAAO,KAAK,cAAc;AAC3B;;;AC/HM,IAAO,oBAAP,cAAiC,MAAK;EAC3C,YAAY,SAAiB,UAA6B,CAAA,GAAE;AAC3D,UAAM,mBAAmB,OAAO,IAAI,OAAO;AAC3C,SAAK,OAAO;EACb;;AAGK,IAAO,WAAP,cAAwB,MAAK;EAClC,YAAY,MAAY;AACvB,UAAM,gBAAgB,IAAI,EAAE;AAC5B,SAAK,OAAO;EACb;;;;ACsBD,eAAe,0BACd,OACA,mBAAqC;AAErC,QAAM,cAAc,qBAAqB;AACzC,MAAI,QAAQ,MAAM,MAAM,IAAI,IAAI,WAAW,EAAE;AAC7C,MAAI,CAAC,OAAO;AACX,UAAM,IAAI,kBAAkB,4BAA4B;MACvD,OAAO,IAAI,SAAS,IAAI,WAAW,EAAE;KACrC;EACF;AACA,MAAI,OAA6B,mBAAmB,KAAK;AACzD,SACC,KAAK,6BAA6B,GAClC,kCAAkC;AAEnC,SAAO;AACR;AASA,SAAS,YAAY,KAAW;AAC/B,SACC,IAAI,SAAS,SAAS,KACtB,IAAI,SAAS,SAAS,KACtB,IAAI,SAAS,SAAS,KACtB,IAAI,SAAS,WAAW;AAE1B;AAEA,SAAS,MAAM,MAAc;AAC5B,SAAO,iBAAiB,QAAQ,KAAK,gBAAgB;AACtD;AAgCA,eAAsB,iBACrB,OACA,OAAgC,CAAA,GAAE;AAvGnC,MAAAC;AAyGC,MAAI,UAAU,MAAM,0BAA0B,OAAO,KAAK,WAAW;AACrE,MAAI,aAA6C,CAAA;AACjD,WAAS,CAAC,KAAK,KAAK,KAAK,OAAO,QAAQ,QAAQ,QAAQ,GAAG;AAC1D,eAAW,IAAI,GAAG,EAAE,IAAI;EACzB;AAEA,SAAO;IACN,MAAM,OACF,MAA8B;AAEjC,UAAI,CAAC,KAAKC,KAAI,IAAI;AAClB,UAAI,WAAW,GAAG,GAAG;AACpB,eAAO,mBAAmB,WAAW,GAAG,CAAC;MAC1C;AACA,UAAI,cAAc,MAAM,MAAM,IAAI,KAAKA,KAAI;AAC3C,UAAI,YAAY,GAAG,KAAK,aAAa;AACpC,YAAI,OAAO,mBAAmB,WAAW;AACzC,mBAAW,GAAG,IAAI;MACnB;AACA,aAAO;IACR;;;;IAIA,WAAUD,MAAA,MAAM,aAAN,gBAAAA,IAAgB,KAAK;IAC/B,WAAQ;AACP,UAAI,WAA8D,CAAA;AAClE,eAAS,CAAC,KAAK,KAAK,KAAK,OAAO,QAAQ,UAAU,GAAG;AACpD,YAAI,QAAQ,IAAI,MAAM,GAAG;AACzB,YAAI,WAAW,MAAM,IAAG;AACxB,YAAI,OAAQ,MAAM,KAAK,GAAG,KAAK;AAC/B,YAAI,aAAa;AAAW,mBAAS,KAAK,EAAE,MAAM,MAAM,QAAO,CAAE;AACjE,YAAI,aAAa;AAAW,mBAAS,KAAK,EAAE,MAAM,MAAM,QAAO,CAAE;AACjE,YAAI,MAAM,KAAK,GAAG;AACjB,mBAAS,KAAK,EAAE,MAAM,MAAM,MAAM,UAAS,CAAE;QAC9C;MACD;AACA,aAAO;IACR;;AAEF;AAeA,eAAsB,oBACrB,OACA,OAAgC,CAAA,GAAE;AAElC,SAAO,iBAAiB,OAAO,IAAI,EAAE,MAAM,CAAC,UAAkB;AAC7D,mBAAe,OAAO,iBAAiB;AACvC,WAAO;EACR,CAAC;AACF;;;ACnKA,IAAM,eAAe;AAEf,SAAU,4BACf,UACA,aACA,kBACA,iBAAuD;AAEvD,SAAO,SAAS,MAAM,UAAU,uCAAuC;AACvE,MAAI,YAAY,SAAS,MAAM,SAAS,KAAK,SAAS,KAAK;AAC3D,MAAI,cAAc,YAAY,IAC7B,CAAC,GAAG,MAAM,IAAI,gBAAgB,YAAY,CAAC,CAAC;AAE7C,MAAI,cAAc,sBAAsB;IACvC,WAAW;IACX,OAAO,CAAC,GAAG,aAAa,CAAC;IACzB,QAAQ,gBAAgB;GACxB;AAED,MAAI,QAAgD,CAAA;AACpD,SAAO,OAAO,gBAAyB;AACtC,QAAI,cAAc,YAAY,IAAI,CAAC,GAAG,MAAM,KAAK,MAAM,IAAI,YAAY,CAAC,CAAC,CAAC;AAC1E,QAAI,aAAa,SAAS,QAAQ,iBAAiB,WAAW,CAAC,EAAE;AAEjE,QAAI;AACJ,QAAI,cAAc,OAAO;AACxB,cAAQ,MAAM,UAAU;IACzB,OAAO;AACN,UAAI,gBAAgB;AACpB,UAAI,aAAa,KAAK,YAAY,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC;AAC3D,UAAI,QAAQ,MAAM,UAAU,YAAY;QACvC,cAAc,aAAa;OAC3B;AACD,cAAQ,MAAM,UAAU,IAAI,QACzB,MAAM,YAAY,OAAO,KAAK,IAC9B;IACJ;AAEA,QAAI,UAAU,MAAM;AACnB,aAAO;IACR;AAEA,QAAI,EAAE,MAAM,OAAO,OAAM,IAAK;AAC9B,QAAI,gBAAgB,YAClB,IAAI,CAAC,GAAG,MAAM,IAAI,MAAM,CAAC,CAAC,EAC1B,OAAO,CAAC,KAAK,KAAK,QAAQ,MAAM,MAAM,OAAO,GAAG,GAAG,CAAC;AAEtD,QAAI,SAAS,KAAK,aAAa;AAC/B,QAAI,SAAS,KAAK,gBAAgB,CAAC;AAEnC,QAAI,WAAW,gBAAgB,WAAW,cAAc;AACvD,aAAO;IACR;AACA,WAAO,UAAU,YAAY;MAC5B,QAAQ,OAAO,MAAM;MACrB,QAAQ,OAAO,MAAM;KACrB;EACF;AACD;;;ACxCM,IAAO,WAAP,MAAO,UAAQ;EACpB,YACiB,OACA,OAAqB,KAAG;AADxB;AACA;AADA,SAAA,QAAA;AACA,SAAA,OAAA;EACd;EAEH,QAAQ,MAAY;AAGnB,QAAIE,QAAO,IAAI,IACd,UAAU,KAAK,KAAK,SAAS,GAAG,IAAI,KAAK,OAAO,GAAG,KAAK,IAAI,GAAG,EAAE;AAElE,WAAO,IAAI,UACV,KAAK,OACL,mBAAmB,IAAI,IAAI,MAAMA,KAAI,EAAE,QAAQ,CAAiB;EAElE;;AAKK,SAAU,KACf,OAAa;AAEb,SAAO,IAAI,SAAS,SAAS,oBAAI,IAAG,CAAE;AACvC;AAhDA;AAkDM,IAAO,QAAP,cAA6C,SAAe;EAGjE,YAAY,OAAc,MAAoB,UAAuB;AACpE,UAAM,OAAO,IAAI;AAHT,gCAAO;AAChB;AAGC,uBAAK,WAAY;EAClB;EACA,IAAI,QAAK;AACR,WAAO,mBAAK,WAAU;EACvB;;AAPA;AAUD,SAAS,gBACR,QAAuB;AA/DxB,MAAAC;AAiEC,QAAM,wBAAwB,OAAO,KAAK,CAAC,MAAM,EAAE,SAAS,WAAW;AAEvE,WAAOA,MAAA,+DAAuB,kBAAvB,gBAAAA,IAAsC,UAAS;AACvD;AAEA,IAAM,iBAAiB,OAAO,iBAAiB;AAEzC,SAAU,YAAe,KAA4B;AAC1D,SAAO,IAAI,cAAc;AAC1B;AAEA,SAAS,eACR,UACA,UAA0B;AAE1B,MAAI,EAAE,cAAa,IAAK,SAAS,OAAO,KAAK,iBAAiB,KAAK,CAAA;AACnE,MAAI,iBAAiB;IACpB,kBAAkB,yBAAyB,SAAS,kBAAkB;IACtE,YAAY,QAAQ,SAAS,SAAS;IACtC,YAAY,SAAS;;AAGtB,MAAI,eAAe;AAClB,QAAIC,gBAAe,gBAAgB,cAAc,MAAM;AACvD,WAAO;MACN,GAAG;MACH,MAAM;MACN,aAAa,cAAc;MAC3B,OAAO,sBAAsB;QAC5B,WAAW,SAAS;QACpB,OAAO,cAAc;QACrB,QAAQ,cAAc;OACtB;MACD,YAAY,OAAe;AAC1B,eAAO,YAAY,OAAOA,aAAY;MACvC;MACA,iBAAiB,4BAChB,UACA,SAAS,WAAW,cAAc,aAClC,eAAe,kBACf,aAAa;;EAGhB;AAEA,MAAI,eAAe,gBAAgB,SAAS,MAAM;AAClD,SAAO;IACN,GAAG;IACH,MAAM;IACN,aAAa,SAAS,WAAW,cAAc;IAC/C,OAAO,sBAAsB;MAC5B,WAAW,SAAS;MACpB,OAAO,SAAS,WAAW,cAAc;MACzC,QAAQ,SAAS;KACjB;IACD,YAAY,OAAe;AAC1B,aAAO,YAAY,OAAO,YAAY;IACvC;IACA,MAAM,gBAAgB,cAAc,SAAO;AAC1C,UAAI,YAAY,eAAe,iBAAiB,YAAY;AAC5D,UAAI,aAAa,SAAS,QAAQ,SAAS,EAAE;AAC7C,aAAO,SAAS,MAAM,IAAI,YAAY,OAAO;IAC9C;;AAEF;AAjIA,YAAAC;AAyJM,IAAOC,SAAP,eAGI,eAGR,qBAHQ,IAAe;EAKxB,YACC,OACA,MACA,UAA8B;AAE9B,UAAM,OAAO,IAAI;AATT,gCAAO;AAChB,uBAAAD;AACA,wBAAC;AAQA,uBAAKA,YAAY;MAChB,GAAG;MACH,YAAY,sBAAsB,QAAQ;;AAE3C,SAAK,cAAc,IAAI,eAAe,MAAM,QAAQ;EACrD;EAEA,IAAI,QAAK;AACR,WAAO,mBAAKA,YAAU;EACvB;EAEA,IAAI,QAAK;AACR,WAAO,mBAAKA,YAAU;EACvB;EAEA,IAAI,SAAM;AACT,WAAO,KAAK,cAAc,EAAE;EAC7B;EAEA,IAAI,QAAK;AACR,WAAO,mBAAKA,YAAU;EACvB;EAEA,MAAM,SACL,cACA,SAAqC;AAErC,QAAI,UAAU,KAAK,cAAc;AACjC,QAAI,cAAc,MAAM,QAAQ,gBAAgB,cAAc,OAAO;AACrE,QAAI,CAAC,aAAa;AACjB,UAAI,OAAO,QAAQ,YAAY,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC;AACxD,UAAI,OAAO,IAAI,QAAQ,WAAW,IAAI;AAEtC,WAAK,KAAK,QAAQ,UAAU;AAC5B,aAAO;QACN;QACA,OAAO,QAAQ;QACf,QAAQ,QAAQ,YAAY,QAAQ,WAAW;;IAEjD;AACA,WAAO,QAAQ,MAAM,OAAO,WAAW;EACxC;;;;;;;;;;;;;;;;;;EAmBA,GACC,OAAY;AAEZ,WAAO,SAAS,KAAK,OAAO,KAAK;EAClC;;AAzEAA,aAAA;;;AClHD,eAAsB,OACrB,UACA,UAA0D,CAAA,GAAE;AAE5D,MAAI,MAAM,WAAW,WAAW,WAAW,IAAI,SAAS,QAAQ;AAChE,MAAI,WAAW,SAAS;AACvB,QAAI,MAAM,MAAM,aAAa,KAAK,OAAO;AACzC,WAAO;EACR;AACA,SAAO,aAAa,KAAK,OAAO;AACjC;AAEA,eAAe,aACd,UACA,UAA8B,CAAA,GAAE;AAEhC,MAAI,WAAW;IACd,aAAa;IACb,WAAW;IACX,YAAY,QAAQ,cAAc,CAAA;;AAEnC,QAAM,SAAS,MAAM,IACpB,SAAS,QAAQ,WAAW,EAAE,MAC9B,mBAAmB,QAAQ,CAAC;AAE7B,SAAO,IAAI,MAAM,SAAS,OAAO,SAAS,MAAM,QAAQ;AACzD;AAEA,eAAe,aACd,UACA,SAAkC;AAElC,MAAI,WAAW;IACd,aAAa;IACb,WAAW;IACX,OAAO,QAAQ;IACf,WAAW,QAAQ;IACnB,YAAY;MACX,MAAM;MACN,eAAe;QACd,aAAa,QAAQ;;;IAGvB,oBAAoB;MACnB,MAAM;MACN,eAAe;QACd,WAAW,QAAQ,mBAAmB;;;IAGxC,QAAQ,QAAQ,UAAU,CAAA;IAC1B,YAAY,QAAQ,cAAc;IAClC,YAAY,QAAQ,cAAc,CAAA;;AAEnC,QAAM,SAAS,MAAM,IACpB,SAAS,QAAQ,WAAW,EAAE,MAC9B,mBAAmB,QAAQ,CAAC;AAE7B,SAAO,IAAIE,OAAM,SAAS,OAAO,SAAS,MAAM,QAAQ;AACzD;;;ACpGM,UAAW,MAChB,OACA,MACA,OAAO,GAAC;AAER,MAAI,SAAS,QAAW;AACvB,WAAO;AACP,YAAQ;EACT;AACA,WAAS,IAAI,OAAO,IAAI,MAAM,KAAK,MAAM;AACxC,UAAM;EACP;AACD;AAMM,UAAW,WACb,WAAY;AAIf,MAAI,UAAU,WAAW,GAAG;AAC3B;EACD;AAEA,QAAM,YAAY,UAAU,IAAI,CAAC,OAAO,GAAG,OAAO,QAAQ,EAAC,CAAE;AAC7D,QAAM,UAAU,UAAU,IAAI,CAAC,OAAO,GAAG,KAAI,CAAE;AAC/C,MAAI,QAAQ,KAAK,CAAC,MAAM,EAAE,IAAI,GAAG;AAChC,UAAM,IAAI,MAAM,mCAAmC;EACpD;AACA,WAAS,IAAI,OAAO;AACnB,QAAI,QAAQ,CAAC,EAAE,MAAM;AAEpB,gBAAU,CAAC,IAAI,UAAU,CAAC,EAAE,OAAO,QAAQ,EAAC;AAC5C,cAAQ,CAAC,IAAI,UAAU,CAAC,EAAE,KAAI;AAE9B,UAAI,EAAE,KAAK,UAAU,QAAQ;AAC5B;MACD;IACD,OAAO;AAEN,YAAM,QAAQ,IAAI,CAAC,EAAE,MAAK,MAAO,KAAK;AACtC,UAAI;IACL;AACA,YAAQ,CAAC,IAAI,UAAU,CAAC,EAAE,KAAI;EAC/B;AACD;AAGM,SAAU,cACf,EAAE,OAAO,MAAM,KAAI,GACnB,QAAc;AAEd,MAAI,SAAS,GAAG;AACf,UAAM,IAAI,MAAM,2BAA2B;EAC5C;AACA,SAAO,QAAQ;AACf,QAAM,mBAAmB,OAAO;AAGhC,QAAM,CAAC,OAAO,KAAK,IAAI,mBAAmB,CAAC,IAAI,SAAS,CAAC,IAAI,CAAC,GAAG,MAAM;AAGvE,MAAI,UAAU,MAAM;AACnB,YAAQ,mBAAmB,QAAQ;EACpC,OAAO;AACN,QAAI,QAAQ,GAAG;AACd,eAAS;AACT,UAAI,QAAQ,OAAO;AAClB,gBAAQ;MACT;IACD,WAAW,QAAQ,OAAO;AACzB,cAAQ;IACT;EACD;AAGA,MAAI,SAAS,MAAM;AAClB,WAAO,mBAAmB,QAAQ;EACnC,OAAO;AACN,QAAI,OAAO,GAAG;AACb,cAAQ;AACR,UAAI,OAAO,OAAO;AACjB,eAAO;MACR;IACD,WAAW,OAAO,OAAO;AACxB,aAAO;IACR;EACD;AAEA,SAAO,CAAC,OAAO,MAAM,IAAI;AAC1B;AASM,SAAU,MACf,OACA,MACA,OAAsB,MAAI;AAE1B,MAAI,SAAS,QAAW;AACvB,WAAO;AACP,YAAQ;EACT;AACA,SAAO;IACN;IACA;IACA;;AAEF;AAGM,SAAU,eAAY;AAC3B,QAAM,WAA4B,CAAA;AAClC,SAAO;IACN,KAAK,CAAC,OAAO,SAAS,KAAK,GAAE,CAAE;IAC/B,QAAQ,MAAM,QAAQ,IAAI,QAAQ;;AAEpC;;;AC7HM,IAAO,aAAP,cAA0B,MAAK;EACpC,YAAY,KAAW;AACtB,UAAM,GAAG;AACT,SAAK,OAAO;EACb;;AAGD,SAAS,qBACR,WACA,OAAwB;AAExB,QAAM,IAAI,WACT,yCAAyC,MAAM,MAAM,SAAS,UAAU,MAAM,EAAE;AAElF;AAEA,SAAS,gBAAgB,SAAe;AACvC,QAAM,IAAI,WACT,iDAAiD,OAAO,EAAE;AAE5D;AAEA,SAAS,oBAAiB;AACzB,QAAM,IAAI,WAAW,0CAA0C;AAChE;AAEA,SAAS,uBACR,WACA,OAAwB;AAExB,MAAI,UAAU,SAAS,MAAM,QAAQ;AACpC,yBAAqB,WAAW,KAAK;EACtC;AACD;AAEM,SAAU,4BAA4B,SAAiB,SAAe;AAE3E,YAAU,KAAK,MAAM,OAAO;AAE5B,MAAI,UAAU,GAAG;AAChB,cAAU,UAAU;EACrB;AAEA,MAAI,WAAW,WAAW,UAAU,GAAG;AACtC,oBAAgB,OAAO;EACxB;AACA,SAAO;AACR;AAaA,IAAM,gBAAN,MAAmB;EAMlB,YAAY,EAAE,SAAS,SAAS,cAAa,GAAsB;AALnE;AACA;AACA;AACA;AAIC,cAAU,4BAA4B,SAAS,OAAO;AAEtD,SAAK,UAAU;AACf,SAAK,UAAU;AACf,SAAK,gBAAgB;AACrB,SAAK,SAAS;EACf;EAEA,EAAE,OAAO,QAAQ,IAAC;AACjB,UAAM,eAAe,KAAK,MAAM,KAAK,UAAU,KAAK,aAAa;AACjE,UAAM,aAAa,eAAe,KAAK;AACvC,UAAM,gBAAgB,KAAK,UAAU;AACrC,UAAM,EAAE,cAAc,cAAa;EACpC;;AAeD,IAAM,kBAAN,MAAqB;EAUpB,YAAY,EAAE,SAAS,SAAS,cAAa,GAAwB;AATrE;AACA;AACA;AAEA;AACA;AACA;AACA;AAIC,UAAM,CAAC,OAAO,MAAM,IAAI,IAAI,cAAc,SAAS,OAAO;AAC1D,SAAK,QAAQ;AACb,SAAK,OAAO;AACZ,SAAK,OAAO;AACZ,QAAI,KAAK,OAAO;AAAG,wBAAiB;AAEpC,SAAK,UAAU;AACf,SAAK,gBAAgB;AACrB,SAAK,SAAS,KAAK,IAAI,GAAG,KAAK,MAAM,KAAK,OAAO,KAAK,SAAS,KAAK,IAAI,CAAC;AACzE,SAAK,UAAU,KAAK,KAAK,KAAK,UAAU,KAAK,aAAa;EAC3D;EAEA,EAAE,OAAO,QAAQ,IAAC;AAEjB,UAAM,oBAAoB,KAAK,MAAM,KAAK,QAAQ,KAAK,aAAa;AACpE,UAAM,kBAAkB,KAAK,KAAK,KAAK,OAAO,KAAK,aAAa;AAChE,eAAW,gBAAgB,MAAM,mBAAmB,eAAe,GAAG;AAErE,YAAM,aAAa,eAAe,KAAK;AACvC,YAAM,YAAY,KAAK,IACtB,KAAK,UACJ,eAAe,KAAK,KAAK,aAAa;AAGxC,YAAM,gBAAgB,YAAY;AAElC,UAAI,iBAAiB;AACrB,UAAI,sBAAsB;AAC1B,UAAI,KAAK,QAAQ,YAAY;AAE5B,cAAM,aAAa,aAAa,KAAK,SAAS,KAAK;AACnD,YAAI;AAAW,iCAAuB,KAAK,OAAO;AAElD,yBAAiB,KAAK,MAAM,aAAa,KAAK,SAAS,KAAK,IAAI;MACjE,OAAO;AAEN,8BAAsB,KAAK,QAAQ;MACpC;AAGA,YAAM,qBACL,KAAK,OAAO,YAAY,gBAAgB,KAAK,OAAO;AAErD,YAAM,gBAAyB;QAC9B;QACA;QACA,KAAK;;AAEN,YAAM,mBAAmB,KAAK,MAC5B,qBAAqB,uBAAuB,KAAK,IAAI;AAGvD,YAAM,cAAuB;QAC5B;QACA,iBAAiB;QACjB;;AAED,YAAM,EAAE,cAAc,eAAe,YAAW;IACjD;EACD;;AAGK,SAAU,oBACf,WACA,OAAwB;AAExB,MAAI,aAAiC,CAAA;AACrC,MAAI,cAAc,MAAM;AACvB,iBAAa,MAAM,IAAI,CAAC,MAAM,MAAM,IAAI,CAAC;EAC1C,WAAW,MAAM,QAAQ,SAAS,GAAG;AACpC,iBAAa,UAAU,IAAI,CAAC,MAAM,KAAK,MAAM,IAAI,CAAC;EACnD;AACA,yBAAuB,YAAY,KAAK;AACxC,SAAO;AACR;AAoBM,IAAO,eAAP,MAAmB;EAIxB,YAAY,EAAE,WAAW,OAAO,YAAW,GAAqB;AAHhE;AACA;AAIC,SAAK,eAAe,oBAAoB,WAAW,KAAK,EAAE,IACzD,CAAC,SAAS,MAAK;AACd,aAAO,KACN,OAAO,YAAY,WAAW,gBAAgB,iBAC7C;;QAED;QACA,SAAS,MAAM,CAAC;QAChB,eAAe,YAAY,CAAC;OAC5B;IACF,CAAC;AAEF,SAAK,QAAQ,KAAK,aAChB,OAAO,CAAC,QAAQ,eAAe,eAAe,EAC9C,IAAI,CAAC,SAAS,KAAK,MAAM;EAC5B;EAEA,EAAE,OAAO,QAAQ,IAAC;AACjB,eAAW,mBAAmB,QAAQ,GAAG,KAAK,YAAY,GAAG;AAC5D,YAAM,eAAe,gBAAgB,IAAI,CAAC,MAAM,EAAE,YAAY;AAC9D,YAAM,UAA+B,gBAAgB,IAAI,CAAC,MAAK;AAC9D,YAAI,iBAAiB,GAAG;AACvB,iBAAO,EAAE,MAAM,EAAE,eAAe,IAAI,EAAE,YAAW;QAClD;AACA,eAAO,EAAE,MAAM,EAAE,eAAe,IAAI,KAAI;MACzC,CAAC;AACD,YAAM,EAAE,cAAc,QAAO;IAC9B;EACD;;;;ACjOD,SAAS,OACR,KACA,KAAW;AAEX,SAAQ,SAAS,MAAM,IAAI,IAAI,GAAG,IAAI,IAAI,GAAG;AAC9C;AAEA,eAAsB,IAMrB,KACA,WACA,MACAC,SAIC;AAhCF,MAAAC;AAoCC,MAAI,UAAU,YAAY,GAAG;AAC7B,MAAI,UAAU,IAAI,aAAa;IAC9B;IACA,OAAO,IAAI;IACX,aAAa,IAAI;GACjB;AAED,MAAI,MAAMD,QAAO,QAChB,IAAI,QAAQ,WAAW,QAAQ,MAAM,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC,CAAC,GAC/D,QAAQ,OACR,QAAQ,YAAY,QAAQ,KAAK,CAAC;AAGnC,MAAI,UAAQC,MAAA,KAAK,iBAAL,gBAAAA,IAAA,eAAyB,aAAY;AACjD,aAAW,EAAE,cAAc,QAAO,KAAM,SAAS;AAChD,UAAM,IAAI,YAAW;AACpB,UAAI,EAAE,MAAM,OAAO,OAAM,IAAK,MAAM,IAAI,SAAS,cAAc,KAAK,IAAI;AACxE,UAAI,QAAQD,QAAO,QAAQ,MAAM,OAAO,MAAM;AAC9C,MAAAA,QAAO,eAAe,KAAK,OAAO,OAAO;IAC1C,CAAC;EACF;AAEA,QAAM,MAAM,OAAM;AAIlB,SAAO,QAAQ,MAAM,WAAW,IAAI,OAAO,IAAI,MAAM,CAAC,IAAI;AAC3D;;;AClDA,SAAS,wBAAwB,GAAoB;AACpD,MAAI,EAAE,MAAM;AAAM,WAAO,EAAE,MAAM,EAAE,IAAI,IAAI,EAAE,KAAI;AACjD,SAAO,EAAE,MAAM,EAAE,IAAI,IAAI,EAAE,KAAI;AAChC;AAEA,eAAsB,IACrB,KACA,WACA,OACA,MACAE,SAIC;AAED,QAAM,UAAU,YAAY,GAAG;AAC/B,MAAI,QAAQ,SAAS,WAAW;AAC/B,UAAM,IAAI,MAAM,uCAAuC;EACxD;AACA,QAAM,UAAU,IAAI,aAAa;IAChC;IACA,OAAO,IAAI;IACX,aAAa,IAAI;GACjB;AAMD,QAAM,aAAa,IAAI,OAAO,OAAO,CAAC,GAAG,MAAM,IAAI,GAAG,CAAC;AACvD,QAAM,QAAQ,KAAK,eAAe,KAAK,aAAY,IAAK,aAAY;AAIpE,aAAW,EAAE,cAAc,QAAO,KAAM,SAAS;AAChD,UAAM,kBAAkB,QAAQ,IAAI,CAAC,MAAM,EAAE,IAAI;AACjD,UAAM,UAAU,QAAQ,IAAI,uBAAuB;AACnD,UAAM,IAAI,YAAW;AAEpB,YAAM,aAAa,IAAI,QACtB,QAAQ,iBAAiB,YAAY,CAAC,EACrC;AAEF,UAAI;AACJ,YAAM,cAAc,IAAI,OAAO,MAAK;AACpC,YAAM,eAAe,QAAQ,YAAY,WAAW;AAEpD,UAAI,eAAe,iBAAiB,WAAW,GAAG;AAEjD,qBAAa,IAAI,QAAQ,WAAW,UAAU;AAG9C,YAAI,OAAO,UAAU,UAAU;AAE9B,gBAAM,QAAQA,QAAO,QACpB,YACA,YAAY,MAAK,GACjB,aAAa,MAAK,CAAE;AAGrB,UAAAA,QAAO,eAAe,OAAO,OAAO,OAAO;QAC5C,OAAO;AAEN,qBAAW,KAAK,KAAK;QACtB;MACD,OAAO;AAEN,qBAAa,MAAM,IAAI,SAAS,YAAY,EAAE,KAAK,CAAC,EAAE,KAAI,MAAO,IAAI;AAErE,cAAM,QAAQA,QAAO,QACpB,YACA,YAAY,MAAK,GACjB,aAAa,MAAK,CAAE;AAIrB,YAAI,OAAO,UAAU,UAAU;AAE9B,UAAAA,QAAO,eAAe,OAAO,OAAO,OAAO;QAC5C,OAAO;AACN,UAAAA,QAAO,WAAW,OAAO,iBAAiB,KAAK;QAChD;MACD;AACA,YAAM,IAAI,MAAM,IACf,YACA,MAAM,QAAQ,MAAM,OAAO;QAC1B,MAAM;QACN,OAAO;QACP,QAAQ;OACR,CAAC;IAEJ,CAAC;EACF;AACA,QAAM,MAAM,OAAM;AACnB;AAEA,SAAS,eACR,WACA,OAAwB;AAGxB,SAAO,UAAU,MAAM,CAAC,GAAG,MAAK;AAE/B,QAAI,OAAO,MAAM;AAAU,aAAO;AAElC,UAAM,CAAC,OAAO,MAAM,IAAI,IAAI;AAC5B,WAAO,OAAO,UAAU,MAAM,CAAC,KAAK,SAAS;EAC9C,CAAC;AACF;;;ACvGA,SAAS,kBAAqB,KAAU,SAAS,GAAG,MAAa;AAChE,MAAI,SAAS,QAAQ,IAAI,SAAS;AAClC,SAAO;IACN;IACA,SAAS,MAAc,KAAa,QAAM;AACzC,aAAO,kBAAkB,KAAK,SAAS,MAAM,KAAK,IAAI;IACvD;IACA,IAAI,MAA+C,QAAQ,GAAC;AAC3D,eAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AACrC,YAAI,SAAS,QAAQ,CAAC,IAAI,KAAK,IAAI,CAAC;MACrC;IACD;IACA,IAAI,OAAa;AAChB,aAAO,IAAI,SAAS,KAAK;IAC1B;;AAEF;AAYA,SAAS,aACR,KAAa;AAMb,MAAI,WAAW,MAAM,QAAQ,IAAI,IAAI,GAAG;AACvC,WAAO;;MAEN,MAAM,kBAAkB,IAAI,IAAI;MAChC,QAAQ,IAAI;MACZ,mBAAmB;;EAErB;AACA,SAAO;IACN,MAAM,IAAI,WACT,IAAI,KAAK,QACT,IAAI,KAAK,YACT,IAAI,KAAK,UAAU;IAEpB,QAAQ,IAAI;IACZ,mBAAmB,IAAI,KAAK;;AAE9B;AAGA,SAAS,4BACR,KAAkB;AAElB,MAAI,WAAW,KAAK;AAGnB,WAAO,IAAI,YAAY,KAAK,MAAM,IAAI,KAAK;EAC5C;AACA,SAAO,IAAI;AACZ;AAYA,SAAS,cACR,KACA,OAAgB;AAEhB,MAAI,WAAW,MAAM,QAAQ,IAAI,IAAI,GAAG;AAEvC,WAAO,kBAAkB,CAAC,KAAK,CAAC;EACjC;AACA,MAAI,aAAa,4BAA4B,IAAI,IAAI;AAErD,MAAI,OAAO,IAAI,WAAW,CAAC,KAAK,CAAC;AACjC,SAAO,IAAI,WAAW,KAAK,QAAQ,KAAK,YAAY,KAAK,UAAU;AACpE;AAEO,IAAM,SAAS;EACrB,QACC,MACA,OACA,QAAgB;AAEhB,WAAO,EAAE,MAAM,OAAO,OAAM;EAC7B;EACA,WACC,MACA,KACA,OAAgB;AAEhB,QAAI,OAAO,aAAa,IAAI;AAC5B,sBACC,MACA,KACA,cAAc,MAAM,KAAK,GACzB,KAAK,iBAAiB;EAExB;EACA,eACC,MACA,KACA,aAAyB;AAEzB,QAAI,OAAO,aAAa,IAAI;AAC5B,0BACC,MACA,aAAa,GAAG,GAChB,KAAK,mBACL,WAAW;EAEb;;AAID,eAAsBC,KAKrB,KACA,YAAwB,MACxB,OAAgD,CAAA,GAAE;AAQlD,SAAO,IAAyC,KAAK,WAAW,MAAM,MAAM;AAC7E;AAGA,eAAsBC,KACrB,KACA,WACA,OACA,OAAmB,CAAA,GAAE;AAErB,SAAO,IAA6B,KAAK,WAAW,OAAO,MAAM,MAAM;AACxE;AAEA,SAAS,YAAY,OAAe,MAAc,MAAY;AAC7D,MAAI,OAAO,KAAK,OAAO,OAAO;AAC7B,WAAO,KAAK,OAAO,QAAQ,OAAO,KAAK,CAAC,IAAI,IAAI;EACjD;AACA,MAAI,QAAQ;AAAM,WAAO,KAAK,OAAO,OAAO,QAAQ,KAAK,IAAI,IAAI;AACjE,SAAO;AACR;AAEA,SAAS,kBACR,KACA,eACA,OACAC,oBAAyB;AAEzB,MAAI,cAAc,WAAW,GAAG;AAC/B,QAAI,KAAK,IAAI,OAAO,CAAC;AACrB;EACD;AACA,QAAM,CAACC,QAAO,GAAG,MAAM,IAAI;AAC3B,QAAM,CAAC,aAAa,GAAG,MAAM,IAAI,IAAI;AACrC,MAAI,OAAOA,WAAU,UAAU;AAC9B,UAAM,OAAO,IAAI,KAAK,SAAS,cAAcA,SAAQD,kBAAiB;AACtE,sBAAkB,EAAE,MAAM,OAAM,GAAI,QAAQ,OAAOA,kBAAiB;AACpE;EACD;AACA,QAAM,CAAC,MAAM,IAAI,IAAI,IAAIC;AACzB,QAAM,MAAM,YAAY,MAAM,IAAI,IAAI;AACtC,MAAI,OAAO,WAAW,GAAG;AACxB,aAAS,IAAI,GAAG,IAAI,KAAK,KAAK;AAC7B,UAAI,KAAK,IAAI,OAAO,eAAe,OAAO,OAAO,KAAKD,kBAAiB;IACxE;AACA;EACD;AACA,WAAS,IAAI,GAAG,IAAI,KAAK,KAAK;AAC7B,UAAM,OAAO,IAAI,KAAK,SACrB,eAAe,OAAO,OAAO,KAAKA,kBAAiB;AAEpD,sBAAkB,EAAE,MAAM,OAAM,GAAI,QAAQ,OAAOA,kBAAiB;EACrE;AACD;AAEA,SAAS,sBACR,MACA,KACAA,oBACA,aAAyB;AAEzB,QAAM,CAAC,MAAM,GAAG,KAAK,IAAI;AACzB,QAAM,CAAC,SAAS,GAAG,QAAQ,IAAI,KAAK;AACpC,QAAM,CAAC,SAAS,GAAG,QAAQ,IAAI,IAAI;AACnC,MAAI,KAAK,SAAS,MAAM;AACvB,QAAI,MAAM,WAAW,GAAG;AACvB,WAAK,KAAK,IACT,IAAI,KAAK,SAAS,GAAGA,kBAAiB,GACtC,KAAK,KAAKA,kBAAiB;AAE5B;IACD;AACA,0BACC;MACC,MAAM,KAAK,KAAK,SAAS,UAAU,KAAK,KAAKA,kBAAiB;MAC9D,QAAQ;OAET,KACAA,oBACA,KAAK;AAEN;EACD;AACA,MAAI,KAAK,OAAO,MAAM;AACrB,QAAI,MAAM,WAAW,GAAG;AACvB,UAAI,SAAS,KAAK,OAAOA;AACzB,WAAK,KAAK,IAAI,IAAI,KAAK,SAAS,QAAQ,SAASA,kBAAiB,GAAG,CAAC;AACtE;IACD;AACA,0BACC,MACA;MACC,MAAM,IAAI,KAAK,SAAS,UAAU,KAAK,OAAOA,kBAAiB;MAC/D,QAAQ;OAETA,oBACA,KAAK;AAEN;EACD;AACA,QAAM,CAAC,MAAM,IAAI,IAAI,IAAI,KAAK;AAC9B,QAAM,CAAC,OAAO,GAAG,KAAK,IAAI,KAAK;AAC/B,QAAM,MAAM,YAAY,MAAM,IAAI,IAAI;AACtC,MAAI,MAAM,WAAW,GAAG;AAGvB,QAAI,SAAS,KAAK,UAAU,KAAK,YAAY,KAAK,YAAY,GAAG;AAChE,UAAI,SAAS,QAAQA;AACrB,UAAI,OAAO,MAAMA;AACjB,WAAK,KAAK,IACT,IAAI,KAAK,SAAS,QAAQ,SAAS,IAAI,GACvC,OAAOA,kBAAiB;AAEzB;IACD;AAEA,aAAS,IAAI,GAAG,IAAI,KAAK,KAAK;AAC7B,UAAI,SAAS,WAAW,QAAQ,QAAQ,KAAKA;AAC7C,WAAK,KAAK,IACT,IAAI,KAAK,SAAS,QAAQ,SAASA,kBAAiB,GACpD,WAAW,OAAO,OAAO,KAAKA,kBAAiB;IAEjD;AACA;EACD;AACA,WAAS,IAAI,GAAG,IAAI,KAAK,KAAK;AAC7B,0BACC;MACC,MAAM,KAAK,KAAK,SACf,WAAW,OAAO,IAAI,QAAQA,kBAAiB;MAEhD,QAAQ;OAET;MACC,MAAM,IAAI,KAAK,SACd,WAAW,QAAQ,IAAI,SAASA,kBAAiB;MAElD,QAAQ;OAETA,oBACA,KAAK;EAEP;AACD;;;AChSA,IAAI,kBAAkB,uBAAsB;AAC5C,SAAS,yBAAsB;AAC9B,MAAI,iBAAiB,oBAAI,QAAO;AAChC,WAAS,WAAW,OAAe;AAClC,QAAI,SAAS,eAAe,IAAI,KAAK,KAAK,EAAE,IAAI,GAAG,IAAI,EAAC;AACxD,mBAAe,IAAI,OAAO,MAAM;AAChC,WAAO;EACR;AACA,SAAO;IACN,UAAU,OAAiB,SAAoB;AAC9C,iBAAW,KAAK,EAAE,OAAO,KAAK;IAC/B;IACA,YAAY,OAAe;AAC1B,UAAI,SAAS,WAAW,KAAK;AAC7B,aAAO,OAAO,KAAK,OAAO,KAAK,OAAO;IACvC;;AAEF;AAEA,eAAe,WAAW,UAA4B;AACrD,MAAI,aAAa,MAAM,SAAS,MAAM,IAAI,SAAS,QAAQ,SAAS,EAAE,IAAI;AAC1E,MAAI,CAAC;AAAY,WAAO,CAAA;AACxB,SAAO,mBAAmB,UAAU;AACrC;AAiBA,eAAe,QACd,UACA,UAAyD,CAAA,GAAE;AAE3D,MAAI,MAAM,WAAW,WAAW,WAAW,IAAI,SAAS,QAAQ;AAChE,MAAI,QAAQ,CAAA;AACZ,MAAI,QAAQ,SAAS;AAAM,YAAQ,MAAM,WAAW,GAAG;AACvD,MAAI,QAAQ,SAAS;AAAS,WAAO,cAAc,KAAK,KAAK;AAC7D,MAAI,QAAQ,SAAS;AAAS,WAAO,cAAc,KAAK,KAAK;AAC7D,SAAO,cAAc,KAAK,KAAK,EAAE,MAAM,CAAC,QAAO;AAC9C,mBAAe,KAAK,iBAAiB;AACrC,WAAO,cAAc,KAAK,KAAK;EAChC,CAAC;AACF;AAEA,eAAe,cACd,UACA,OAAiB;AAEjB,MAAI,EAAE,KAAI,IAAK,SAAS,QAAQ,SAAS;AACzC,MAAI,OAAO,MAAM,SAAS,MAAM,IAAI,IAAI;AACxC,MAAI,CAAC,MAAM;AACV,UAAM,IAAI,kBAAkB,YAAY;MACvC,OAAO,IAAI,SAAS,IAAI;KACxB;EACF;AACA,kBAAgB,UAAU,SAAS,OAAO,IAAI;AAC9C,SAAO,IAAIE,OACV,SAAS,OACT,SAAS,MACT,wBAAwB,mBAAmB,IAAI,GAAG,KAAK,CAAC;AAE1D;AAEA,eAAe,cACd,UACA,OAAiB;AAEjB,MAAI,EAAE,KAAI,IAAK,SAAS,QAAQ,SAAS;AACzC,MAAI,OAAO,MAAM,SAAS,MAAM,IAAI,IAAI;AACxC,MAAI,CAAC,MAAM;AACV,UAAM,IAAI,kBAAkB,YAAY;MACvC,OAAO,IAAI,SAAS,IAAI;KACxB;EACF;AACA,kBAAgB,UAAU,SAAS,OAAO,IAAI;AAC9C,SAAO,IAAI,MACV,SAAS,OACT,SAAS,MACT,wBAAwB,mBAAmB,IAAI,GAAG,KAAK,CAAC;AAE1D;AAEA,eAAe,SAAiC,UAAyB;AACxE,MAAI,EAAE,OAAO,KAAI,IAAK,SAAS,QAAQ,WAAW;AAClD,MAAI,OAAO,MAAM,SAAS,MAAM,IAAI,IAAI;AACxC,MAAI,CAAC,MAAM;AACV,UAAM,IAAI,kBAAkB,qBAAqB;MAChD,OAAO,IAAI,SAAS,IAAI;KACxB;EACF;AACA,MAAI,WACH,mBAAmB,IAAI;AACxB,MAAI,SAAS,cAAc,SAAS;AACnC,aAAS,aAAa,sBAAsB,QAAQ;EACrD;AACA,SAAO,SAAS,cAAc,UAC3B,IAAIA,OAAM,OAAO,SAAS,MAAM,QAAQ,IACxC,IAAI,MAAM,OAAO,SAAS,MAAM,QAAQ;AAC5C;AAoBA,eAAe,QACd,UACA,UAAwC,CAAA,GAAE;AAE1C,MAAI,MAAM,WAAW,WAAW,WAAW,IAAI,SAAS,QAAQ;AAChE,MAAI,OAAO,MAAM,SAAS,GAAG;AAC7B,kBAAgB,UAAU,IAAI,OAAO,IAAI;AACzC,MAAI,QAAQ,SAAS;AAAW,WAAO;AACvC,MAAI,QAAQ,SAAS,WAAW,gBAAgBA;AAAO,WAAO;AAC9D,MAAI,QAAQ,SAAS,WAAW,gBAAgB;AAAO,WAAO;AAC9D,MAAI,OAAO,gBAAgBA,SAAQ,UAAU;AAC7C,QAAM,IAAI,MAAM,yBAAyB,QAAQ,IAAI,WAAW,IAAI,GAAG;AACxE;AAyBA,eAAsB,KACrB,UACA,UAAwC,CAAA,GAAE;AAE1C,MAAI,QAAQ,WAAW,WAAW,SAAS,QAAQ;AACnD,MAAI,cAAc,gBAAgB,YAAY,KAAK;AAInD,MAAI,eAAe,gBAAgB,OAAO,KAAK,KAAK,KAAK;AACzD,MAAI,iBAAiB,gBAAgB,OAAO,KAAK,KAAK,KAAK;AAC3D,SAAO,aAAa,UAAU,OAAO,EAAE,MAAM,CAAC,QAAO;AACpD,mBAAe,KAAK,iBAAiB;AACrC,WAAO,eAAe,UAAU,OAAO;EACxC,CAAC;AACF;AAEA,KAAK,KAAK;AACV,KAAK,KAAK;",
  "names": ["root", "range", "bytes_per_element", "_bytes", "_shape", "_bytes", "_a", "_a", "opts", "root", "_a", "native_order", "_metadata", "Array", "Array", "setter", "_a", "setter", "get", "set", "bytes_per_element", "slice", "Array"]
}
